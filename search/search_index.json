{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Atomist - How Teams Deliver Software Every serious business has its own development and delivery experience. Most of them aren\u2019t what we want. We want to spend our time and focus solving problems for the business, but to do that well, we need to enact our own blueprint for software delivery. So far, enterprises piece together pipeline tools, configured by a plethora of YAML or by hand in a GUI. For anything interesting, we resort to a Bash script, the lowest common denominator of programming. We enroll myriad chatbots to spam our channels. We write how-to wiki pages and distribute hand-me-down scripts. As our practices improve, older projects languish in prior standards. Meanwhile we shake our heads wistfully over the elegant flow of shiny new delivery tools \u2013 they will never fit our real-world environment. Atomist says, there is a better way. A world beyond pipelines, a world of little YAML and Bash, a world where we code our way to an appropriate delivery experience, with higher coding standards, up-to-date application suites, and continual improvement. And this way begins where we are, not with a big migration. The new world is driven by events, not configuration, and we specify our reactions in a modern programming language. These events are correlated to each other into a coherent model, an API for Software. Developers and automations work together, coordinating in chat. Decisions are for people; consistent execution of tedious tasks is for programs. Escape Bash and YAML Tired of managing CI/CD Bash scripts and YAML config across dozens of repositories? Use Atomist to tame the complexity and execute your best delivery process across all your repositories. What is this better way? Atomist lets you construct your delivery process in code \u2013 but not too much code. A service, a framework, and some libraries take care of the pieces that are common to every development organization. Atomist works atop your existing toolchain, adding functionality and smoothing your experience; then you\u2019re free to improve it. The crux of your development experience lives in your software delivery machine (SDM). This is a service that runs wherever you choose to run it. Start with one of ours, then make it yours. Your SDM is in TypeScript (or JavaScript works too), and comes with a framework designed for software delivery and development automation. Write functions to make decisions or take action, with access to all the code plus the context of the push or build or issue event. All of this is open source. While you can run an SDM independently and in private to help only yourself, the magic happens when it connects to the Atomist service to respond to your whole team or organization. The service provides triggering with rich events and custom commands, interactive chat integration, and built-in automations like sweet chat messages for standard events like code push and issue creation. These chat messages get updated when new information comes in. They include useful buttons to take action: raise a PR, label an issue, or approve the next step in the deploy process. But wait, there\u2019s more! I\u2019ve talked about how your delivery flow can be defined in code instead of Bash, in one open place instead of many narrow pipelines. I mentioned custom commands, where you can ensconce common developer activities in a convenient location, accessible from chat. These commands are code: consistent, shared, versioned. You might have gleaned that because your Software Delivery Machine is code, you\u2019re never limited to plugins, nor to anyone else\u2019s idea of the correct delivery mechanism; your SDM can integrate with your existing tools. Keep the tools that are working for you , and integrate new ones as you wish. Tie these together with an SDM, plus bonuses like automatic CHANGELOG management . Your SDM gives you something else: the ability to manipulate code across all your projects with one command. Atomist libraries help you write code transforms\u2013functions that operate on code\u2013and the API for Software turns those into branches, pull requests, or automatic commits on every deviating push. Bring code up to standards and then keep it there. Your SDM gives you something else: start new projects with the right code and setup, every time. Atomist generators start from a real, working project and use code transforms to construct a starting point in a new repository. Your SDM can respond to more events , and to custom events that you send. You can query your correlated events using GraphQL. You can build chat commands, with updating messages and adding action buttons. You can add integrations and commands written by Atomist and the community, and contribute your own. Stories Check out some samples of what an Atomist SDM can do: Upgrade test files to a new standard Enforce custom code formatting Deploy Spring Boot to Kubernetes , and generate new projects, and manage versions of existing projects ( video ) Convert a migration script into a Slack command You might want to know Existing integrations Architecture Security model How to proceed If you want bring the Atomist into your team, you\u2019ll get built-in chat integrations immediately. Proceed to the Using Atomist page to get Atomist installed in your Slack workspace, authorized in GitHub, and connected to your continuous integration system. If you want to develop with Atomist, either for your team or for your own local use (with no enrollment), please skip to the Developer Guide to learn how to create and run your own SDM.","title":"Introduction"},{"location":"#atomist-how-teams-deliver-software","text":"Every serious business has its own development and delivery experience. Most of them aren\u2019t what we want. We want to spend our time and focus solving problems for the business, but to do that well, we need to enact our own blueprint for software delivery. So far, enterprises piece together pipeline tools, configured by a plethora of YAML or by hand in a GUI. For anything interesting, we resort to a Bash script, the lowest common denominator of programming. We enroll myriad chatbots to spam our channels. We write how-to wiki pages and distribute hand-me-down scripts. As our practices improve, older projects languish in prior standards. Meanwhile we shake our heads wistfully over the elegant flow of shiny new delivery tools \u2013 they will never fit our real-world environment. Atomist says, there is a better way. A world beyond pipelines, a world of little YAML and Bash, a world where we code our way to an appropriate delivery experience, with higher coding standards, up-to-date application suites, and continual improvement. And this way begins where we are, not with a big migration. The new world is driven by events, not configuration, and we specify our reactions in a modern programming language. These events are correlated to each other into a coherent model, an API for Software. Developers and automations work together, coordinating in chat. Decisions are for people; consistent execution of tedious tasks is for programs. Escape Bash and YAML Tired of managing CI/CD Bash scripts and YAML config across dozens of repositories? Use Atomist to tame the complexity and execute your best delivery process across all your repositories.","title":"Atomist - How Teams Deliver Software"},{"location":"#what-is-this-better-way","text":"Atomist lets you construct your delivery process in code \u2013 but not too much code. A service, a framework, and some libraries take care of the pieces that are common to every development organization. Atomist works atop your existing toolchain, adding functionality and smoothing your experience; then you\u2019re free to improve it. The crux of your development experience lives in your software delivery machine (SDM). This is a service that runs wherever you choose to run it. Start with one of ours, then make it yours. Your SDM is in TypeScript (or JavaScript works too), and comes with a framework designed for software delivery and development automation. Write functions to make decisions or take action, with access to all the code plus the context of the push or build or issue event. All of this is open source. While you can run an SDM independently and in private to help only yourself, the magic happens when it connects to the Atomist service to respond to your whole team or organization. The service provides triggering with rich events and custom commands, interactive chat integration, and built-in automations like sweet chat messages for standard events like code push and issue creation. These chat messages get updated when new information comes in. They include useful buttons to take action: raise a PR, label an issue, or approve the next step in the deploy process.","title":"What is this better way?"},{"location":"#but-wait-theres-more","text":"I\u2019ve talked about how your delivery flow can be defined in code instead of Bash, in one open place instead of many narrow pipelines. I mentioned custom commands, where you can ensconce common developer activities in a convenient location, accessible from chat. These commands are code: consistent, shared, versioned. You might have gleaned that because your Software Delivery Machine is code, you\u2019re never limited to plugins, nor to anyone else\u2019s idea of the correct delivery mechanism; your SDM can integrate with your existing tools. Keep the tools that are working for you , and integrate new ones as you wish. Tie these together with an SDM, plus bonuses like automatic CHANGELOG management . Your SDM gives you something else: the ability to manipulate code across all your projects with one command. Atomist libraries help you write code transforms\u2013functions that operate on code\u2013and the API for Software turns those into branches, pull requests, or automatic commits on every deviating push. Bring code up to standards and then keep it there. Your SDM gives you something else: start new projects with the right code and setup, every time. Atomist generators start from a real, working project and use code transforms to construct a starting point in a new repository. Your SDM can respond to more events , and to custom events that you send. You can query your correlated events using GraphQL. You can build chat commands, with updating messages and adding action buttons. You can add integrations and commands written by Atomist and the community, and contribute your own.","title":"But wait, there's more!"},{"location":"#stories","text":"Check out some samples of what an Atomist SDM can do: Upgrade test files to a new standard Enforce custom code formatting Deploy Spring Boot to Kubernetes , and generate new projects, and manage versions of existing projects ( video ) Convert a migration script into a Slack command","title":"Stories"},{"location":"#you-might-want-to-know","text":"Existing integrations Architecture Security model","title":"You might want to know"},{"location":"#how-to-proceed","text":"If you want bring the Atomist into your team, you\u2019ll get built-in chat integrations immediately. Proceed to the Using Atomist page to get Atomist installed in your Slack workspace, authorized in GitHub, and connected to your continuous integration system. If you want to develop with Atomist, either for your team or for your own local use (with no enrollment), please skip to the Developer Guide to learn how to create and run your own SDM.","title":"How to proceed"},{"location":"quick-start/","text":"This page shows you how to start building your own development automations using Atomist. Use this to explore, whether or not you have access to the Atomist service, and whether or not your team has other SDMs running. The easiest way to get started with Atomist is to work on your laptop in local mode . You will create your own software delivery machine, use it, and then customize it, all in the privacy of your machine. Later, you can connect your SDM to the Atomist service, and then it will work with your team\u2019s version control and chat. An Atomist SDM can run any delivery process, and many other things besides\u2013but for exploration we have to start somewhere. Let\u2019s pretend your team operates several web services, you write them in Java using Spring Boot, and you like build them with maven. Since this SDM is for your personal use on your laptop, \u201cdeployment\u201d means starting the service up locally. We are going to create a new SDM project, build it, run it, and then use it: we will create a new Spring web service, make commits to it, and see it deployed. You\u2019ll need Git , Node.js (this comes with npm ), and the Java JDK installed. Run the listed commands in a terminal on Mac or Linux, or in Bash on Windows (git-bash, cygwin, or turn on bash support). Quick start Install the Atomist command-line utility. We will use this to create a new SDM project and to start it up. Using Homebrew on macOS: brew install atomist-cli On other platforms, install Node.js and then run: npm install -g @atomist/cli Create a local software delivery machine (SDM). This is going to create a new project in the Atomist projects directory (which defaults to $HOME/atomist/projects ). atomist create sdm Select the default machine, spring . When prompted for the name of the target repository, enter quick-sdm . When prompted for a target owner, enter your user name (on GitHub or anywhere). The output of this command includes the newly created file directory. In that directory, Change into the newly created SDM project. cd $HOME/atomist/projects/<target owner>/quick-sdm Start your local SDM. npm install atomist start --local The above command will install the project dependencies using npm, compile the TypeScript, and start your SDM. Depending on your network connection, this may take a minute or more. Leave this terminal window open. Logs will print to this screen. In another terminal, check what your SDM can do. This will print a list of commands supported by your running quick-sdm. atomist show skills Start up the SDM feed so you can see what the SDM is doing. atomist feed Leave this terminal window open. Messages will print here. Now it is time to use your SDM. While it is running, the atomist command line utility can send your commands to it. In another terminal, create a Spring Boot project. atomist create spring This command will connect to your locally running SDM and use its capabilities to create a new Spring Boot project for you. When prompted for the target repository, enter quick-spring . When prompted for group identifier and root package, enter com.me and com.me.spring , respectively. (These are maven concepts.) When prompted for the target owner, enter your user name again. If you look in the terminal with the Atomist feed, you will see the SDM cloning the seed repository, cloning it locally, building it, and deploying it locally. The first time you run this, it may take a few minutes as it downloads all the Maven and project dependencies. You can go to the URL provided for the local deployment and verify that your new Spring Boot application is running. Move into your newly created Spring Boot project. cd ~/atomist/<your user name>/quick-spring Change the message in your Spring Boot application. Edit src/main/java/com/me/spring/QuickSpringController.java , changing \u201cworld\u201d to your location. Then commit your change. git add src/main/java/com/me/spring/QuickSpringController.java git commit -m 'Update location' Go back to the Atomist feed to observe your locally running SDM noticing your commit and respond by building and deploying your latest version. Go to the URL again and verify the message contains your location. Next steps Find many things you can do with an SDM in the Developer Guide . When you\u2019re ready to put your SDM to work for your whole team, continue with setup .","title":"Developer Quick Start"},{"location":"quick-start/#quick-start","text":"Install the Atomist command-line utility. We will use this to create a new SDM project and to start it up. Using Homebrew on macOS: brew install atomist-cli On other platforms, install Node.js and then run: npm install -g @atomist/cli Create a local software delivery machine (SDM). This is going to create a new project in the Atomist projects directory (which defaults to $HOME/atomist/projects ). atomist create sdm Select the default machine, spring . When prompted for the name of the target repository, enter quick-sdm . When prompted for a target owner, enter your user name (on GitHub or anywhere). The output of this command includes the newly created file directory. In that directory, Change into the newly created SDM project. cd $HOME/atomist/projects/<target owner>/quick-sdm Start your local SDM. npm install atomist start --local The above command will install the project dependencies using npm, compile the TypeScript, and start your SDM. Depending on your network connection, this may take a minute or more. Leave this terminal window open. Logs will print to this screen. In another terminal, check what your SDM can do. This will print a list of commands supported by your running quick-sdm. atomist show skills Start up the SDM feed so you can see what the SDM is doing. atomist feed Leave this terminal window open. Messages will print here. Now it is time to use your SDM. While it is running, the atomist command line utility can send your commands to it. In another terminal, create a Spring Boot project. atomist create spring This command will connect to your locally running SDM and use its capabilities to create a new Spring Boot project for you. When prompted for the target repository, enter quick-spring . When prompted for group identifier and root package, enter com.me and com.me.spring , respectively. (These are maven concepts.) When prompted for the target owner, enter your user name again. If you look in the terminal with the Atomist feed, you will see the SDM cloning the seed repository, cloning it locally, building it, and deploying it locally. The first time you run this, it may take a few minutes as it downloads all the Maven and project dependencies. You can go to the URL provided for the local deployment and verify that your new Spring Boot application is running. Move into your newly created Spring Boot project. cd ~/atomist/<your user name>/quick-spring Change the message in your Spring Boot application. Edit src/main/java/com/me/spring/QuickSpringController.java , changing \u201cworld\u201d to your location. Then commit your change. git add src/main/java/com/me/spring/QuickSpringController.java git commit -m 'Update location' Go back to the Atomist feed to observe your locally running SDM noticing your commit and respond by building and deploying your latest version. Go to the URL again and verify the message contains your location.","title":"Quick start"},{"location":"quick-start/#next-steps","text":"Find many things you can do with an SDM in the Developer Guide . When you\u2019re ready to put your SDM to work for your whole team, continue with setup .","title":"Next steps"},{"location":"support/","text":"Thanks so much for choosing Atomist! At Atomist, we want all developers to excel. We believe that given the right tools and guidance, all developers can be highly productive. We strive to provide tools that give their users super powers and we\u2019re happy to provide any guidance we can to help you use them most effectively. If you have any questions or need any help of any kind, don\u2019t hesitate to contact us in whatever way is most convenient for you. Chat with us right here Atomist Community Slack support@atomist.com Twitter Issues and pull requests on our open source projects We exist to help you be as productive you can be. Let us know how we can help you. Happy coding!","title":"Support"},{"location":"developer/","text":"Developer Guide When you\u2019re ready to craft your own delivery and development automation, this is the place to be. How to use this guide With this guide, we aim to provide all the information you need to create and customize a software delivery machine for your organization\u2019s needs. When the information here is not clear or not sufficient, we appreciate your perspective. Ask us questions through the chat icon in the lower-right of this page, or on the Atomist community Slack . You can also contribute to this guide by creating issues or pull requests on the docs repository . If you want to learn by doing, run through the Developer Quick Start first. If you want to start from higher-level concepts, begin reading about the architecture . New superpowers This guide should help you make your SDM: Build your repositories , more flexibly than a pipeline Deploy your code , with interactivity Inspect your code , across projects and automatically on push Transform your code , across projects and automatically on push Respond to builds , from the SDM or external build systems Implement custom commands Create new projects according to your own standards Underlying concepts To do all this, these higher-level concepts are relevant: Setting up your system to develop and run SDMs the atomist command line tool your Software Delivery Machine Commands Goals the Project interface Advanced topics Crafting sophisticated Slack messages Using GraphQL to subscribe to events Deploying your SDM Once you\u2019ve finished this section, you\u2019ll have everything you need to eliminate the pain points in your development and delivery processes. Or if you don\u2019t, please let us know! We are available in the Atomist community Slack , or through the chat icon at the bottom of this page.","title":"What you can do"},{"location":"developer/#developer-guide","text":"When you\u2019re ready to craft your own delivery and development automation, this is the place to be.","title":"Developer Guide"},{"location":"developer/#how-to-use-this-guide","text":"With this guide, we aim to provide all the information you need to create and customize a software delivery machine for your organization\u2019s needs. When the information here is not clear or not sufficient, we appreciate your perspective. Ask us questions through the chat icon in the lower-right of this page, or on the Atomist community Slack . You can also contribute to this guide by creating issues or pull requests on the docs repository . If you want to learn by doing, run through the Developer Quick Start first. If you want to start from higher-level concepts, begin reading about the architecture .","title":"How to use this guide"},{"location":"developer/#new-superpowers","text":"This guide should help you make your SDM: Build your repositories , more flexibly than a pipeline Deploy your code , with interactivity Inspect your code , across projects and automatically on push Transform your code , across projects and automatically on push Respond to builds , from the SDM or external build systems Implement custom commands Create new projects according to your own standards","title":"New superpowers"},{"location":"developer/#underlying-concepts","text":"To do all this, these higher-level concepts are relevant: Setting up your system to develop and run SDMs the atomist command line tool your Software Delivery Machine Commands Goals the Project interface","title":"Underlying concepts"},{"location":"developer/#advanced-topics","text":"Crafting sophisticated Slack messages Using GraphQL to subscribe to events Deploying your SDM Once you\u2019ve finished this section, you\u2019ll have everything you need to eliminate the pain points in your development and delivery processes. Or if you don\u2019t, please let us know! We are available in the Atomist community Slack , or through the chat icon at the bottom of this page.","title":"Advanced topics"},{"location":"developer/architecture/","text":"It all starts with a software delivery machine of your very own. That can be for your team or for you personally\u2013one of each is good. An Atomist Software Delivery Machine (SDM) provides a high-level interface for you to take action when things happen. In much the same way your continuous integration build kicks off when you push to your repository, Atomist can execute tasks like security scans, documentation publication, release creation, and deployment. Because you\u2019re using a real programming language, not YAML or Bash, and because you have access to a real ecosystem, Node.js, you can create the richest delivery experience you can imagine. API for Software The SDM is a persistent process that runs in the background. An SDM links up to the API for software , implemented by the Atomist service, exposing: What we know : The Atomist cortex, accessible through GraphQL queries and subscription joins What just happened : An event, triggered by a GraphQL subscription, which is contextualized with the existing knowledge What you\u2019re working on : A library that enables you to comprehend and manipulate the source code you\u2019re working on. When a push occurs, the SDM gets all this context and the code. It decides what delivery actions to take, and sets goals accordingly. Instead of a static pipeline, you get to choose the delivery flow for each commit. A push is not the only event that matters in our software development. The Atomist development automation platform ingests events from your software development systems: Source code repositories like GitHub.com and GitHub Enterprise Issue tracking systems like GitHub and Jira Continuous integration platforms like Travis CI , CircleCI , and Jenkins Application frameworks like Spring Runtime platforms like Kubernetes and Cloud Foundry Custom events from any other system you use and makes them available via the Atomist API for software. As Atomist ingests events, typically via webhook JSON payloads, it automatically correlates them to each other: commits to pushes to builds to deployments to running containers. This results in a data model that represents your development flow. The Software Delivery Machine subscribes to the most important events, like a push to source control and a completed build. You can subscribe to more events and take action when they occur, with the data model providing the necessary context so your automations can always do the right thing. The development automation platform also provides a simple yet powerful interface for implementing custom chat bot commands, also executable from your command line. Atomist provides all the infrastructure needed to recognize commands, collect parameters, execute the code, and respond. This lets you focus on writing your command code, not boilerplate code and ceremony around running bots. Instead of shell scripts that are useful only to you, write commands that help your whole team. Coding your SDM A software delivery machine uses the @atomist/sdm framework to specify the code delivery process and other automations. You don\u2019t configure your SDM: you code it, by combining or writing functions in TypeScript (or JavaScript). Some common setups, such as deliverying and maintaining Spring Boot apps or npm libraries, are provided in extension packs . You can configure the whole pack, or use functions from the pack in your own setup. Connect your SDM Atomist maintains two implementations of the API for Software: Team mode : a complete, cloud-based service, Local mode : an open-source, filesystem-based version that runs on your laptop. An SDM is most useful when running for your whole team, connected to the Atomist API for software, Slack, and your version control. Run it on your laptop while you\u2019re testing and modifying the SDM, then in your favorite production environment (on-prem or in the cloud) for ongoing use. If you don\u2019t want to subscribe to the Atomist service and hook up Slack and GitHub/BitBucket/GitLab etc, you\u2019re in luck! Run your SDM in local mode , on your own machine. Receive push events from your own local commits, get messages in a terminal feed, and trigger commands on the command line. Check the Developer Quick Start for instructions to get started in local mode.","title":"Architecture"},{"location":"developer/architecture/#api-for-software","text":"The SDM is a persistent process that runs in the background. An SDM links up to the API for software , implemented by the Atomist service, exposing: What we know : The Atomist cortex, accessible through GraphQL queries and subscription joins What just happened : An event, triggered by a GraphQL subscription, which is contextualized with the existing knowledge What you\u2019re working on : A library that enables you to comprehend and manipulate the source code you\u2019re working on. When a push occurs, the SDM gets all this context and the code. It decides what delivery actions to take, and sets goals accordingly. Instead of a static pipeline, you get to choose the delivery flow for each commit. A push is not the only event that matters in our software development. The Atomist development automation platform ingests events from your software development systems: Source code repositories like GitHub.com and GitHub Enterprise Issue tracking systems like GitHub and Jira Continuous integration platforms like Travis CI , CircleCI , and Jenkins Application frameworks like Spring Runtime platforms like Kubernetes and Cloud Foundry Custom events from any other system you use and makes them available via the Atomist API for software. As Atomist ingests events, typically via webhook JSON payloads, it automatically correlates them to each other: commits to pushes to builds to deployments to running containers. This results in a data model that represents your development flow. The Software Delivery Machine subscribes to the most important events, like a push to source control and a completed build. You can subscribe to more events and take action when they occur, with the data model providing the necessary context so your automations can always do the right thing. The development automation platform also provides a simple yet powerful interface for implementing custom chat bot commands, also executable from your command line. Atomist provides all the infrastructure needed to recognize commands, collect parameters, execute the code, and respond. This lets you focus on writing your command code, not boilerplate code and ceremony around running bots. Instead of shell scripts that are useful only to you, write commands that help your whole team.","title":"API for Software"},{"location":"developer/architecture/#coding-your-sdm","text":"A software delivery machine uses the @atomist/sdm framework to specify the code delivery process and other automations. You don\u2019t configure your SDM: you code it, by combining or writing functions in TypeScript (or JavaScript). Some common setups, such as deliverying and maintaining Spring Boot apps or npm libraries, are provided in extension packs . You can configure the whole pack, or use functions from the pack in your own setup.","title":"Coding your SDM"},{"location":"developer/architecture/#connect-your-sdm","text":"Atomist maintains two implementations of the API for Software: Team mode : a complete, cloud-based service, Local mode : an open-source, filesystem-based version that runs on your laptop. An SDM is most useful when running for your whole team, connected to the Atomist API for software, Slack, and your version control. Run it on your laptop while you\u2019re testing and modifying the SDM, then in your favorite production environment (on-prem or in the cloud) for ongoing use. If you don\u2019t want to subscribe to the Atomist service and hook up Slack and GitHub/BitBucket/GitLab etc, you\u2019re in luck! Run your SDM in local mode , on your own machine. Receive push events from your own local commits, get messages in a terminal feed, and trigger commands on the command line. Check the Developer Quick Start for instructions to get started in local mode.","title":"Connect your SDM"},{"location":"developer/astutils/","text":"Every programming language has a structure. The first part of compilation breaks down the structure of the file into an abstract syntax tree (AST), a data structure that represents the code in programming language concepts. When you understand the structure of your programming language, you can use this to find bits of code that you\u2019re looking for. With Atomist, you can also update those bits of code without changing the rest of the file at all. There are functions in astUtils to help you access the AST. For this, you\u2019ll need a parser for your language. Parsers for Java, TypeScript (which can parse JavaScript), and Markdown are provided already. Creating a compatible parser for another language is easy if an ANTLR grammar already exists. More on that in our @atomist/antlr library. The ASTs for most languages are deep and complicated. To access portions of the tree in Atomist, you use path expressions . They let you navigate into the parts of the tree you care about, without worrying about stuff in the middle. For instance, to find method invocations in Java, I can use the Java9FileParser , which is based on an existing Java ANTLR grammar . I can skip over everything between the top-level compilationUnit and get at the name of the invoked method with this path expression: /compilationUnit//methodInvocation_lfno_primary/identifier/Identifier (Caveat: this doesn\u2019t catch every method call. It\u2019s simplified for this example.) See more details on path expression syntax in the tree-path library docs . finding and changing code instances in a project Given a parser and a path expression, you can find all matching code using astUtils.matchIterator . This uses the path expression discussed above to find all the method names called in all the Java files: const matchIterable = await astUtils . matchIterator ( project , { parseWith : Java9FileParser , globPatterns : \"**/*.java\" , pathExpression : `/compilationUnit//methodInvocation_lfno_primary/identifier/Identifier` , }); const words : { [ k : string ] : number } = {}; for await ( const m of matchIterable ) { console . log ( \"Found a call to \" + m . $value + \"\\nChanging it to foo!\" ); // you can change it! m . $value = \"foo\" ; } You get an AsyncIterable of MatchResult s. Use the for await(...of...) syntax to access each match result. Check the $value property for the string that matched. Update the $value property to change that string in the file, when you are writing a code transform . If you want information about the file that the code is in, try astUtils.fileHitIterator . See also: the Project API do simpler manipulations of file content with projectUtils get at the relevant parts of files with microgrammars and parseUtils","title":"Astutils"},{"location":"developer/astutils/#finding-and-changing-code-instances-in-a-project","text":"Given a parser and a path expression, you can find all matching code using astUtils.matchIterator . This uses the path expression discussed above to find all the method names called in all the Java files: const matchIterable = await astUtils . matchIterator ( project , { parseWith : Java9FileParser , globPatterns : \"**/*.java\" , pathExpression : `/compilationUnit//methodInvocation_lfno_primary/identifier/Identifier` , }); const words : { [ k : string ] : number } = {}; for await ( const m of matchIterable ) { console . log ( \"Found a call to \" + m . $value + \"\\nChanging it to foo!\" ); // you can change it! m . $value = \"foo\" ; } You get an AsyncIterable of MatchResult s. Use the for await(...of...) syntax to access each match result. Check the $value property for the string that matched. Update the $value property to change that string in the file, when you are writing a code transform . If you want information about the file that the code is in, try astUtils.fileHitIterator .","title":"finding and changing code instances in a project"},{"location":"developer/astutils/#see-also","text":"the Project API do simpler manipulations of file content with projectUtils get at the relevant parts of files with microgrammars and parseUtils","title":"See also:"},{"location":"developer/autofix/","text":"Autofixes keep your source code in the state you like it, without nagging people. An Autofix checks every push, and if the code doesn\u2019t look like you want it to, changes it and makes a commit. The instructions in this page apply after: You have an SDM that [sets goals][goals] You have a code transform command . This page shows how to: Turn a code transform into an autofix Skip some pushes goals Change a code transform into an autofix Assume that we have the following code transform: export const AddApacheLicenseFileTransform : CodeTransform < NoParameters > = async ( p : Project ) => { const httpClient = DefaultHttpClientFactory . create (); const license = await httpClient . exchange ( \"https://www.apache.org/licenses/LICENSE-2.0.txt\" ); return p . addFile ( \"LICENSE\" , license . body as string ); }; We can create an AutofixRegistration . export const AddApacheLicenseFileAutofix : AutofixRegistration = { name : \"add apache license file\" , transform : AddApacheLicenseFileTransform , pushTest : not ( hasFile ( \"LICENSE\" )), options : { ignoreFailure : false , considerOnlyChangedFiles : false , }, }; An AutofixRegistration references the code transform (or an array of code transforms). Each autofix will make its own commit, and the name appears in the commit message: Autofix: <name of the autofix> See also: AutofixRegistration API Docs Skip some pushes The optional PushTest field limits when the Autofix will be applied. If the test returns false, Atomist will skip this Autofix. Here, we only want to add a license file to pushes that do not currently have one. We have the following PushTest that checks whether a project contains a license file. hasFile ( \"LICENSE\" ) hasFile returns true if a file is present in the code. The not function inverts the result, so the Autofix will only run when there is no LICENSE file present in the project after a push. For more push tests, see Push Tests . Autofix Registration options You can define a set of options on the registration: ignoreFailure : failures in the transform will cause other later autofixes to not be applied if set to false considerOnlyChangedFiles : the code transform will only be applied to files that have been changed in the push if set to true Add the autofix goal to your goalset If you already have an Autofix goal, register your new autofix on it: autofixGoal . with ( AddApacheLicenseFileAutofix ); If not, get one. First you instantiate the goal itself and add the AutofixRegistration to it. const autofixGoal = new Autofix (). with ( AddApacheLicenseFileAutofix ); Then you add the goal to your goal set. For example, if you want to add the goal to each push, you add the following piece of code. sdm . addPushRules ( onAnyPush (). setGoals ( autofix )); Commit behavior of autofixes When autofixes are applied as a result of a push, the rest of the goal set will be cancelled, since they should run on the fixed code instead. Each autofix will result in a separate commit, but all autofix commits will be pushed at the same time. This push will then trigger a new goal set execution.","title":"Autofixes"},{"location":"developer/autofix/#change-a-code-transform-into-an-autofix","text":"Assume that we have the following code transform: export const AddApacheLicenseFileTransform : CodeTransform < NoParameters > = async ( p : Project ) => { const httpClient = DefaultHttpClientFactory . create (); const license = await httpClient . exchange ( \"https://www.apache.org/licenses/LICENSE-2.0.txt\" ); return p . addFile ( \"LICENSE\" , license . body as string ); }; We can create an AutofixRegistration . export const AddApacheLicenseFileAutofix : AutofixRegistration = { name : \"add apache license file\" , transform : AddApacheLicenseFileTransform , pushTest : not ( hasFile ( \"LICENSE\" )), options : { ignoreFailure : false , considerOnlyChangedFiles : false , }, }; An AutofixRegistration references the code transform (or an array of code transforms). Each autofix will make its own commit, and the name appears in the commit message: Autofix: <name of the autofix> See also: AutofixRegistration API Docs","title":"Change a code transform into an autofix"},{"location":"developer/autofix/#skip-some-pushes","text":"The optional PushTest field limits when the Autofix will be applied. If the test returns false, Atomist will skip this Autofix. Here, we only want to add a license file to pushes that do not currently have one. We have the following PushTest that checks whether a project contains a license file. hasFile ( \"LICENSE\" ) hasFile returns true if a file is present in the code. The not function inverts the result, so the Autofix will only run when there is no LICENSE file present in the project after a push. For more push tests, see Push Tests .","title":"Skip some pushes"},{"location":"developer/autofix/#autofix-registration-options","text":"You can define a set of options on the registration: ignoreFailure : failures in the transform will cause other later autofixes to not be applied if set to false considerOnlyChangedFiles : the code transform will only be applied to files that have been changed in the push if set to true","title":"Autofix Registration options"},{"location":"developer/autofix/#add-the-autofix-goal-to-your-goalset","text":"If you already have an Autofix goal, register your new autofix on it: autofixGoal . with ( AddApacheLicenseFileAutofix ); If not, get one. First you instantiate the goal itself and add the AutofixRegistration to it. const autofixGoal = new Autofix (). with ( AddApacheLicenseFileAutofix ); Then you add the goal to your goal set. For example, if you want to add the goal to each push, you add the following piece of code. sdm . addPushRules ( onAnyPush (). setGoals ( autofix ));","title":"Add the autofix goal to your goalset"},{"location":"developer/autofix/#commit-behavior-of-autofixes","text":"When autofixes are applied as a result of a push, the rest of the goal set will be cancelled, since they should run on the fixed code instead. Each autofix will result in a separate commit, but all autofix commits will be pushed at the same time. This push will then trigger a new goal set execution.","title":"Commit behavior of autofixes"},{"location":"developer/build/","text":"Getting your projects built is one of the most important parts of a CI lifecycle. As a full-featured CI solution, Atomist provides the functionality needed to perform builds. Or, integrate with your existing build tools. With Atomist, you can start where you are and then have the flexibility to move where you want to go. This page shows how to Run builds in your SDM Set a goal to represent builds that happen in your CI tool The Build goal Atomist provides a goal that is designed to handle building software: the Build goal. It lives in the Build Pack , so run npm install @atomist/sdm-pack-build to get it. The build goal does a couple things: Invoke a builder that builds your project Link the built artifact, associating it to the commit Get one by calling the Build constructor. If you want it to appear as something more specific than \u201cbuild\u201d, pass a displayName in its options. const build = new Build ({ displayName : \"maven build\" }). with ({ name : \"maven\" , builder : mavenBuilder (), }); This goal defines a build that will be handled by Maven. Be sure to add the goal to your goal set . The trick is: you need a Builder . Builders Builders implement the logic that is needed to build your software. Out of the box, Atomist provides a couple of builders for: Maven Gradle NodeJS using npm Generic builder that calls a terminal script You can also create your own. A builder is a function that gets a GoalInvocation and a build number and return a Promise<BuildInProgress> ( goalInvocation : GoalInvocation , buildNo : string ) => Promise < BuildInProgress > Builds handled by external systems In addition to handling the CI lifecycle itself, Atomist can also defer the build to external systems like your existing CI lifecycle. To achieve this, you need to define your build goal like this: const build = new Build ({ displayName : \"Travis build\" }). with ({ name : \"maven\" , externalTool : \"travis\" }); You can find more detailed information on how to hook up existing CI systems on the integrations page . Atomist builders Atomist does not build your software. You have a build tool that does that. Atomist spawns a process to call your build tool. The Builder knows the command to run, along with how to parse the log file. Here are some handy builders that are already available. For anything else, start with a general spawnBuilder . Maven Maven builds are supported out of the box through the mavenBuilder found in sdm-pack-spring . The builder is defined as such export function mavenBuilder ( args : Array < { name : string , value? : string } > = [], deploymentUnitFileLocator : ( p : LocalProject , mpi : VersionedArtifact ) => string = ( p , mpi ) => ` ${ p . baseDir } /target/ ${ mpi . artifact } - ${ mpi . version } .jar` ) : Builder The Maven builder will issue a mvn package (or use mvnw if that\u2019s available in the project) command to build your project. The first argument of the builder allows you to add extra -D arguments to the Maven build command, if a value is defined it will add -Dname=value , otherwise it will add -Dname . The second argument will indicate where the build goal can find the artifact produced by the build. This is the artifact that for example can be used in other goals like deployment. By default, it will look in the default location as defined by Maven conventions, i.e. target/artifact-version.jar , but you can change this if you like. Aside from an in-process Maven build, Atomist also provides a dockerized Maven builder, which is defined as such export function dockerizedMavenBuilder ( version : string = DefaultMavenDockerVersion , args : Array < { name : string , value? : string } > = [], deploymentUnitFileLocator : ( p : LocalProject , mpi : VersionedArtifact ) => string = ( p , mpi ) => ` ${ p . baseDir } /target/ ${ mpi . artifact } - ${ mpi . version } .jar` ) : Builder In addition to the same options as the in-process Maven builder, the dockerized version also allows you to define a version. Upon goal execution, this builder will use a docker run command to invoke Maven. In other words, you don\u2019t need to have a Maven installation on the SDM or have your project configured to use the Maven wrapper. Danger If you\u2019re running your SDM in Docker, please take care to take into account the Docker-in-Docker or the Docker-outside-of-Docker guidelines if you use the dockerized Maven builder Gradle Atomist also provide support for building projects using Gradle. At the moment, only single module projects are supported. To use the Gradle integration, configure your Build goal like this using the gradleSingleModuleBuilder in sdm-pack-spring : const build = new Build (). with ({ name : \"gradle build\" , builder : gradleSingleModuleBuilder (), }); The Maven builder will issue a gradle clean build (or use gradlew if that\u2019s available in the project) command to build your project. npm If you want to build NodeJS projects using npm, Atomist can certainly help you with that. In order to do so, define your Build goal like this, using the nodeBuilder available in @atomist/sdm-pack-node : const build = new Build (). with ({ name : \"npm\" , builder : nodeBuilder ( \"run\" , \"build\" ), }); In this case the builder will execute an npm run build command in the root of your project. Linking the artifact produced by the build In order to capture the output deliverable of a build you can use the Artifact goal. When added to a goalset, it will be fulfilled by the Build goal after successful completion of a build that is able to store the artifact in a more permanent store. The Artifact goal will also contain a link to the deliverable, which will be displayed next to the goal indicator in the messaging channel.","title":"Build Goal"},{"location":"developer/build/#the-build-goal","text":"Atomist provides a goal that is designed to handle building software: the Build goal. It lives in the Build Pack , so run npm install @atomist/sdm-pack-build to get it. The build goal does a couple things: Invoke a builder that builds your project Link the built artifact, associating it to the commit Get one by calling the Build constructor. If you want it to appear as something more specific than \u201cbuild\u201d, pass a displayName in its options. const build = new Build ({ displayName : \"maven build\" }). with ({ name : \"maven\" , builder : mavenBuilder (), }); This goal defines a build that will be handled by Maven. Be sure to add the goal to your goal set . The trick is: you need a Builder .","title":"The Build goal"},{"location":"developer/build/#builders","text":"Builders implement the logic that is needed to build your software. Out of the box, Atomist provides a couple of builders for: Maven Gradle NodeJS using npm Generic builder that calls a terminal script You can also create your own. A builder is a function that gets a GoalInvocation and a build number and return a Promise<BuildInProgress> ( goalInvocation : GoalInvocation , buildNo : string ) => Promise < BuildInProgress >","title":"Builders"},{"location":"developer/build/#builds-handled-by-external-systems","text":"In addition to handling the CI lifecycle itself, Atomist can also defer the build to external systems like your existing CI lifecycle. To achieve this, you need to define your build goal like this: const build = new Build ({ displayName : \"Travis build\" }). with ({ name : \"maven\" , externalTool : \"travis\" }); You can find more detailed information on how to hook up existing CI systems on the integrations page .","title":"Builds handled by external systems"},{"location":"developer/build/#atomist-builders","text":"Atomist does not build your software. You have a build tool that does that. Atomist spawns a process to call your build tool. The Builder knows the command to run, along with how to parse the log file. Here are some handy builders that are already available. For anything else, start with a general spawnBuilder .","title":"Atomist builders"},{"location":"developer/build/#maven","text":"Maven builds are supported out of the box through the mavenBuilder found in sdm-pack-spring . The builder is defined as such export function mavenBuilder ( args : Array < { name : string , value? : string } > = [], deploymentUnitFileLocator : ( p : LocalProject , mpi : VersionedArtifact ) => string = ( p , mpi ) => ` ${ p . baseDir } /target/ ${ mpi . artifact } - ${ mpi . version } .jar` ) : Builder The Maven builder will issue a mvn package (or use mvnw if that\u2019s available in the project) command to build your project. The first argument of the builder allows you to add extra -D arguments to the Maven build command, if a value is defined it will add -Dname=value , otherwise it will add -Dname . The second argument will indicate where the build goal can find the artifact produced by the build. This is the artifact that for example can be used in other goals like deployment. By default, it will look in the default location as defined by Maven conventions, i.e. target/artifact-version.jar , but you can change this if you like. Aside from an in-process Maven build, Atomist also provides a dockerized Maven builder, which is defined as such export function dockerizedMavenBuilder ( version : string = DefaultMavenDockerVersion , args : Array < { name : string , value? : string } > = [], deploymentUnitFileLocator : ( p : LocalProject , mpi : VersionedArtifact ) => string = ( p , mpi ) => ` ${ p . baseDir } /target/ ${ mpi . artifact } - ${ mpi . version } .jar` ) : Builder In addition to the same options as the in-process Maven builder, the dockerized version also allows you to define a version. Upon goal execution, this builder will use a docker run command to invoke Maven. In other words, you don\u2019t need to have a Maven installation on the SDM or have your project configured to use the Maven wrapper. Danger If you\u2019re running your SDM in Docker, please take care to take into account the Docker-in-Docker or the Docker-outside-of-Docker guidelines if you use the dockerized Maven builder","title":"Maven"},{"location":"developer/build/#gradle","text":"Atomist also provide support for building projects using Gradle. At the moment, only single module projects are supported. To use the Gradle integration, configure your Build goal like this using the gradleSingleModuleBuilder in sdm-pack-spring : const build = new Build (). with ({ name : \"gradle build\" , builder : gradleSingleModuleBuilder (), }); The Maven builder will issue a gradle clean build (or use gradlew if that\u2019s available in the project) command to build your project.","title":"Gradle"},{"location":"developer/build/#npm","text":"If you want to build NodeJS projects using npm, Atomist can certainly help you with that. In order to do so, define your Build goal like this, using the nodeBuilder available in @atomist/sdm-pack-node : const build = new Build (). with ({ name : \"npm\" , builder : nodeBuilder ( \"run\" , \"build\" ), }); In this case the builder will execute an npm run build command in the root of your project.","title":"npm"},{"location":"developer/build/#linking-the-artifact-produced-by-the-build","text":"In order to capture the output deliverable of a build you can use the Artifact goal. When added to a goalset, it will be fulfilled by the Build goal after successful completion of a build that is able to store the artifact in a more permanent store. The Artifact goal will also contain a link to the deliverable, which will be displayed next to the goal indicator in the messaging channel.","title":"Linking the artifact produced by the build"},{"location":"developer/cli/","text":"The Atomist command line is useful for starting SDMs and configuring your connection. In local mode , the atomist command line runs commands in your SDM. help Run atomist --help to see a list of options. Since atomist can run multi-word commands, only the first word of each is listed in the help. Drill down by asking for more specific help. For instance, atomist --help yields (among other lines): atomist show ... 2 commands To find out what you can show, use atomist show --help . Commands: atomist show sdms Show connected sdms atomist show skills Show skills atomist start Run your SDM! In your SDM\u2019s project directory, atomist start will start it up. By default, it starts in team mode . Here are some important options: \u2013local Run in local mode \u2013no-compile By default, atomist start will compile the project. Use this option to skip that step. \u2013change-dir >dir< Run an SDM that\u2019s in another directory. After you start an SDM, leave it running in that terminal. The logs print to the screen. atomist config This will prompt you to set up the connection parameters for an SDM in team mode. See Configuration for more. Local Mode These commands are relevant to running SDMs in local mode, along with atomist start --local . atomist feed When an SDM runs in local mode, it cannot send messages to people in chat. Instead, it sends them to the feed . The feed is an instance of the Atomist command line (run as atomist feed ) that stays open listening for messages from local-mode SDMs and printing them. When you run commands or make commits locally, the feed prints information. In chat, messages from Atomist can have buttons. The buttons trigger more commands. In the terminal, the feed gives you URLs instead. Open them (command-click if you\u2019re in iTerm2 on a Mac) to \u201cpush the button\u201d. When the button-links open in a browser, the browser displays only an acknowledgement; the useful responses to the command show up in the feed again. Projects in the Atomist projects root Local SDMs work with projects in the Atomist projects root (usually $HOME/atomist/projects ). For an SDM to respond to commits, these projects also need git hooks installed. Fetch a project with atomist clone to get it in the right place with the right hooks. Or if you\u2019ve already cloned a project, use atomist add git hooks to set up triggering. atomist clone atomist clone <git url> : clone a repository into the right place in the Atomist project root (~/atomist/projects/OWNER/REPO) and install git hooks that send commit events to an SDM running in local mode. atomist add git hooks In an existing cloned project, this adds git hooks to send commit events to an SDM running in local mode. The project still needs to in the right directory location. If you already have git hooks, this will add to them. If you didn\u2019t have any, this creates the files in .git/hooks . atomist remove git hooks Remove the git hooks that atomist added, if any. atomist replay post-commit This sends a notification to any running SDMs about the most recent commit, as if you had just committed it. This is useful if your SDM was not running when that commit happened. It\u2019s also great for testing your SDM repeatedly.","title":"Command Line Interface"},{"location":"developer/cli/#help","text":"Run atomist --help to see a list of options. Since atomist can run multi-word commands, only the first word of each is listed in the help. Drill down by asking for more specific help. For instance, atomist --help yields (among other lines): atomist show ... 2 commands To find out what you can show, use atomist show --help . Commands: atomist show sdms Show connected sdms atomist show skills Show skills","title":"help"},{"location":"developer/cli/#atomist-start","text":"Run your SDM! In your SDM\u2019s project directory, atomist start will start it up. By default, it starts in team mode . Here are some important options: \u2013local Run in local mode \u2013no-compile By default, atomist start will compile the project. Use this option to skip that step. \u2013change-dir >dir< Run an SDM that\u2019s in another directory. After you start an SDM, leave it running in that terminal. The logs print to the screen.","title":"atomist start"},{"location":"developer/cli/#atomist-config","text":"This will prompt you to set up the connection parameters for an SDM in team mode. See Configuration for more.","title":"atomist config"},{"location":"developer/cli/#local-mode","text":"These commands are relevant to running SDMs in local mode, along with atomist start --local .","title":"Local Mode"},{"location":"developer/cli/#atomist-feed","text":"When an SDM runs in local mode, it cannot send messages to people in chat. Instead, it sends them to the feed . The feed is an instance of the Atomist command line (run as atomist feed ) that stays open listening for messages from local-mode SDMs and printing them. When you run commands or make commits locally, the feed prints information. In chat, messages from Atomist can have buttons. The buttons trigger more commands. In the terminal, the feed gives you URLs instead. Open them (command-click if you\u2019re in iTerm2 on a Mac) to \u201cpush the button\u201d. When the button-links open in a browser, the browser displays only an acknowledgement; the useful responses to the command show up in the feed again.","title":"atomist feed"},{"location":"developer/cli/#projects-in-the-atomist-projects-root","text":"Local SDMs work with projects in the Atomist projects root (usually $HOME/atomist/projects ). For an SDM to respond to commits, these projects also need git hooks installed. Fetch a project with atomist clone to get it in the right place with the right hooks. Or if you\u2019ve already cloned a project, use atomist add git hooks to set up triggering.","title":"Projects in the Atomist projects root"},{"location":"developer/cli/#atomist-clone","text":"atomist clone <git url> : clone a repository into the right place in the Atomist project root (~/atomist/projects/OWNER/REPO) and install git hooks that send commit events to an SDM running in local mode.","title":"atomist clone"},{"location":"developer/cli/#atomist-add-git-hooks","text":"In an existing cloned project, this adds git hooks to send commit events to an SDM running in local mode. The project still needs to in the right directory location. If you already have git hooks, this will add to them. If you didn\u2019t have any, this creates the files in .git/hooks .","title":"atomist add git hooks"},{"location":"developer/cli/#atomist-remove-git-hooks","text":"Remove the git hooks that atomist added, if any.","title":"atomist remove git hooks"},{"location":"developer/cli/#atomist-replay-post-commit","text":"This sends a notification to any running SDMs about the most recent commit, as if you had just committed it. This is useful if your SDM was not running when that commit happened. It\u2019s also great for testing your SDM repeatedly.","title":"atomist replay post-commit"},{"location":"developer/commands/","text":"In an Software Delivery Machine (SDM) , a command is an action that can be triggered on demand, either from the command line in local mode , from chat in team mode , or in the Atomist web interface. This can be any action that you write in a TypeScript function. What would you like your team to do more frequently or more consistently? This page will show you how to: create a command test your command respond to the person who invoked the command wrap a shell script in a command define parameters for your command This page starts after you have created an SDM. Create a command First, we\u2019ll write the function for our command. For this example, we will write the classic \u201chello, world\u201d function. To be able to respond regardless of whether the command was invoked on the command line, in chat, or the web interface, we need to learn a little about what a command function looks like. We call these command functions \u201clisteners\u201d, because they are always listening for someone to call them. All command listeners take a single argument, a CommandListenerInvocation , which provides some useful information to the command, like how to respond to the person who invoked the command. Command listeners are asynchronous functions, returning a Promise . The Promise contains an object with at least a code property, whose value is a number . A code of zero means success. If the code is non-zero, the command execution is considered unsuccessful. Armed with this information, we can write our command listener function. import { HandlerResult , NoParameters } from \"@atomist/automation-client\" ; import { CommandListenerInvocation } from \"@atomist/sdm\" ; export async function helloWorldListener ( ci : CommandListenerInvocation < NoParameters > ) : Promise < HandlerResult > { return ci . addressChannels ( \"Hello, world\" ); } You can see the CommandListenerInvocation has an addressChannels property, which sends a message to the appropriate places \u2013 in this case, to wherever the command was invoked. Like much of the API, this is an asynchronous function. Register your command The next thing to do is register your command in your SDM. First, we create a CommandHandlerRegistration . import { CommandHandlerRegistration } from \"@atomist/sdm\" ; const helloWorldCommand : CommandHandlerRegistration = { name : \"HelloWorld\" , description : \"Responds with a friendly greeting to everyone\" , intent : \"hello\" , listener : async ci => { await ci . addressChannels ( \"Hello, world\" ); return { code : 0 }; }, }; We provide a unique name and description in the registration. The value of the intent property defines the command you enter to invoke the command listener function. Here we have defined our function inline. In the test, we would also have to update the invocation of the command to helloWorldCommand.listener(ci) . Once we have the registration, we can add the command to our SDM object. import { Configuration } from \"@atomist/automation-client\" ; import { SoftwareDeliveryMachine , SoftwareDeliveryMachineConfiguration , } from \"@atomist/sdm\" ; import { createSoftwareDeliveryMachine , configureSdm , } from \"@atomist/sdm-core\" ; function machine ( configuration : SoftwareDeliveryMachineConfiguration ) : SoftwareDeliveryMachine { const sdm = createSoftwareDeliveryMachine ({ name : \"My SDM\" , configuration , }); sdm . addCommand ( helloWorldCommand ); return sdm ; } export const configuration : Configuration = { postProcessors : [ configureSdm ( machine )], }; The configuration object should be exported from the index.ts of your SDM. Run your command If you are running your SDM in local mode, start the SDM as you normally would atomist start --local and then in another terminal run the hello command: atomist hello and the SDM should respond in the same terminal. In team mode, once you have started your SDM you can send the intent to the Atomist bot @atomist hello and it will respond back to you in the channel. In chat, you can send @atomist describe skill \"hello\" to see details of your command and its parameters. Wrap a shell script If you want to turn a shell script into a bot command, just call that shell script from a command listener. You can use the execPromise helper to capture the output and respond back with it. import { execPromise } from \"@atomist/automation-client\" ; import { CommandHandlerRegistration } from \"@atomist/sdm\" ; const myScriptCommand : CommandHandlerRegistration = { name : \"MyScript\" , description : \"Run my-script and respond with its stdout\" , intent : \"my script\" , listener : async ci => { const result = await execPromise ( \"my-script\" , [ \"its\" , \"args\" ]); return ci . addressChannels ( result . stdout ); }, }; See also: Running external commands Command parameters Command parameters give you extra information that can be different each time the command runs. By default, commands not require parameters. However, you can specify parameters to be gathered in chat by the Atomist bot or via the web interface or CLI. These parameters can be accessed in a typesafe manner. To specify commands, use the optional parameters property when creating a command. Let\u2019s make our hello command welcome us by name to wherever we are. Defining parameters Start by defining the parameters. A parameter definition object maps the name of each parameter to optional details. Pass it to the command registration so that it will know what parameters to gather. const helloWorldParametersDefinition = { name : { description : \"name\" , required : true , pattern : /.*/ , }, location : {}, }; const helloWorldCommand : CommandHandlerRegistration < { name : string , location : string } > = { name : \"HelloWorld\" , description : \"Responds with a friendly greeting to everyone\" , intent : \"hello\" , parameters : helloWorldParametersDefinition , listener : async ci => { return ci . addressChannels ( `Welcome to ${ ci . parameters . location } , ${ ci . parameters . name } ` ); }, }; Atomist will now prompt anyone who invokes this command for name and location . In this case any value will be accepted, but we can use regular expressions to ensure that valid values are submitted. The helloWorldParametersDefinition object has one property for each parameter. Each property\u2019s name is the name of the parameter, and its value describes the parameter. These options are available in the parameter definition (all optional): attribute type description default description string short description same as name pattern RegExp regular expression that the parameter\u2019s value must match match any single line string ( ^.*$ ) required boolean is the parameter required? false displayName string name to display; may contain spaces same as name validInput string describe what makes a valid parameter value blank displayable boolean whether to show a parameter value after it\u2019s been entered true maxLength number maximum number of characters to accept no maximum minLength number minmum number of characters needed 0 type ParameterType string, boolean, number, or Chooser string order number when prompting, ask for smaller \u2018order\u2019 parameters first order doesn\u2019t matter group Group when prompting, put parameters in the same Group together none control \u201cinput\u201d or \u201ctextarea\u201d input type for string parameters in dialogues \u201cinput\u201d We can combine parameter definitions using spreads. For example, this will also bring in some common parameters defined in another object constant: parameters : { ... CommonParameters , name : { description : \"name\" , required : true , pattern : /.*/ , }, body : { description : \"multi line body text\" , required : true , pattern : /[\\s\\S]*/ , control : \"textarea\" } location : {}, }, The property definition mechanism applies to all commands, so you can apply it to code inspections and code transform commands. Accessing parameters in the command The CommandHandlerRegistration type is parameterized by the type of the properties object. In this case it\u2019s the anonymous type { name: string, location: string } , but in more complex scenarios we\u2019d use an interface. By default, no parameters are exposed. We access the parameter values in the listener via the parameters property, as in ci.parameters.name : listener : async ci => { return ci . addressChannels ( `Welcome to ${ ci . parameters . location } , ${ ci . parameters . name } ` ); }, Test your command Testing your command listener requires that you mock the parts of CommandListenerInvocation you use and then call your function. Using the Mocha testing framework, it would look something like this. import { NoParameters } from \"@atomist/automation-client\" ; import { CommandListenerInvocation } from \"@atomist/sdm\" ; import * as assert from \"assert\" ; describe ( \"helloWorldListener\" , () => { it ( \"should respond successfully\" , async () => { let response : string ; const ci : CommandListenerInvocation < NoParameters > = { addressChannels : async ( m : string ) => response = m , }; const result = await helloWorldListener ( ci ); assert ( result ); assert ( result . code === 0 ); assert ( response === \"Hello, world\" ); }); }); We assign the message sent to the response property so we can later confirm it was the message we expected. What else would you like to do? What is missing from this page? Please tell me! There\u2019s a #docs channel in Atomist community Slack , or you can create an issue on this repository .","title":"Commands"},{"location":"developer/commands/#create-a-command","text":"First, we\u2019ll write the function for our command. For this example, we will write the classic \u201chello, world\u201d function. To be able to respond regardless of whether the command was invoked on the command line, in chat, or the web interface, we need to learn a little about what a command function looks like. We call these command functions \u201clisteners\u201d, because they are always listening for someone to call them. All command listeners take a single argument, a CommandListenerInvocation , which provides some useful information to the command, like how to respond to the person who invoked the command. Command listeners are asynchronous functions, returning a Promise . The Promise contains an object with at least a code property, whose value is a number . A code of zero means success. If the code is non-zero, the command execution is considered unsuccessful. Armed with this information, we can write our command listener function. import { HandlerResult , NoParameters } from \"@atomist/automation-client\" ; import { CommandListenerInvocation } from \"@atomist/sdm\" ; export async function helloWorldListener ( ci : CommandListenerInvocation < NoParameters > ) : Promise < HandlerResult > { return ci . addressChannels ( \"Hello, world\" ); } You can see the CommandListenerInvocation has an addressChannels property, which sends a message to the appropriate places \u2013 in this case, to wherever the command was invoked. Like much of the API, this is an asynchronous function.","title":"Create a command"},{"location":"developer/commands/#register-your-command","text":"The next thing to do is register your command in your SDM. First, we create a CommandHandlerRegistration . import { CommandHandlerRegistration } from \"@atomist/sdm\" ; const helloWorldCommand : CommandHandlerRegistration = { name : \"HelloWorld\" , description : \"Responds with a friendly greeting to everyone\" , intent : \"hello\" , listener : async ci => { await ci . addressChannels ( \"Hello, world\" ); return { code : 0 }; }, }; We provide a unique name and description in the registration. The value of the intent property defines the command you enter to invoke the command listener function. Here we have defined our function inline. In the test, we would also have to update the invocation of the command to helloWorldCommand.listener(ci) . Once we have the registration, we can add the command to our SDM object. import { Configuration } from \"@atomist/automation-client\" ; import { SoftwareDeliveryMachine , SoftwareDeliveryMachineConfiguration , } from \"@atomist/sdm\" ; import { createSoftwareDeliveryMachine , configureSdm , } from \"@atomist/sdm-core\" ; function machine ( configuration : SoftwareDeliveryMachineConfiguration ) : SoftwareDeliveryMachine { const sdm = createSoftwareDeliveryMachine ({ name : \"My SDM\" , configuration , }); sdm . addCommand ( helloWorldCommand ); return sdm ; } export const configuration : Configuration = { postProcessors : [ configureSdm ( machine )], }; The configuration object should be exported from the index.ts of your SDM.","title":"Register your command"},{"location":"developer/commands/#run-your-command","text":"If you are running your SDM in local mode, start the SDM as you normally would atomist start --local and then in another terminal run the hello command: atomist hello and the SDM should respond in the same terminal. In team mode, once you have started your SDM you can send the intent to the Atomist bot @atomist hello and it will respond back to you in the channel. In chat, you can send @atomist describe skill \"hello\" to see details of your command and its parameters.","title":"Run your command"},{"location":"developer/commands/#wrap-a-shell-script","text":"If you want to turn a shell script into a bot command, just call that shell script from a command listener. You can use the execPromise helper to capture the output and respond back with it. import { execPromise } from \"@atomist/automation-client\" ; import { CommandHandlerRegistration } from \"@atomist/sdm\" ; const myScriptCommand : CommandHandlerRegistration = { name : \"MyScript\" , description : \"Run my-script and respond with its stdout\" , intent : \"my script\" , listener : async ci => { const result = await execPromise ( \"my-script\" , [ \"its\" , \"args\" ]); return ci . addressChannels ( result . stdout ); }, }; See also: Running external commands","title":"Wrap a shell script"},{"location":"developer/commands/#command-parameters","text":"Command parameters give you extra information that can be different each time the command runs. By default, commands not require parameters. However, you can specify parameters to be gathered in chat by the Atomist bot or via the web interface or CLI. These parameters can be accessed in a typesafe manner. To specify commands, use the optional parameters property when creating a command. Let\u2019s make our hello command welcome us by name to wherever we are.","title":"Command parameters"},{"location":"developer/commands/#defining-parameters","text":"Start by defining the parameters. A parameter definition object maps the name of each parameter to optional details. Pass it to the command registration so that it will know what parameters to gather. const helloWorldParametersDefinition = { name : { description : \"name\" , required : true , pattern : /.*/ , }, location : {}, }; const helloWorldCommand : CommandHandlerRegistration < { name : string , location : string } > = { name : \"HelloWorld\" , description : \"Responds with a friendly greeting to everyone\" , intent : \"hello\" , parameters : helloWorldParametersDefinition , listener : async ci => { return ci . addressChannels ( `Welcome to ${ ci . parameters . location } , ${ ci . parameters . name } ` ); }, }; Atomist will now prompt anyone who invokes this command for name and location . In this case any value will be accepted, but we can use regular expressions to ensure that valid values are submitted. The helloWorldParametersDefinition object has one property for each parameter. Each property\u2019s name is the name of the parameter, and its value describes the parameter. These options are available in the parameter definition (all optional): attribute type description default description string short description same as name pattern RegExp regular expression that the parameter\u2019s value must match match any single line string ( ^.*$ ) required boolean is the parameter required? false displayName string name to display; may contain spaces same as name validInput string describe what makes a valid parameter value blank displayable boolean whether to show a parameter value after it\u2019s been entered true maxLength number maximum number of characters to accept no maximum minLength number minmum number of characters needed 0 type ParameterType string, boolean, number, or Chooser string order number when prompting, ask for smaller \u2018order\u2019 parameters first order doesn\u2019t matter group Group when prompting, put parameters in the same Group together none control \u201cinput\u201d or \u201ctextarea\u201d input type for string parameters in dialogues \u201cinput\u201d We can combine parameter definitions using spreads. For example, this will also bring in some common parameters defined in another object constant: parameters : { ... CommonParameters , name : { description : \"name\" , required : true , pattern : /.*/ , }, body : { description : \"multi line body text\" , required : true , pattern : /[\\s\\S]*/ , control : \"textarea\" } location : {}, }, The property definition mechanism applies to all commands, so you can apply it to code inspections and code transform commands.","title":"Defining parameters"},{"location":"developer/commands/#accessing-parameters-in-the-command","text":"The CommandHandlerRegistration type is parameterized by the type of the properties object. In this case it\u2019s the anonymous type { name: string, location: string } , but in more complex scenarios we\u2019d use an interface. By default, no parameters are exposed. We access the parameter values in the listener via the parameters property, as in ci.parameters.name : listener : async ci => { return ci . addressChannels ( `Welcome to ${ ci . parameters . location } , ${ ci . parameters . name } ` ); },","title":"Accessing parameters in the command"},{"location":"developer/commands/#test-your-command","text":"Testing your command listener requires that you mock the parts of CommandListenerInvocation you use and then call your function. Using the Mocha testing framework, it would look something like this. import { NoParameters } from \"@atomist/automation-client\" ; import { CommandListenerInvocation } from \"@atomist/sdm\" ; import * as assert from \"assert\" ; describe ( \"helloWorldListener\" , () => { it ( \"should respond successfully\" , async () => { let response : string ; const ci : CommandListenerInvocation < NoParameters > = { addressChannels : async ( m : string ) => response = m , }; const result = await helloWorldListener ( ci ); assert ( result ); assert ( result . code === 0 ); assert ( response === \"Hello, world\" ); }); }); We assign the message sent to the response property so we can later confirm it was the message we expected.","title":"Test your command"},{"location":"developer/commands/#what-else-would-you-like-to-do","text":"What is missing from this page? Please tell me! There\u2019s a #docs channel in Atomist community Slack , or you can create an issue on this repository .","title":"What else would you like to do?"},{"location":"developer/config/","text":"Configure your SDM with connection parameters for the Atomist API for software, and for anything else that your particular delivery automations need. Initialize your SDM configuration by running atomist config as instructed in prerequisites . The configuration file, typically located under your home/user profile directory at .atomist/client.config.json . It is a standard JSON file. To connect to the Atomist service, it will look something like: { \"apiKey\" : \"ABCDEF0123456789ABCDEF0123456789ABCDEF0123456789\" , \"workspaceIds\" : [ \"A0421WAYA\" , ] } The apiKey is your Atomist API key and workspaceIds are the Atomist IDs of the workspaces where you want to run your team SDMs. If you want to change the API key or add/remove workspaces, you can edit this file directly. The configuration values in your index.ts file will override those from your user configuration. You can list environment variables in your configuration. The SDM will substitute environment variable values in expressions when you write them like ${ENV_VAR} . For example: { ... \"sdm\" : { \"docker\" : { \"host\" : \"registry.hub.docker.com\" , \"password\" : \"${DOCKER_PASSWORD}\" } } } For the full list of configuration sources, see the API doc . The full list of configuration values are here .","title":"SDM Configuration"},{"location":"developer/create/","text":"Automated project creation saves time and ensures that you start new services, libraries and other projects with good solid code that meets your standards and includes the components you need, configured the way you like them. In Atomist, you automate project creation using a generator, a type of command . Generators typically copy their code from a known-good repository called a seed, and then modify the code in certain ways, such as renaming classes so that it\u2019s ready to use without lots of manual find and replace. Generators frequently also configure supporting systems, for example, by creating a dedicated Slack channel, setting up issue tracking, and so on. To make your own generator, get an SDM of your own. In team mode, the SDM hooks your generator up to chat and creates repositories in your version control. You can also add a custom form to serve project creation to your team or organization. In local mode, the SDM creates a directory on your filesytem. This page gives you enough information to create a generator from your own seed with your own transforms and custom parameters Seed A seed is a project that works as a starting point. It is real, functional code, not a template. The simplest generator makes a copy of the seed in a new repository; most generators transform the code first. You can use any project you already have, or craft one carefully for new projects to start from. This makes a canonical \u201cbest starting point\u201d for your organization. For examples, see all the repositories in our atomist-seeds organization . Generator Registration To add a generator to your SDM, register it where you configure your SDM (usually machine.ts ): sdm . addGeneratorCommand ( MkdocsSiteGenerator ); The sample code on this page is about a generator for starting a new documentation site like this one. That MkdocsSiteGenerator is a [GeneratorRegistration][apidoc-generator-registration] : export const MkdocsSiteGenerator : GeneratorRegistration = { name : \"Mkdocs Site\" , intent : \"create mkdocs site\" , startingPoint : GitHubRepoRef.from ({ owner : \"atomist-seeds\" , repo : \"mkdocs-site\" }), transform : [ updateTitle ( \"README.md\" , \"New Project\" )], } The important elements of a GeneratorRegistration are: name of the generator. This can be any string. intent a string or array of strings; type this to trigger the command. startingPoint gives the generator a seed. Use a pointer to a repository in version control - see RepoRef for options. transform is an array of zero or more code transforms to apply. Parameters Generator commands work the same way as command parameters . In addition, a generator command automatically gets some parameters that every generator needs: attribute type description default target.description string description for the new repository \u201d\u201c target.repo string new repository name none target.visibility \u201cpublic\u201d or \u201cprivate\u201d what kind of visibility a new repository gets \u201cprivate\u201d","title":"Project Generators"},{"location":"developer/create/#seed","text":"A seed is a project that works as a starting point. It is real, functional code, not a template. The simplest generator makes a copy of the seed in a new repository; most generators transform the code first. You can use any project you already have, or craft one carefully for new projects to start from. This makes a canonical \u201cbest starting point\u201d for your organization. For examples, see all the repositories in our atomist-seeds organization .","title":"Seed"},{"location":"developer/create/#generator-registration","text":"To add a generator to your SDM, register it where you configure your SDM (usually machine.ts ): sdm . addGeneratorCommand ( MkdocsSiteGenerator ); The sample code on this page is about a generator for starting a new documentation site like this one. That MkdocsSiteGenerator is a [GeneratorRegistration][apidoc-generator-registration] : export const MkdocsSiteGenerator : GeneratorRegistration = { name : \"Mkdocs Site\" , intent : \"create mkdocs site\" , startingPoint : GitHubRepoRef.from ({ owner : \"atomist-seeds\" , repo : \"mkdocs-site\" }), transform : [ updateTitle ( \"README.md\" , \"New Project\" )], } The important elements of a GeneratorRegistration are: name of the generator. This can be any string. intent a string or array of strings; type this to trigger the command. startingPoint gives the generator a seed. Use a pointer to a repository in version control - see RepoRef for options. transform is an array of zero or more code transforms to apply.","title":"Generator Registration"},{"location":"developer/create/#parameters","text":"Generator commands work the same way as command parameters . In addition, a generator command automatically gets some parameters that every generator needs: attribute type description default target.description string description for the new repository \u201d\u201c target.repo string new repository name none target.visibility \u201cpublic\u201d or \u201cprivate\u201d what kind of visibility a new repository gets \u201cprivate\u201d","title":"Parameters"},{"location":"developer/deploy/","text":"Deployment is the goal of delivery, so you probably want a deployment goal . We have some pre-built ones: Kubernetes Cloud Foundry Use these, fork these and change them, or program your deployment in a custom goal . Set them along with other goals in your delivery flows.","title":"Deploys"},{"location":"developer/event/","text":"SDM supported events In an SDM, there are several built-in events that you can take action on. You can also make a custom event subscription. Most of these work only in team mode; the local SDM only hears about push events. Goal-related listeners do work in local mode. To respond to these events, register a listener with a function to run in response. Each listener function receives a ListenerInvocation containing general context and specific information about that event. This page shows you how to: write a listener function for many different events register that listener with your SDM Generally, you\u2019ll configure listeners inside your machine function . Repository Creation (team mode only) This fires when a repository is first created in your version control manager. The repository might not have code yet! If you want to respond to a repository with code in it, register a first push listener . This is a good time to add standard labels to the repository, give read-only access to your whole organization, or announce its existence in chat. Create a function that accepts a RepoCreationListenerInvocation . In addition to the standard RepoContext , this invocation has a repo field with owner and name. (You could also use the standard id field.) The addressChannels method won\u2019t do anything, as the repository is not yet linked to any chat channels. Pass this function to sdm.addRepoCreationListener . First Push (team mode only) This fires the first time code is pushed to a new repository. This is a good time to look at the code in the repository, and send messages to chat that offer to upgrade it or add a deployment spec. Note that sometimes the repository has not been linked to a channel yet, so addressChannels won\u2019t have anywhere to go. Create a function that accepts a PushListenerInvocation . In addition to the standard RepoContext , this invocation has push and project . If you want to check whether there are any channels linked, you could look in pushListenerInvocation.push.repo.channels . If that is empty, there are no channels linked yet. You might consider implementing a Channel Link listener to send messages about a new repository. Pass this function to sdm.addFirstPushListener . Repo Onboarding (team mode only) This fires when a repository formerly not watched by Atomist is brought into our purvey, like when we add a webhook to a new organization. You might want to do similar things to a FirstPushListener. Create a function that accepts a ProjectListenerInvocation . In addition to the standard RepoContext project , giving you access to the code in the repository. Pass this function to sdm.addRepoOnboardingListener . Goal Events These work in local mode as well as team mode, since they happen around Goals . Goals Set Once per push, the goals are chosen. This subscription fires after that happens. Create a function that accepts a GoalsSetListenerInvocation . In addition to the standard RepoContext , this invocation has push and fields about the goals that were set: goalSet , goalSetId , and goalSetName . Pass this function to sdm.addGoalsSetListener . Goal Execution This fires for every goal, before and after execution in your SDM. You can notify a person when a goal completes, or send a message to a logging system, for instance. Create a function that accepts a GoalExecutionListenerInvocation . In addition to the standard RepoContext , this invocation has goalEvent property. Check its state to see whether the goal is in_process , successful, or failed. Pass this function to sdm.addGoalExecutionListener . Goal Completion (team mode only) This fires when a goal created by your SDM is completed, even if the goal is implemented in another SDM. In most cases, you probably want a goal execution listener instead. Create a function that accepts a GoalCompletionListenerInvocation . In addition to the standard RepoContext , this invocation has [ completedGoal ] field, which is an SdmGoalEvent . Check its state to see whether the goal completed successfully. Pass this function to sdm.addGoalCompletionListener . Channels A repository can be linked to a chat channel. Then, the addressChannel method in the invocation object passed to listeners will post messages to all channels linked to the repository in the event. There are also some events around chat channels that you can subscribe to in your SDM. Channel Link (team mode only) This fires when a repository is linked to a chat channel. Create a function that accepts a ChannelLinkListenerInvocation . In addition to the standard SdmContext , this invocation has project and newlyLinkedChannelName . There is also a handy method to send messages: addressNewlyLinkedChannel . Pass this function to sdm.addChannelLinkListener . User Joined Channel (team mode only) When a user joins a channel that is linked to at least one repository, your SDM can respond to it. Create a function that accepts a UserJoiningChannelListenerInvocation . In addition to an SdmContext , this invocation has joinEvent , which contains data about the user and channel, and repos , an array of identifiers for all the linked repositories. Pass this function to sdm.addUserJoiningChannelListener . Issues Currently, these events fire for GitHub issues. They work with GitHub.com and GitHub Enterprise. New Issue (team mode only) When a new issue is created, you might want to capitalize its title, or complain if it doesn\u2019t have a description. You might want to add labels to it. This is a good place to action some organizational policies. Create a function that accepts a NewIssueListenerInvocation . In addition to the standard RepoContext , this invocation has issue , with fields selected in this GraphQL . Pass this function to sdm.addNewIssueListener . Issue Updated (team mode only) When an issue changes, you might want to update some other system. Create a function that accepts a UpdatedIssueListenerInvocation . In addition to the standard RepoContext , this invocation has issue , with fields selected in this GraphQL . Pass this function to sdm.addUpdatedIssueListener . Issue Closed (team mode only) When an issue closes, you might want to congratulate someone. Create a function that accepts a ClosedIssueListenerInvocation . In addition to the standard RepoContext , this invocation has issue , with fields selected in this GraphQL . Pass this function to sdm.addClosedIssueListener . Fingerprint Difference (team mode only) When a fingerprint is added to a push, and that fingerprint differs in value from the same fingerprint before the push, this listener gets to respond. Create a function that accepts a FingerprintDifferenceListenerInvocation . In addition to the standard RepoContext , this invocation has diffs , an array of FingerprintDifference objects containing the old and new value of each changed fingerprint. Pass this function to sdm.addFingerprintDifferenceListener . Startup (team mode only) When your SDM has completed startup, these listeners are called. This is handy for sending notifications to logging systems or to chat. Create a function that accepts a StartupListenerInvocation . This is different from most of the listener invocations. It is an AdminCommunicationContext , which has an addressAdmin method and the sdm itself as a property. Pass this function to sdm.addStartupListener . Tag (team mode only) When a tag is added to a repository, you have the opportunity to respond. Create a function that accepts a TagListenerInvocation . In addition to the standard RepoContext , this invocation has a tag Pass this function to sdm.addTagListener . Triggered This one is different: you can make a listener that is invoked at time intervals while your SDM is running. Create a function that accepts a TriggeredListenerInvocation . It is an AdminCommunicationContext , which has an addressAdmin method and the sdm itself as a property. Include this in a TriggeredListenerRegistration , along with a trigger which contains either a cron expression or an interval in milliseconds. Pass the registration to sdm.addTriggeredListener .","title":"Event Listeners"},{"location":"developer/event/#sdm-supported-events","text":"In an SDM, there are several built-in events that you can take action on. You can also make a custom event subscription. Most of these work only in team mode; the local SDM only hears about push events. Goal-related listeners do work in local mode. To respond to these events, register a listener with a function to run in response. Each listener function receives a ListenerInvocation containing general context and specific information about that event. This page shows you how to: write a listener function for many different events register that listener with your SDM Generally, you\u2019ll configure listeners inside your machine function .","title":"SDM supported events"},{"location":"developer/event/#repository-creation","text":"(team mode only) This fires when a repository is first created in your version control manager. The repository might not have code yet! If you want to respond to a repository with code in it, register a first push listener . This is a good time to add standard labels to the repository, give read-only access to your whole organization, or announce its existence in chat. Create a function that accepts a RepoCreationListenerInvocation . In addition to the standard RepoContext , this invocation has a repo field with owner and name. (You could also use the standard id field.) The addressChannels method won\u2019t do anything, as the repository is not yet linked to any chat channels. Pass this function to sdm.addRepoCreationListener .","title":"Repository Creation"},{"location":"developer/event/#first-push","text":"(team mode only) This fires the first time code is pushed to a new repository. This is a good time to look at the code in the repository, and send messages to chat that offer to upgrade it or add a deployment spec. Note that sometimes the repository has not been linked to a channel yet, so addressChannels won\u2019t have anywhere to go. Create a function that accepts a PushListenerInvocation . In addition to the standard RepoContext , this invocation has push and project . If you want to check whether there are any channels linked, you could look in pushListenerInvocation.push.repo.channels . If that is empty, there are no channels linked yet. You might consider implementing a Channel Link listener to send messages about a new repository. Pass this function to sdm.addFirstPushListener .","title":"First Push"},{"location":"developer/event/#repo-onboarding","text":"(team mode only) This fires when a repository formerly not watched by Atomist is brought into our purvey, like when we add a webhook to a new organization. You might want to do similar things to a FirstPushListener. Create a function that accepts a ProjectListenerInvocation . In addition to the standard RepoContext project , giving you access to the code in the repository. Pass this function to sdm.addRepoOnboardingListener .","title":"Repo Onboarding"},{"location":"developer/event/#goal-events","text":"These work in local mode as well as team mode, since they happen around Goals .","title":"Goal Events"},{"location":"developer/event/#goals-set","text":"Once per push, the goals are chosen. This subscription fires after that happens. Create a function that accepts a GoalsSetListenerInvocation . In addition to the standard RepoContext , this invocation has push and fields about the goals that were set: goalSet , goalSetId , and goalSetName . Pass this function to sdm.addGoalsSetListener .","title":"Goals Set"},{"location":"developer/event/#goal-execution","text":"This fires for every goal, before and after execution in your SDM. You can notify a person when a goal completes, or send a message to a logging system, for instance. Create a function that accepts a GoalExecutionListenerInvocation . In addition to the standard RepoContext , this invocation has goalEvent property. Check its state to see whether the goal is in_process , successful, or failed. Pass this function to sdm.addGoalExecutionListener .","title":"Goal Execution"},{"location":"developer/event/#goal-completion","text":"(team mode only) This fires when a goal created by your SDM is completed, even if the goal is implemented in another SDM. In most cases, you probably want a goal execution listener instead. Create a function that accepts a GoalCompletionListenerInvocation . In addition to the standard RepoContext , this invocation has [ completedGoal ] field, which is an SdmGoalEvent . Check its state to see whether the goal completed successfully. Pass this function to sdm.addGoalCompletionListener .","title":"Goal Completion"},{"location":"developer/event/#channels","text":"A repository can be linked to a chat channel. Then, the addressChannel method in the invocation object passed to listeners will post messages to all channels linked to the repository in the event. There are also some events around chat channels that you can subscribe to in your SDM.","title":"Channels"},{"location":"developer/event/#channel-link","text":"(team mode only) This fires when a repository is linked to a chat channel. Create a function that accepts a ChannelLinkListenerInvocation . In addition to the standard SdmContext , this invocation has project and newlyLinkedChannelName . There is also a handy method to send messages: addressNewlyLinkedChannel . Pass this function to sdm.addChannelLinkListener .","title":"Channel Link"},{"location":"developer/event/#user-joined-channel","text":"(team mode only) When a user joins a channel that is linked to at least one repository, your SDM can respond to it. Create a function that accepts a UserJoiningChannelListenerInvocation . In addition to an SdmContext , this invocation has joinEvent , which contains data about the user and channel, and repos , an array of identifiers for all the linked repositories. Pass this function to sdm.addUserJoiningChannelListener .","title":"User Joined Channel"},{"location":"developer/event/#issues","text":"Currently, these events fire for GitHub issues. They work with GitHub.com and GitHub Enterprise.","title":"Issues"},{"location":"developer/event/#new-issue","text":"(team mode only) When a new issue is created, you might want to capitalize its title, or complain if it doesn\u2019t have a description. You might want to add labels to it. This is a good place to action some organizational policies. Create a function that accepts a NewIssueListenerInvocation . In addition to the standard RepoContext , this invocation has issue , with fields selected in this GraphQL . Pass this function to sdm.addNewIssueListener .","title":"New Issue"},{"location":"developer/event/#issue-updated","text":"(team mode only) When an issue changes, you might want to update some other system. Create a function that accepts a UpdatedIssueListenerInvocation . In addition to the standard RepoContext , this invocation has issue , with fields selected in this GraphQL . Pass this function to sdm.addUpdatedIssueListener .","title":"Issue Updated"},{"location":"developer/event/#issue-closed","text":"(team mode only) When an issue closes, you might want to congratulate someone. Create a function that accepts a ClosedIssueListenerInvocation . In addition to the standard RepoContext , this invocation has issue , with fields selected in this GraphQL . Pass this function to sdm.addClosedIssueListener .","title":"Issue Closed"},{"location":"developer/event/#fingerprint-difference","text":"(team mode only) When a fingerprint is added to a push, and that fingerprint differs in value from the same fingerprint before the push, this listener gets to respond. Create a function that accepts a FingerprintDifferenceListenerInvocation . In addition to the standard RepoContext , this invocation has diffs , an array of FingerprintDifference objects containing the old and new value of each changed fingerprint. Pass this function to sdm.addFingerprintDifferenceListener .","title":"Fingerprint Difference"},{"location":"developer/event/#startup","text":"(team mode only) When your SDM has completed startup, these listeners are called. This is handy for sending notifications to logging systems or to chat. Create a function that accepts a StartupListenerInvocation . This is different from most of the listener invocations. It is an AdminCommunicationContext , which has an addressAdmin method and the sdm itself as a property. Pass this function to sdm.addStartupListener .","title":"Startup"},{"location":"developer/event/#tag","text":"(team mode only) When a tag is added to a repository, you have the opportunity to respond. Create a function that accepts a TagListenerInvocation . In addition to the standard RepoContext , this invocation has a tag Pass this function to sdm.addTagListener .","title":"Tag"},{"location":"developer/event/#triggered","text":"This one is different: you can make a listener that is invoked at time intervals while your SDM is running. Create a function that accepts a TriggeredListenerInvocation . It is an AdminCommunicationContext , which has an addressAdmin method and the sdm itself as a property. Include this in a TriggeredListenerRegistration , along with a trigger which contains either a cron expression or an interval in milliseconds. Pass the registration to sdm.addTriggeredListener .","title":"Triggered"},{"location":"developer/fingerprint/","text":"In team mode only , the SDM can take and react to fingerprints . Fingerprints are data computed against a push. Think of them as snapshots. Typically they reflect the state of the repository\u2019s source code after the push; they can also take into account other characteristics of the commit. Fingerprinting is valuable because: It enables us to assess the impact of a particular commit, through providing a semantic diff . For example, did the commit change dependencies? Did it change some particularly sensitive files that necessitate closer than usual review? It enables us to understand the evolution of a code base over time. Atomist persists fingerprints, so we can trace over time anything we fingerprint, and report against it. For example, what is happening to code quality metrics over time? Atomist extension packs include some out of the box fingerprints, such as Maven and npm dependency fingerprints. This page describes how to: Create a custom fingerprint Look at your fingerprints in GraphQL Report on a fingerprint React to changes in a fingerprint Create a fingerprint But it\u2019s easy to write your own. Fingerprint registrations are like other listener registrations, specifying a name and PushTest . The following example is the complete code for fingerprinting dependencies specified in a package-lock.json file: export class PackageLockFingerprinter implements FingerprinterRegistration { public readonly name = \"PackageLockFingerprinter\" ; // optional; defaults to running on any push public readonly pushTest : PushTest = IsNode ; public async action ( cri : PushImpactListenerInvocation ) : Promise < FingerprinterResult > { const lockFile = await cri . project . getFile ( \"package-lock.json\" ); if ( ! lockFile ) { return []; } try { const content = await lockFile . getContent (); const json = JSON . parse ( content ); const deps = json . dependencies ; const dstr = JSON . stringify ( deps ); return { name : \"dependencies\" , abbreviation : \"deps\" , version : \"0.1\" , sha : computeShaOf ( dstr ), data : json , }; } catch ( err ) { logger . warn ( \"Unable to compute package-lock.json fingerprint: %s\" , err . message ); return []; } } } Fingerprinters can be added to an SDM as follows: fingerprint . with ( new PackageLockFingerprinter ()); Fingerprinting will only occur if fingerprint is a Fingerprint and it is included when goals are set . When the fingerprint goal executes, it will send the fingerprint to Atomist, where it will be attached to the commit in the graph, available to the API for Software. Query a fingerprint Verify that your fingerprint worked by finding it in GraphQL. In the Atomist [web interface][] (at https://app.atomist.com ), once you are logged in, click on the GraphQL icon. Here\u2019s a query: query Fingerprint { Commit(sha: \"efbf90778 your sha goes here f1b1e7bc6\") { fingerprints { name sha } } } After the SDM is running with the new fingerprint registered, and a push is made, then substitute the 40-character git SHA of the last pushed commit for the string in the above query. If it worked, the response should include something like this: \"data\" : { \"Commit\" : [ { \"fingerprints\" : [ { \"name\" : \"YourFingerprintName\" , \"sha\" : \"efbf90778cb6403ccef71ee5e89ef13f1b1e7bc6\" } ] } ] } , Here, the sha field contains whatever you put in the sha field of your fingerprint result. The data of the fingerprint is not stored in the graph.","title":"Fingerprints"},{"location":"developer/fingerprint/#create-a-fingerprint","text":"But it\u2019s easy to write your own. Fingerprint registrations are like other listener registrations, specifying a name and PushTest . The following example is the complete code for fingerprinting dependencies specified in a package-lock.json file: export class PackageLockFingerprinter implements FingerprinterRegistration { public readonly name = \"PackageLockFingerprinter\" ; // optional; defaults to running on any push public readonly pushTest : PushTest = IsNode ; public async action ( cri : PushImpactListenerInvocation ) : Promise < FingerprinterResult > { const lockFile = await cri . project . getFile ( \"package-lock.json\" ); if ( ! lockFile ) { return []; } try { const content = await lockFile . getContent (); const json = JSON . parse ( content ); const deps = json . dependencies ; const dstr = JSON . stringify ( deps ); return { name : \"dependencies\" , abbreviation : \"deps\" , version : \"0.1\" , sha : computeShaOf ( dstr ), data : json , }; } catch ( err ) { logger . warn ( \"Unable to compute package-lock.json fingerprint: %s\" , err . message ); return []; } } } Fingerprinters can be added to an SDM as follows: fingerprint . with ( new PackageLockFingerprinter ()); Fingerprinting will only occur if fingerprint is a Fingerprint and it is included when goals are set . When the fingerprint goal executes, it will send the fingerprint to Atomist, where it will be attached to the commit in the graph, available to the API for Software.","title":"Create a fingerprint"},{"location":"developer/fingerprint/#query-a-fingerprint","text":"Verify that your fingerprint worked by finding it in GraphQL. In the Atomist [web interface][] (at https://app.atomist.com ), once you are logged in, click on the GraphQL icon. Here\u2019s a query: query Fingerprint { Commit(sha: \"efbf90778 your sha goes here f1b1e7bc6\") { fingerprints { name sha } } } After the SDM is running with the new fingerprint registered, and a push is made, then substitute the 40-character git SHA of the last pushed commit for the string in the above query. If it worked, the response should include something like this: \"data\" : { \"Commit\" : [ { \"fingerprints\" : [ { \"name\" : \"YourFingerprintName\" , \"sha\" : \"efbf90778cb6403ccef71ee5e89ef13f1b1e7bc6\" } ] } ] } , Here, the sha field contains whatever you put in the sha field of your fingerprint result. The data of the fingerprint is not stored in the graph.","title":"Query a fingerprint"},{"location":"developer/glossary/","text":"Atomist the company that produces this spectacular glossary. a development automation platform, consisting of a service, a framework, and libraries to help you automate your software delivery, your way. Atomist service the part of the Atomist platform that is operated by Atomist the company: the event hub, GraphQL endpoint, and web interface. [more info][architecture] PushRule a specification for goals to set on a given push. more info PushTest a function that decides whether a particular push is relevant. It can look at the code and return a boolean. more info autofix a code transform that is applied every push. more info automations in general, an automation is anything that a program does so that you don\u2019t have to. In this guide, an automation is something that Atomist runs for you. You can create automations (functions) and then have Atomist run them when events happen or on demand. channel link inside a chat channel, you can link a repository to that channel. The Atomist bot will then send messages about that repository to the channel. more info code inspection like an of automated code review; a function that looks at the code in a project and produces comments. Atomist can run them after every push. more info code transform a function that operates on a project, changing the code inside it. more info code transform an automated code change. Write a function to change code, and apply it to one project or many projects, or after every commit. more info command this is a thing that the Atomist bot (in team mode) or command line (in local mode) knows how to do. Each command has a phrase that triggers it, called an intent . As a person, send that intent to the @atomist bot in chat or to the atomist command line in the terminal. As an SDM developer, register new commands to teach Atomist how to respond to these. command line utility (CLI) (or \u201catomist command line\u201d) a program that you install on your computer in order to run an SDM. It also does various other atomist-related things, especially in local mode. more info command registration defines an intent and an implementation for a new command in an SDM. more info community Slack this Slack workspace is free for everyone to join . Here, you can see Atomist in action on our own open source projects . Ask us questions and discuss what you\u2019d like to do or see with Atomist. cortex a database where Atomist stores correlated events dashboard better known as the Atomist web interface, this lives at app.atomist.com , and it gives you access to some notifications and the settings for your Atomist workspace. more info delivery in this guide, delivery is about moving new code into production, through each of the fixes, checks, builds, publishments, deployments, and approvals that are necessary in your organization. development automation programs that make the work of software development smoother. This includes delivery automation: getting new code through all its checkpoints and into production. Other examples include project creation , [issue creation](../user/lifecycle.md, and code maintenance . durable when an SDM is configured as durable, then when it is no longer connected, the Atomist event hub will queue events for it until it comes back up. more info extension pack a collection of integrations or useful functions that can be added to an SDM. more info feed (or \u201catomist feed\u201d or \u201cSDM feed\u201d) a place for a local-mode SDM to send you messages and updates, since it does not have access to chat. more info fingerprint a distilled piece of important information about the code at a particular time. They can be compared to notice when a change is significant in a particular way. more info generator a particular kind of command that creates a new project. It starts from a seed, runs some code transforms , and puts the result in a new repository. goal approval goals can pause the work on a particular delivery flow, pending a human telling them to proceed. A button appears on the push notification in chat. goal preconditions one goal can wait for another goal (or goals) to complete before starting. more info goals steps to execute after a push. These are set by a software delivery machine. more info intent (or \u201ccommand intent\u201d) the phrase to type to trigger a command lifecycle in general, lifecycle means the stages in any process. In this guide, we talk about automations triggered in different parts of the software development lifecycle. Lifecycle messages are the built-in notifications that the Atomist bot sends to chat to describe issue, pull request, issue comment, and push events (along with build, goal, and other events correlated with the push). more info listener the SDM framework lets you register listeners to various useful events. check the whole list local mode when an SDM runs on your laptop, working only on code that\u2019s on your laptop, sending messages only to your laptop. more info project in this guide, \u201cproject\u201d refers to a git repository with code in it. project owner a grouping above projects. Projects are repositories, and they each belong to someone. On GitHub, the owner is a user or an organization. On BitBucket, the owner is a user or a BitBucket project. projects directory (or \u201cAtomist projects directory\u201d) this is a directory on your computer where local-mode SDMs will look for projects to work on. It defaults to $HOME/atomist/projects more info push event the most important event in delivery automation, a push represents new code arriving in a repository. Normally (in team mode) this is triggered when someone pushes commits to the central version control repository. In local mode, a push event is triggered on a commit. push impact a function that reacts to a change in code. It can do anything: send a message to chat, for instance. more info push notification the message that atomist bot sends to chat after each push event. It gets updated to include information about builds, goal, tags, deployments, and more. more info registration an object that provides instructions to an SDM or a goal. A registration includes a name (for diagnostics), and some specific action (a transform, an inspection, or a listener, depending on the built-in goal). Many registrations also include an optional PushTest, narrowing on particular pushes. seed the starting point for a generator. A seed is a real project that serves as a model for new projects. skills another name for commands. Skills are things Atomist knows how to do. software delivery machine (SDM) a program that you run, which connects to the atomist service (in team mode) for triggering and chat integration. Your SDM runs your software delivery flow and other development automations. target (as in \u201ctarget repository\u201d or \u201ctarget owner\u201d) when you run a generator, this is where Atomist will put the new project. See project and project owner team in this guide, your team includes all the other people at your company who might interact with Atomist. team mode an SDM running in team mode connects to the Atomist service. It might run on your laptop or in a production environment within your network. more info version control in this guide, \u201cversion control\u201d refers to the place where you push code to share it with your team like GitHub, GitLab, or BitBucket. Everyone uses git locally, right? (I know, not everyone does, but everyone who uses Atomist has to.) web interface the Atomist web interface lives at app.atomist.com , and it gives you access to some notifications and the settings for your Atomist workspace. more info workspace many services have a concept of \u201cworkspace,\u201d and Atomist is one of them. An Atomist workspace represents your organization\u2019s account with Atomist.","title":"Glossary"},{"location":"developer/glossary/#atomist","text":"the company that produces this spectacular glossary. a development automation platform, consisting of a service, a framework, and libraries to help you automate your software delivery, your way.","title":"Atomist"},{"location":"developer/glossary/#atomist-service","text":"the part of the Atomist platform that is operated by Atomist the company: the event hub, GraphQL endpoint, and web interface. [more info][architecture]","title":"Atomist service"},{"location":"developer/glossary/#pushrule","text":"a specification for goals to set on a given push. more info","title":"PushRule"},{"location":"developer/glossary/#pushtest","text":"a function that decides whether a particular push is relevant. It can look at the code and return a boolean. more info","title":"PushTest"},{"location":"developer/glossary/#autofix","text":"a code transform that is applied every push. more info","title":"autofix"},{"location":"developer/glossary/#automations","text":"in general, an automation is anything that a program does so that you don\u2019t have to. In this guide, an automation is something that Atomist runs for you. You can create automations (functions) and then have Atomist run them when events happen or on demand.","title":"automations"},{"location":"developer/glossary/#channel-link","text":"inside a chat channel, you can link a repository to that channel. The Atomist bot will then send messages about that repository to the channel. more info","title":"channel link"},{"location":"developer/glossary/#code-inspection","text":"like an of automated code review; a function that looks at the code in a project and produces comments. Atomist can run them after every push. more info","title":"code inspection"},{"location":"developer/glossary/#code-transform","text":"a function that operates on a project, changing the code inside it. more info","title":"code transform"},{"location":"developer/glossary/#code-transform_1","text":"an automated code change. Write a function to change code, and apply it to one project or many projects, or after every commit. more info","title":"code transform"},{"location":"developer/glossary/#command","text":"this is a thing that the Atomist bot (in team mode) or command line (in local mode) knows how to do. Each command has a phrase that triggers it, called an intent . As a person, send that intent to the @atomist bot in chat or to the atomist command line in the terminal. As an SDM developer, register new commands to teach Atomist how to respond to these.","title":"command"},{"location":"developer/glossary/#command-line-utility-cli","text":"(or \u201catomist command line\u201d) a program that you install on your computer in order to run an SDM. It also does various other atomist-related things, especially in local mode. more info","title":"command line utility (CLI)"},{"location":"developer/glossary/#command-registration","text":"defines an intent and an implementation for a new command in an SDM. more info","title":"command registration"},{"location":"developer/glossary/#community-slack","text":"this Slack workspace is free for everyone to join . Here, you can see Atomist in action on our own open source projects . Ask us questions and discuss what you\u2019d like to do or see with Atomist.","title":"community Slack"},{"location":"developer/glossary/#cortex","text":"a database where Atomist stores correlated events","title":"cortex"},{"location":"developer/glossary/#dashboard","text":"better known as the Atomist web interface, this lives at app.atomist.com , and it gives you access to some notifications and the settings for your Atomist workspace. more info","title":"dashboard"},{"location":"developer/glossary/#delivery","text":"in this guide, delivery is about moving new code into production, through each of the fixes, checks, builds, publishments, deployments, and approvals that are necessary in your organization.","title":"delivery"},{"location":"developer/glossary/#development-automation","text":"programs that make the work of software development smoother. This includes delivery automation: getting new code through all its checkpoints and into production. Other examples include project creation , [issue creation](../user/lifecycle.md, and code maintenance .","title":"development automation"},{"location":"developer/glossary/#durable","text":"when an SDM is configured as durable, then when it is no longer connected, the Atomist event hub will queue events for it until it comes back up. more info","title":"durable"},{"location":"developer/glossary/#extension-pack","text":"a collection of integrations or useful functions that can be added to an SDM. more info","title":"extension pack"},{"location":"developer/glossary/#feed","text":"(or \u201catomist feed\u201d or \u201cSDM feed\u201d) a place for a local-mode SDM to send you messages and updates, since it does not have access to chat. more info","title":"feed"},{"location":"developer/glossary/#fingerprint","text":"a distilled piece of important information about the code at a particular time. They can be compared to notice when a change is significant in a particular way. more info","title":"fingerprint"},{"location":"developer/glossary/#generator","text":"a particular kind of command that creates a new project. It starts from a seed, runs some code transforms , and puts the result in a new repository.","title":"generator"},{"location":"developer/glossary/#goal-approval","text":"goals can pause the work on a particular delivery flow, pending a human telling them to proceed. A button appears on the push notification in chat.","title":"goal approval"},{"location":"developer/glossary/#goal-preconditions","text":"one goal can wait for another goal (or goals) to complete before starting. more info","title":"goal preconditions"},{"location":"developer/glossary/#goals","text":"steps to execute after a push. These are set by a software delivery machine. more info","title":"goals"},{"location":"developer/glossary/#intent","text":"(or \u201ccommand intent\u201d) the phrase to type to trigger a command","title":"intent"},{"location":"developer/glossary/#lifecycle","text":"in general, lifecycle means the stages in any process. In this guide, we talk about automations triggered in different parts of the software development lifecycle. Lifecycle messages are the built-in notifications that the Atomist bot sends to chat to describe issue, pull request, issue comment, and push events (along with build, goal, and other events correlated with the push). more info","title":"lifecycle"},{"location":"developer/glossary/#listener","text":"the SDM framework lets you register listeners to various useful events. check the whole list","title":"listener"},{"location":"developer/glossary/#local-mode","text":"when an SDM runs on your laptop, working only on code that\u2019s on your laptop, sending messages only to your laptop. more info","title":"local mode"},{"location":"developer/glossary/#project","text":"in this guide, \u201cproject\u201d refers to a git repository with code in it.","title":"project"},{"location":"developer/glossary/#project-owner","text":"a grouping above projects. Projects are repositories, and they each belong to someone. On GitHub, the owner is a user or an organization. On BitBucket, the owner is a user or a BitBucket project.","title":"project owner"},{"location":"developer/glossary/#projects-directory","text":"(or \u201cAtomist projects directory\u201d) this is a directory on your computer where local-mode SDMs will look for projects to work on. It defaults to $HOME/atomist/projects more info","title":"projects directory"},{"location":"developer/glossary/#push-event","text":"the most important event in delivery automation, a push represents new code arriving in a repository. Normally (in team mode) this is triggered when someone pushes commits to the central version control repository. In local mode, a push event is triggered on a commit.","title":"push event"},{"location":"developer/glossary/#push-impact","text":"a function that reacts to a change in code. It can do anything: send a message to chat, for instance. more info","title":"push impact"},{"location":"developer/glossary/#push-notification","text":"the message that atomist bot sends to chat after each push event. It gets updated to include information about builds, goal, tags, deployments, and more. more info","title":"push notification"},{"location":"developer/glossary/#registration","text":"an object that provides instructions to an SDM or a goal. A registration includes a name (for diagnostics), and some specific action (a transform, an inspection, or a listener, depending on the built-in goal). Many registrations also include an optional PushTest, narrowing on particular pushes.","title":"registration"},{"location":"developer/glossary/#seed","text":"the starting point for a generator. A seed is a real project that serves as a model for new projects.","title":"seed"},{"location":"developer/glossary/#skills","text":"another name for commands. Skills are things Atomist knows how to do.","title":"skills"},{"location":"developer/glossary/#software-delivery-machine-sdm","text":"a program that you run, which connects to the atomist service (in team mode) for triggering and chat integration. Your SDM runs your software delivery flow and other development automations.","title":"software delivery machine (SDM)"},{"location":"developer/glossary/#target","text":"(as in \u201ctarget repository\u201d or \u201ctarget owner\u201d) when you run a generator, this is where Atomist will put the new project. See project and project owner","title":"target"},{"location":"developer/glossary/#team","text":"in this guide, your team includes all the other people at your company who might interact with Atomist.","title":"team"},{"location":"developer/glossary/#team-mode","text":"an SDM running in team mode connects to the Atomist service. It might run on your laptop or in a production environment within your network. more info","title":"team mode"},{"location":"developer/glossary/#version-control","text":"in this guide, \u201cversion control\u201d refers to the place where you push code to share it with your team like GitHub, GitLab, or BitBucket. Everyone uses git locally, right? (I know, not everyone does, but everyone who uses Atomist has to.)","title":"version control"},{"location":"developer/glossary/#web-interface","text":"the Atomist web interface lives at app.atomist.com , and it gives you access to some notifications and the settings for your Atomist workspace. more info","title":"web interface"},{"location":"developer/glossary/#workspace","text":"many services have a concept of \u201cworkspace,\u201d and Atomist is one of them. An Atomist workspace represents your organization\u2019s account with Atomist.","title":"workspace"},{"location":"developer/goal/","text":"Goals are reusable parts of functionality used within a CI/CD context. Think of tasks like starting a build, deploying your application to Kubernetes. These goals consist primarily of: something to identify the goal by, i.e. a unique name a block of code to be executed when the task needs to be run metadata to describe the goal and when it is applicable. The most important SDM functionality relates to what happens on a push to a repository. An SDM allows you to process a push in any way you choose, but typically you want it to initiate a delivery flow. In short, an SDM allows you to set goals on as a response to an event, for example a push. Goals can be completed by an SDM or elsewhere; for example, the SDM can recognize that a goal is complete when a build finishes in an external system. The goals set on a push don\u2019t need to be the same every time. Unlike the static pipelines you may be used to, with Atomist the delivery flow is not necessarily the same for every change. In essense, Atomist allows you to create a pipeline per push. Goals aren\u2019t configured per repository. They are chosen dynamically, in response to any push in any repository, based on the code and the context. What kind of project is it? What branch was pushed? Is there a pull request? Which files changed? Brand-new repositories require no configuration. Goals are not necessarily sequential\u2013by default they execute in parallel\u2013but certain goals, such as deployment, have preconditions (goals that must have previously completed successfully). In Slack, a push notification with several goals looks like this: This page shows how to create goals teach them what to do require approval The next page describes how to set goals for each push . Create goals Set up goals wherever you configure your SDM, probably in lib/machine/machine.ts . This example comes from an SDM for Java Spring Boot web services . A Goal object supplies its name, descriptions for its various possible states, and an implementation. To experiment, you might want to create your own goal Or explore the built-in goal implementations: Build - run a build, with an existing integration or your own function Autofix - apply formatting changes, CHANGELOG updates, etc. as automatic commits AutoInspect - inspect the new code PushImpact - run any other function as a response to the push Fingerprint - compute a snapshot of some aspect of the code, for tracking After you\u2019ve created some goals, choose when to set them . Creating a goal You can define your own goal to extend Atomist\u2019s out of the box capabilities. For example, you can: Delegate to a CLI by spawning a process and waiting for its result Call the API of a third party service Use a Node module or Atomist\u2019s API to implement your functionality right in TypeScript To define your own goal, you must provide a name and description and a function for how to execute it. Using the goal function Use the goal function from @atomist/sdm; pass it an object with a displayName and as many properties out of GoalDefinition as you choose. Also pass a function to call when it\u2019s time to execute the goal. That function can return void or an ExecuteGoalResult . For example: const releaseDocs = goal ( { displayName : \"My new goal\" }, async ( inv : GoalInvocation ) => { // do what is needed return { code : 0 }; }); Waiting on a Precondition Sometimes goals need other goals to have completed before they can start. This is handled while setting goals on a push. Sometimes they wait on external conditions, such as another service having started. This is handled with wait rules . Built-in Goals A goal object has some identifying information, code to fulfill the goal, and optional preconditions (goals that need to complete before it can start). Some common goals have their own constructors. Atomist provides a couple of out of the box goal implementations for common CI tasks to be executed within a pipeline. AutoInspect Run an inspection on the code; if the code doesn\u2019t pass, you can fail the goals or require approval (a button push). To use it, you\u2019ll need to create one, set it on each push, and register inspections on it. Instantiate an empty one: export const codeInspection = new AutoCodeInspection (); And set it when you want it to run on a push. Here\u2019s the shortest way to run this goal on every push: sdm . addGoalContributions ( goalContributors ( onAnyPush (). setGoals ( goals ( \"Inspections\" ). plan ( codeInspection )))) Now the fun part: register inspections on it. Check the Inspections page for more on how to write inspections. Once you have an AutoInspectRegistration , register it on your goal: codeInspection . with ( MyAutoInspectRegistration ) . with ( AnotherInspectRegistration ); You can register any number of inspections. You can call with on the goal at any point in SDM configuration. If no inspections are registered, the goal will succeed. If any registration\u2019s onInspectionResult returns \u201cfail\u201d, the goal will fail. If none return \u201cfail\u201d but one returns \u201crequire approval\u201d, the goal will go to Waiting for Approval state until someone clicks the Approve button in Slack or on the Atomist web interface. Autofix This goal tells the SDM to check each push and create commits on top of it to correct fixable violations in the code. For example, you can use this for automatic linting or to add license headers where they have been omitted. Instantiate the goal: const autofixGoal = new Autofix (). with ( AddApacheLicenseFileAutofix ); Add autofix registrations: see the autofix documentation . Then you add the goal to your goal set. For example, if you want to add the goal to each push: sdm . addPushRules ( onAnyPush (). setGoals ( autofix )); Each autofix registration can include a push test to select the projects it can operate on. PushImpact This allows you to run an arbitrary function in response to a push, with information about the changes in the push. For example, the following function lists changed files to any Slack channels linked to a repo: export const listChangedFiles : PushImpactRegistration = { action ( i : PushImpactListenerInvocation ) { return i . addressChannels ( `Files changed: \\ n ${ i . filesChanged . map ( n => \"- `\" + n + \"`\" ). join ( \"\\n\" ) } ` ); }, name : \"List files changed\" , }; If you don\u2019t have a custom name or PushTest, you can use the following shorthand, supplying only the PushImpactListener function: export const listChangedFiles = i => i . addressChannels ( `Files changed: \\ n ${ i . filesChanged . map ( n => \"- `\" + n + \"`\" ). join ( \"\\n\" ) } ` ); Create a PushImpact goal and add listeners as follows: const pushImpactGoal = new PushImpact (). with ( listChangedFiles ) If your reaction is essentially a review\u2013for example, it\u2019s associated with a known problem in a particular file location\u2013use a CodeInspectionRegistration rather than a PushImpactRegistration . Build This one has its own section .","title":"Create Goals"},{"location":"developer/goal/#create-goals","text":"Set up goals wherever you configure your SDM, probably in lib/machine/machine.ts . This example comes from an SDM for Java Spring Boot web services . A Goal object supplies its name, descriptions for its various possible states, and an implementation. To experiment, you might want to create your own goal Or explore the built-in goal implementations: Build - run a build, with an existing integration or your own function Autofix - apply formatting changes, CHANGELOG updates, etc. as automatic commits AutoInspect - inspect the new code PushImpact - run any other function as a response to the push Fingerprint - compute a snapshot of some aspect of the code, for tracking After you\u2019ve created some goals, choose when to set them .","title":"Create goals"},{"location":"developer/goal/#creating-a-goal","text":"You can define your own goal to extend Atomist\u2019s out of the box capabilities. For example, you can: Delegate to a CLI by spawning a process and waiting for its result Call the API of a third party service Use a Node module or Atomist\u2019s API to implement your functionality right in TypeScript To define your own goal, you must provide a name and description and a function for how to execute it.","title":"Creating a goal"},{"location":"developer/goal/#using-the-goal-function","text":"Use the goal function from @atomist/sdm; pass it an object with a displayName and as many properties out of GoalDefinition as you choose. Also pass a function to call when it\u2019s time to execute the goal. That function can return void or an ExecuteGoalResult . For example: const releaseDocs = goal ( { displayName : \"My new goal\" }, async ( inv : GoalInvocation ) => { // do what is needed return { code : 0 }; });","title":"Using the goal function"},{"location":"developer/goal/#waiting-on-a-precondition","text":"Sometimes goals need other goals to have completed before they can start. This is handled while setting goals on a push. Sometimes they wait on external conditions, such as another service having started. This is handled with wait rules .","title":"Waiting on a Precondition"},{"location":"developer/goal/#built-in-goals","text":"A goal object has some identifying information, code to fulfill the goal, and optional preconditions (goals that need to complete before it can start). Some common goals have their own constructors. Atomist provides a couple of out of the box goal implementations for common CI tasks to be executed within a pipeline.","title":"Built-in Goals"},{"location":"developer/goal/#autoinspect","text":"Run an inspection on the code; if the code doesn\u2019t pass, you can fail the goals or require approval (a button push). To use it, you\u2019ll need to create one, set it on each push, and register inspections on it. Instantiate an empty one: export const codeInspection = new AutoCodeInspection (); And set it when you want it to run on a push. Here\u2019s the shortest way to run this goal on every push: sdm . addGoalContributions ( goalContributors ( onAnyPush (). setGoals ( goals ( \"Inspections\" ). plan ( codeInspection )))) Now the fun part: register inspections on it. Check the Inspections page for more on how to write inspections. Once you have an AutoInspectRegistration , register it on your goal: codeInspection . with ( MyAutoInspectRegistration ) . with ( AnotherInspectRegistration ); You can register any number of inspections. You can call with on the goal at any point in SDM configuration. If no inspections are registered, the goal will succeed. If any registration\u2019s onInspectionResult returns \u201cfail\u201d, the goal will fail. If none return \u201cfail\u201d but one returns \u201crequire approval\u201d, the goal will go to Waiting for Approval state until someone clicks the Approve button in Slack or on the Atomist web interface.","title":"AutoInspect"},{"location":"developer/goal/#autofix","text":"This goal tells the SDM to check each push and create commits on top of it to correct fixable violations in the code. For example, you can use this for automatic linting or to add license headers where they have been omitted. Instantiate the goal: const autofixGoal = new Autofix (). with ( AddApacheLicenseFileAutofix ); Add autofix registrations: see the autofix documentation . Then you add the goal to your goal set. For example, if you want to add the goal to each push: sdm . addPushRules ( onAnyPush (). setGoals ( autofix )); Each autofix registration can include a push test to select the projects it can operate on.","title":"Autofix"},{"location":"developer/goal/#pushimpact","text":"This allows you to run an arbitrary function in response to a push, with information about the changes in the push. For example, the following function lists changed files to any Slack channels linked to a repo: export const listChangedFiles : PushImpactRegistration = { action ( i : PushImpactListenerInvocation ) { return i . addressChannels ( `Files changed: \\ n ${ i . filesChanged . map ( n => \"- `\" + n + \"`\" ). join ( \"\\n\" ) } ` ); }, name : \"List files changed\" , }; If you don\u2019t have a custom name or PushTest, you can use the following shorthand, supplying only the PushImpactListener function: export const listChangedFiles = i => i . addressChannels ( `Files changed: \\ n ${ i . filesChanged . map ( n => \"- `\" + n + \"`\" ). join ( \"\\n\" ) } ` ); Create a PushImpact goal and add listeners as follows: const pushImpactGoal = new PushImpact (). with ( listChangedFiles ) If your reaction is essentially a review\u2013for example, it\u2019s associated with a known problem in a particular file location\u2013use a CodeInspectionRegistration rather than a PushImpactRegistration .","title":"PushImpact"},{"location":"developer/goal/#build","text":"This one has its own section .","title":"Build"},{"location":"developer/goals-more/","text":"Here are some more things you can do with goals: Perform a preparatory action after checking out code and before executing the goal, with GoalProjectListeners Reset goals on the latest commit, to have your SDM try again. Prepare the checked out code Any built-in goal , plus any goal created with the goal function, implements FulfillableGoal . These can have GoalProjectListeners. Say you want to run tests as a separate goal. But you have to run a build before the tests can run. By default, the goal will execute in a fresh checkout of the repository (caveat: in local mode , it may reuse a cached checkout). Your test goal wants to run tests, it doesn\u2019t really want to run a build; it wants that to have run already. Separately, you also want an integration-test goal and it also needs a build beforehand. Encapsulate that \u201cthing that needs to happen before the goal runs\u201d in a GoalProjectListener. Create a GoalProjectListener A GoalProjectListener function accepts a Project, a GoalInvocation , and a GoalProjectListenerEvent (\u201cbefore\u201d or \u201cafter\u201d). The important part is the Project ; this is the checked-out repository that needs built (or whatever preparation you are encapsulating). const BuildCheckedOutCode : GoalProjectListener = async ( project , inv , event ) => { if ( ! await project . hasDirectory ( \"site\" )) { return { code : 0 , message : \"Looks OK, site directory already exists\" }; } // do the build or whatever is needful }, Create a GoalProjectListenerRegistration A GoalProjectListenerRegistration object defines a name and when to run the GoalProjectListener. The name field will appear in the description of the goal while it\u2019s running, inside push events . The events array determines whether this runs before or after a goal executes (default is both). const BuildCheckedOutCodeFirst : GoalProjectListenerRegistration = { name : \"build the code\" , events : [ GoalProjectListenerEvent . before ], listener : BuildCheckedOutCode , }; Register the GoalProjectListener on goals Any FulfillableGoal can accept a GoalProjectListenerRegistration with its withProjectListener method. Call this when you create the goal. For instance, here is a possible custom test goal: const myTest = goal ( { displayName : \"Tests\" }, executeMyTests ) . withProjectListener ( BuildCheckedOutCodeFirst ); Reset goals Your SDM can have a command to reset goals on the last commit. Add the goalState extension pack to your SDM: import { goalState } from \"@atomist/sdm-core\" ; sdm . addExtensionPacks ( goalState (), ); Then send @atomist reset goals <name of your SDM> , where \u201cname of your sdm\u201d is the name property in package.json, minus any @ characters. You can add branch=my-branch and/or sha=<40-character SHA> to change which commit gets a new set of goals.","title":"Doing More with Goals"},{"location":"developer/goals-more/#prepare-the-checked-out-code","text":"Any built-in goal , plus any goal created with the goal function, implements FulfillableGoal . These can have GoalProjectListeners. Say you want to run tests as a separate goal. But you have to run a build before the tests can run. By default, the goal will execute in a fresh checkout of the repository (caveat: in local mode , it may reuse a cached checkout). Your test goal wants to run tests, it doesn\u2019t really want to run a build; it wants that to have run already. Separately, you also want an integration-test goal and it also needs a build beforehand. Encapsulate that \u201cthing that needs to happen before the goal runs\u201d in a GoalProjectListener.","title":"Prepare the checked out code"},{"location":"developer/goals-more/#create-a-goalprojectlistener","text":"A GoalProjectListener function accepts a Project, a GoalInvocation , and a GoalProjectListenerEvent (\u201cbefore\u201d or \u201cafter\u201d). The important part is the Project ; this is the checked-out repository that needs built (or whatever preparation you are encapsulating). const BuildCheckedOutCode : GoalProjectListener = async ( project , inv , event ) => { if ( ! await project . hasDirectory ( \"site\" )) { return { code : 0 , message : \"Looks OK, site directory already exists\" }; } // do the build or whatever is needful },","title":"Create a GoalProjectListener"},{"location":"developer/goals-more/#create-a-goalprojectlistenerregistration","text":"A GoalProjectListenerRegistration object defines a name and when to run the GoalProjectListener. The name field will appear in the description of the goal while it\u2019s running, inside push events . The events array determines whether this runs before or after a goal executes (default is both). const BuildCheckedOutCodeFirst : GoalProjectListenerRegistration = { name : \"build the code\" , events : [ GoalProjectListenerEvent . before ], listener : BuildCheckedOutCode , };","title":"Create a GoalProjectListenerRegistration"},{"location":"developer/goals-more/#register-the-goalprojectlistener-on-goals","text":"Any FulfillableGoal can accept a GoalProjectListenerRegistration with its withProjectListener method. Call this when you create the goal. For instance, here is a possible custom test goal: const myTest = goal ( { displayName : \"Tests\" }, executeMyTests ) . withProjectListener ( BuildCheckedOutCodeFirst );","title":"Register the GoalProjectListener on goals"},{"location":"developer/goals-more/#reset-goals","text":"Your SDM can have a command to reset goals on the last commit. Add the goalState extension pack to your SDM: import { goalState } from \"@atomist/sdm-core\" ; sdm . addExtensionPacks ( goalState (), ); Then send @atomist reset goals <name of your SDM> , where \u201cname of your sdm\u201d is the name property in package.json, minus any @ characters. You can add branch=my-branch and/or sha=<40-character SHA> to change which commit gets a new set of goals.","title":"Reset goals"},{"location":"developer/graphql/","text":"GraphQL is a powerful query language that you use to query and mutate your data in the Atomist automation platform. Besides being a great query language, GraphQL provides great tool support based on strongly-typed schemas, type generation for TypeScript, and many other advantages. The Atomist SDM includes many of the GraphQL queries that are most useful in automating software delivery. You can also create your own. The following sections tell you how to use GraphQL to query your data, how to use subscriptions to get notifications when new data is ingested, and how to mutate data. Accessing data with Graph i QL For development purposes it is often helpful to test GraphQL queries using a user interface. The Atomist web application provides the Graph i QL GraphQL client, which allows you write and run queries, displaying the shape of the resulting data. Graph i QL also provides access to the data model documentation. Try This Log in to the Atomist app and click on the GraphQL link to get to the interactive Graph i QL client. Enter this query (substitute your version control login): query MyBranches { Branch(orderBy: [timestamp_desc]) { commit @required { author(login: \"YOUR-GITHUB-LOGIN\") @required { login } } name repo { name } } } This will show you all the branches where you are the last commit author, most recent first. This is handy for finding in-progress work. This query demonstrates several features of Atomist\u2019s GraphQL interface: Each node has a Query type, so you can access branch, commit, repo, build, etc. directly. However, it is strongly recommended to start with either something that aren\u2019t many of (like branches) or select by a unique identifier (like Commit(sha: \"abcdef...\") {...} ). You can order by almost any field or fields, using orderBy . Pass it an array of order criteria (you\u2019ll get a popup to select them from). Each node can be selected by almost any field, as in author(login: \"jessitron\") {...} If you add @required (this is a custom GraphQL directive) to a subfield, then you won\u2019t see nodes that don\u2019t have that field, or where that field doesn\u2019t meet your selection criteria. Check the schema browser in Graph i QL for all the different Query types, properties, and selection options. Try adding pullRequests as a field, with number and state properties, to find out which branches have open PRs. Queries You can execute queries from command and event handlers when running an Atomist API client using the GraphClient.query() function. A GraphClient is available from the HandlerContext included in listener invocations via its graphClient property. The query() function takes a single argument: a QueryOptions object. The actual GraphQL query can be supplied as a string via the query property of QueryOptions , as the path to a file containing the query via the path property, or as the name of a query in the project\u2019s GraphQL query files via the name property. The path property can be an absolute or relative path, the latter being resolved against the path of the calling script. The name should be the name of a GraphQL query operation found within a file with a .graphql extension in a graphql/query folder in the directory of the calling script or one of its parents. Note Externalizing queries in files makes it possible to generate types for use in your TypeScript code. More on that later. The following example shows you how to query for pushes and see all corresponding continuous integration builds. Start by creating the query. The sample query includes a variable and a predicate that matches only failed builds. This example assumes the query is saved in a file called pushesWithFailedBuilds.graphql . query PushesWithFailedBuilds ($name: String!) { Push { repo(name: $name) { name owner } builds(status: failed) { name status buildUrl } } } Once the query is defined, you can use it with the GraphClient to execute a query. const result = await invocation . context . graphClient . query ({ name : \"PushesWithFailedBuilds\" , variables : { name : \"demo-service\" }, }) } The query method takes the name of the query as the name property of its first parameter. The name provided matches that in the GraphQL file. The variables property in the above example is used to provide the value for the query variable. Custom Event Handlers Subscriptions As detailed in the section on event handlers, GraphQL subscriptions can be used to subscribe to events as they get ingested into the Atomist platform. Subscriptions can\u2019t be executed with the GraphClient ; instead they can only be used from an event handler. Many of these are included in the SDM. There are two ways to declare subscriptions on event handlers: either by embedded strings or by referencing external files, which is more reusable. This example demonstrates subscribing using an external file: subscription PushesWithFailedBuilds { Push { repo { name owner } builds(status: failed) { name status buildUrl } } } A GraphQL subscription begins with the keyword subscription followed by a name for the subscription, PushesWithFailedBuilds in this case. After the opening brace, you specify the type of the top-level event you are subscribing to, Push in this example. Your subscription then defines the structured data you want to receive for each such event, navigating the data model\u2019s properties and relationships to connect related data elements like pushes, repositories, and CI builds. Note When specifying the filename, the .graphql extension is optional. Mutations Most of the data in the Atomist platform is ingested via Webhooks and is read-only. There are however a small number of very useful GraphQL mutations available. Mutation Description createSlackChannel Create a new public channel in Slack addBotToSlackChannel Invite the Atomist bot user into the given channel inviteUserToSlackChannel Invite any user into the given channel linkSlackChannelToRepo Link a GitHub repository to a Slack channel setTeamPreference Set preference data on the team entity setUserPreference Set preference data on the user entity Like queries, mutations can be loaded from files and executed with the GraphClient . Here is an example showing how to create a new channel in Slack. Here\u2019s the GraphQL file containing the mutation: mutation CreateSlackChannel($name: String!) { createSlackChannel(name: $name) { id } } This invokes the mutation from the GraphQL file: await invocation . context . graphClient . mutate ({ name : \"CreateSlackChannel\" , variables : { name : \"random\" }, }) Strongly-typed GraphQL queries One nice side-effect of using GraphQL as the query layer is that you can generate types for use with TypeScript from the schema and your queries, subscriptions, and mutations. To generate types for your externalized GraphQL operations, run npm run gql:gen . This creates a file called types.ts in src/typings/ . Now you can change the earlier query to use those types: import * as graphql from \"./typings/types\" ; //... const result = await invocation . context . graphClient . query < graphql . PushesWithFailedBuilds . Query , graphql . PushesWithFailedBuilds . Variables > ({ name : \"PushesWithFailedBuilds\" , variables : { name : \"demo-service\" }, }); // .... }","title":"Custom GraphQL Queries"},{"location":"developer/graphql/#accessing-data-with-graphiql","text":"For development purposes it is often helpful to test GraphQL queries using a user interface. The Atomist web application provides the Graph i QL GraphQL client, which allows you write and run queries, displaying the shape of the resulting data. Graph i QL also provides access to the data model documentation.","title":"Accessing data with GraphiQL"},{"location":"developer/graphql/#try-this","text":"Log in to the Atomist app and click on the GraphQL link to get to the interactive Graph i QL client. Enter this query (substitute your version control login): query MyBranches { Branch(orderBy: [timestamp_desc]) { commit @required { author(login: \"YOUR-GITHUB-LOGIN\") @required { login } } name repo { name } } } This will show you all the branches where you are the last commit author, most recent first. This is handy for finding in-progress work. This query demonstrates several features of Atomist\u2019s GraphQL interface: Each node has a Query type, so you can access branch, commit, repo, build, etc. directly. However, it is strongly recommended to start with either something that aren\u2019t many of (like branches) or select by a unique identifier (like Commit(sha: \"abcdef...\") {...} ). You can order by almost any field or fields, using orderBy . Pass it an array of order criteria (you\u2019ll get a popup to select them from). Each node can be selected by almost any field, as in author(login: \"jessitron\") {...} If you add @required (this is a custom GraphQL directive) to a subfield, then you won\u2019t see nodes that don\u2019t have that field, or where that field doesn\u2019t meet your selection criteria. Check the schema browser in Graph i QL for all the different Query types, properties, and selection options. Try adding pullRequests as a field, with number and state properties, to find out which branches have open PRs.","title":"Try This"},{"location":"developer/graphql/#queries","text":"You can execute queries from command and event handlers when running an Atomist API client using the GraphClient.query() function. A GraphClient is available from the HandlerContext included in listener invocations via its graphClient property. The query() function takes a single argument: a QueryOptions object. The actual GraphQL query can be supplied as a string via the query property of QueryOptions , as the path to a file containing the query via the path property, or as the name of a query in the project\u2019s GraphQL query files via the name property. The path property can be an absolute or relative path, the latter being resolved against the path of the calling script. The name should be the name of a GraphQL query operation found within a file with a .graphql extension in a graphql/query folder in the directory of the calling script or one of its parents. Note Externalizing queries in files makes it possible to generate types for use in your TypeScript code. More on that later. The following example shows you how to query for pushes and see all corresponding continuous integration builds. Start by creating the query. The sample query includes a variable and a predicate that matches only failed builds. This example assumes the query is saved in a file called pushesWithFailedBuilds.graphql . query PushesWithFailedBuilds ($name: String!) { Push { repo(name: $name) { name owner } builds(status: failed) { name status buildUrl } } } Once the query is defined, you can use it with the GraphClient to execute a query. const result = await invocation . context . graphClient . query ({ name : \"PushesWithFailedBuilds\" , variables : { name : \"demo-service\" }, }) } The query method takes the name of the query as the name property of its first parameter. The name provided matches that in the GraphQL file. The variables property in the above example is used to provide the value for the query variable.","title":"Queries"},{"location":"developer/graphql/#custom-event-handlers","text":"","title":"Custom Event Handlers"},{"location":"developer/graphql/#subscriptions","text":"As detailed in the section on event handlers, GraphQL subscriptions can be used to subscribe to events as they get ingested into the Atomist platform. Subscriptions can\u2019t be executed with the GraphClient ; instead they can only be used from an event handler. Many of these are included in the SDM. There are two ways to declare subscriptions on event handlers: either by embedded strings or by referencing external files, which is more reusable. This example demonstrates subscribing using an external file: subscription PushesWithFailedBuilds { Push { repo { name owner } builds(status: failed) { name status buildUrl } } } A GraphQL subscription begins with the keyword subscription followed by a name for the subscription, PushesWithFailedBuilds in this case. After the opening brace, you specify the type of the top-level event you are subscribing to, Push in this example. Your subscription then defines the structured data you want to receive for each such event, navigating the data model\u2019s properties and relationships to connect related data elements like pushes, repositories, and CI builds. Note When specifying the filename, the .graphql extension is optional.","title":"Subscriptions"},{"location":"developer/graphql/#mutations","text":"Most of the data in the Atomist platform is ingested via Webhooks and is read-only. There are however a small number of very useful GraphQL mutations available. Mutation Description createSlackChannel Create a new public channel in Slack addBotToSlackChannel Invite the Atomist bot user into the given channel inviteUserToSlackChannel Invite any user into the given channel linkSlackChannelToRepo Link a GitHub repository to a Slack channel setTeamPreference Set preference data on the team entity setUserPreference Set preference data on the user entity Like queries, mutations can be loaded from files and executed with the GraphClient . Here is an example showing how to create a new channel in Slack. Here\u2019s the GraphQL file containing the mutation: mutation CreateSlackChannel($name: String!) { createSlackChannel(name: $name) { id } } This invokes the mutation from the GraphQL file: await invocation . context . graphClient . mutate ({ name : \"CreateSlackChannel\" , variables : { name : \"random\" }, })","title":"Mutations"},{"location":"developer/graphql/#strongly-typed-graphql-queries","text":"One nice side-effect of using GraphQL as the query layer is that you can generate types for use with TypeScript from the schema and your queries, subscriptions, and mutations. To generate types for your externalized GraphQL operations, run npm run gql:gen . This creates a file called types.ts in src/typings/ . Now you can change the earlier query to use those types: import * as graphql from \"./typings/types\" ; //... const result = await invocation . context . graphClient . query < graphql . PushesWithFailedBuilds . Query , graphql . PushesWithFailedBuilds . Variables > ({ name : \"PushesWithFailedBuilds\" , variables : { name : \"demo-service\" }, }); // .... }","title":"Strongly-typed GraphQL queries"},{"location":"developer/http/","text":"There are several HTTP client libraries available in Node. You\u2019re free to use any of them, if they work for you. We have found that some internal networks have interesting characteristics that confuse many of them. To accommodate this, we made an HttpClientFactory abstraction that can be used to change the http client used in an SDM. You have access to these as well. I recommend the DefaultHttpClientFactory , which is backed by axios .","title":"HTTP Calls in an SDM"},{"location":"developer/inspect/","text":"Evaluate all your code according to your own standards. Code inspections let you locate problems and measure how closely standards are followed. Run them on one repository or all repositories. Run them after every commit, so that developers are notified of the status of the code whenever they work in a repository. For instance, when I make a commit to docs-sdm, a code inspection creates a GitHub issue for all the tslint violations in the branch. That issue looks like this: Code inspections can instead send messages to Slack. They can block further progress in goals, so you can prevent deploy of noncompliant code. They can also require specific approval before proceeding with other goals. Prerequisite: First, you\u2019ll need an AutoCodeInspection goal . Installing an inspection from a pack You can find inspections in packs, and register them on your AutoCodeInspection goal . Find inspections related to: Lines of code Spring TypeScript Custom inspections An inspection looks at a repository and produces some report. It is implemented as a function from Project to an inspection result, plus a separate function to react to these results. You decide what an inspection result contains, how to populate it, and how to react to them. This page shows you how to: Create your inspection Create a command to run it on demand in any project or projects Add it as an automatic inspection to every commit. Declare a result type Start by deciding what your inspection wants to say about a repository. For instance, your inspection might look for files with too many lines. Your result might contain the paths of files that have too many lines in them. Here, the type is defined as a string array. type FilesWithTooManyLines = string []; Create an inspection function The CodeInspection is a function from a project (and optionally, inspection parameters) to an inspection result. Your inspection can call functions on the Project to determine the result. For instance, this one gathers all the file paths where the content is over 1000 lines: import { NoParameters , Project , projectUtils , } from \"@atomist/automation-client\" ; const InspectFileLengths : CodeInspection < FilesWithTooManyLines , NoParameters > = async ( p : Project ) => { // this sample code returns the paths to TypeScript files with over 1000 lines const longFiles = await projectUtils . gatherFromFiles ( p , \"**/*.ts\" , async f => { const c = await f . getContent (); const lineCount = c . split ( \"\\n\" ). length ; if ( lineCount > 1000 ) { return f . path ; } else { return undefined ; } }); return longFiles . filter ( path => path !== undefined ); }; See also: projectUtils Create a function to react to this result Usually when you run a code inspection, you want to report back to yourself or your team what the results were. Since your inspection returns a custom type, you have to define what to do with it. We need a function that reacts to the inspection results. It takes as input an array of CodeInspectionResult which includes information about the repository that was inspected and the results of the inspection. For instance, the following reaction function sends a message containing the identifying information of the project and a summary of the results: import { CodeInspectionResult , CommandListenerInvocation , } from \"@atomist/sdm\" ; async function sendFilesWithTooManyLinesMessage ( results : Array < CodeInspectionResult < FilesWithTooManyLines >> , inv : CommandListenerInvocation ) { const message = results . map ( r => ` ${ r . repoId . owner } / ${ r . repoId . repo } There are ${ r . result . length } files with too many lines` ) . join ( \"\\n\" ); return inv . addressChannels ( message ); } Create a command to run the inspection and react to it Combine the inspection and the reaction into an object, a command registration. The intent is what you\u2019ll type to get Atomist to run the inspection. import { NoParameters } from \"@atomist/autiomation-client\" ; import { CodeInspectionRegistration } from \"@atomist/sdm\" ; const InspectFileLengthsCommand : CodeInspectionRegistration < FilesWithTooManyLines , NoParameters > = { name : \"InspectFileLengths\" , description : \"Files should be under 1000 lines\" , intent : \"inspect file lengths\" , inspection : InspectFileLengths , onInspectionResults : sendFilesWithTooManyLinesMessage , }; Register the command on your SDM Finally, teach the SDM about your command. In machine.ts , or wherever you configure your SDM, add sdm . addCodeInspectionCommand ( InspectFileLengthsCommand ); Run the inspection Recompile and restart your SDM. Depending on the context where you run @atomist inspect file lengths , you\u2019ll receive a response for one or many projects. For local mode : run it within a repository directory to inspect one project, or one directory up (within an owner directory) to inspect all repositories under that owner, or anywhere else to inspect all repositories. For team mode , in Slack: address Atomist in a channel linked to a repository to inspect that repository: @atomist inspect file lengths . Or, specify a regular expression of repository names to check them all: @atomist inspect file lengths targets.repos=\".*\" . Automatically run your code inspection You may use your inspection to find places in the code that need to change, and then change them. But how will you know when the file lengths creep back up? Make an auto code inspection run on every push (or in local mode, on every commit). Then you can point out when a file has reached 1000 lines. You can point this out with a message, by creating an issue, by failing the goal, or by asking people to push a button to approve the unorthodox file length. Make your inspection return a review Rather than returning the arbitrary type FilesWithTooManyLines , we first convert our inspection to return a ProjectReview , which packages information about the project being inspected with the comments from the inspection. import { NoParameters , Project , ProjectReview , projectUtils , ReviewComment , } from \"@atomist/automation-client\" ; const InspectFileLengths : CodeInspection < ProjectReview , NoParameters > = async ( p : Project ) => { const longFiles = await projectUtils . gatherFromFiles ( p , \"**/*.ts\" , async f => { const c = await f . getContent (); const lineCount = c . split ( \"\\n\" ). length ; if ( lineCount > 1000 ) { return f . path ; } else { return undefined ; } }). filter ( path => path !== undefined ); const comments : ReviewComment [] = longFiles . map ( f => ({ severity : \"warn\" , detail : \"File has more than 1000 lines\" , category : \"file\" , subcategory : \"file-length\" , sourceLocation : { path : f }, })); return { repoId : p.id , comments }; }; Decide what should happen What qualifies as a failed inspection and what should happen when an inspection fails? Decide this in a function that listens for your code inspection results and returns a PushImpactResponse : proceed , failGoals , or requireApprovalToProceed . You also get access to an invocation object, in case you want to post a message as well. Let\u2019s use that to send the message from this function and no longer use the now out-of-date sendFilesWithTooManyLinesMessage function. import { ReviewListener } from \"@atomist/sdm\" ; const failGoalsIfCommentsReviewListener : ReviewListener = async rli => { if ( rli . review . comments && rli . review . comments . length > 0 ) { await rli . addressChannels ( \"The following files have more than 1000 lines:\\n\" + rli . review . comments . map ( c => c . sourceLocation . path ). join ( \"\\n\" )); return PushImpactResponse . failGoals ; } return PushImpactResponse . proceed ; }; There are some handy ReviewListeners available: slackReviewListenerRegistration sends messages to Slack about the review. By default, the goal proceeeds after sending the message. To change this, send { pushReactionResponse: PushImpactResponse.failGoals } (for instance) in its options. singleIssueManagingReviewListener and friends create GitHub issues per category or per branch. You\u2019ll need the sdm-pack-issue extension pack. Update the registrations Update the registration to reflect the new return type, ProjectReview , and remove the onInspectionResults property. import { NoParameters , ProjectReview , } from \"@atomist/automation-client\" ; import { CodeInspectionRegistration } from \"@atomist/sdm\" ; const InspectFileLengthsCommand : CodeInspectionRegistration < ProjectReview , NoParameters > = { name : \"InspectFileLengths\" , description : \"Files should be under 1000 lines\" , intent : \"inspect file lengths\" , inspection : InspectFileLengths , }; Also create a registration for the review listener: import { ReviewListenerRegistration } from \"@atomist/sdm\" ; const FailGoalsIfComments : ReviewListenerRegistration = { name : \"Fail Goals if any code inspections result in comments\" , listener : failGoalsIfCommentsReviewListener , }; AutoInspect goal Finally, attach this code inspection and its listener to your AutoCodeInspection goal: import { AutoCodeInspection } from \"@atomist/sdm\" ; const codeInspection = new AutoCodeInspection (); codeInspection . with ( AutoInspectFileLengths ) . withListener ( FailGoalsIfComments ); Activate your AutoCodeInspection by setting the goal when a push happens. See AutoInspect goal for details.","title":"Code Inspections"},{"location":"developer/inspect/#installing-an-inspection-from-a-pack","text":"You can find inspections in packs, and register them on your AutoCodeInspection goal . Find inspections related to: Lines of code Spring TypeScript","title":"Installing an inspection from a pack"},{"location":"developer/inspect/#custom-inspections","text":"An inspection looks at a repository and produces some report. It is implemented as a function from Project to an inspection result, plus a separate function to react to these results. You decide what an inspection result contains, how to populate it, and how to react to them. This page shows you how to: Create your inspection Create a command to run it on demand in any project or projects Add it as an automatic inspection to every commit.","title":"Custom inspections"},{"location":"developer/inspect/#declare-a-result-type","text":"Start by deciding what your inspection wants to say about a repository. For instance, your inspection might look for files with too many lines. Your result might contain the paths of files that have too many lines in them. Here, the type is defined as a string array. type FilesWithTooManyLines = string [];","title":"Declare a result type"},{"location":"developer/inspect/#create-an-inspection-function","text":"The CodeInspection is a function from a project (and optionally, inspection parameters) to an inspection result. Your inspection can call functions on the Project to determine the result. For instance, this one gathers all the file paths where the content is over 1000 lines: import { NoParameters , Project , projectUtils , } from \"@atomist/automation-client\" ; const InspectFileLengths : CodeInspection < FilesWithTooManyLines , NoParameters > = async ( p : Project ) => { // this sample code returns the paths to TypeScript files with over 1000 lines const longFiles = await projectUtils . gatherFromFiles ( p , \"**/*.ts\" , async f => { const c = await f . getContent (); const lineCount = c . split ( \"\\n\" ). length ; if ( lineCount > 1000 ) { return f . path ; } else { return undefined ; } }); return longFiles . filter ( path => path !== undefined ); }; See also: projectUtils","title":"Create an inspection function"},{"location":"developer/inspect/#create-a-function-to-react-to-this-result","text":"Usually when you run a code inspection, you want to report back to yourself or your team what the results were. Since your inspection returns a custom type, you have to define what to do with it. We need a function that reacts to the inspection results. It takes as input an array of CodeInspectionResult which includes information about the repository that was inspected and the results of the inspection. For instance, the following reaction function sends a message containing the identifying information of the project and a summary of the results: import { CodeInspectionResult , CommandListenerInvocation , } from \"@atomist/sdm\" ; async function sendFilesWithTooManyLinesMessage ( results : Array < CodeInspectionResult < FilesWithTooManyLines >> , inv : CommandListenerInvocation ) { const message = results . map ( r => ` ${ r . repoId . owner } / ${ r . repoId . repo } There are ${ r . result . length } files with too many lines` ) . join ( \"\\n\" ); return inv . addressChannels ( message ); }","title":"Create a function to react to this result"},{"location":"developer/inspect/#create-a-command-to-run-the-inspection-and-react-to-it","text":"Combine the inspection and the reaction into an object, a command registration. The intent is what you\u2019ll type to get Atomist to run the inspection. import { NoParameters } from \"@atomist/autiomation-client\" ; import { CodeInspectionRegistration } from \"@atomist/sdm\" ; const InspectFileLengthsCommand : CodeInspectionRegistration < FilesWithTooManyLines , NoParameters > = { name : \"InspectFileLengths\" , description : \"Files should be under 1000 lines\" , intent : \"inspect file lengths\" , inspection : InspectFileLengths , onInspectionResults : sendFilesWithTooManyLinesMessage , };","title":"Create a command to run the inspection and react to it"},{"location":"developer/inspect/#register-the-command-on-your-sdm","text":"Finally, teach the SDM about your command. In machine.ts , or wherever you configure your SDM, add sdm . addCodeInspectionCommand ( InspectFileLengthsCommand );","title":"Register the command on your SDM"},{"location":"developer/inspect/#run-the-inspection","text":"Recompile and restart your SDM. Depending on the context where you run @atomist inspect file lengths , you\u2019ll receive a response for one or many projects. For local mode : run it within a repository directory to inspect one project, or one directory up (within an owner directory) to inspect all repositories under that owner, or anywhere else to inspect all repositories. For team mode , in Slack: address Atomist in a channel linked to a repository to inspect that repository: @atomist inspect file lengths . Or, specify a regular expression of repository names to check them all: @atomist inspect file lengths targets.repos=\".*\" .","title":"Run the inspection"},{"location":"developer/inspect/#automatically-run-your-code-inspection","text":"You may use your inspection to find places in the code that need to change, and then change them. But how will you know when the file lengths creep back up? Make an auto code inspection run on every push (or in local mode, on every commit). Then you can point out when a file has reached 1000 lines. You can point this out with a message, by creating an issue, by failing the goal, or by asking people to push a button to approve the unorthodox file length.","title":"Automatically run your code inspection"},{"location":"developer/inspect/#make-your-inspection-return-a-review","text":"Rather than returning the arbitrary type FilesWithTooManyLines , we first convert our inspection to return a ProjectReview , which packages information about the project being inspected with the comments from the inspection. import { NoParameters , Project , ProjectReview , projectUtils , ReviewComment , } from \"@atomist/automation-client\" ; const InspectFileLengths : CodeInspection < ProjectReview , NoParameters > = async ( p : Project ) => { const longFiles = await projectUtils . gatherFromFiles ( p , \"**/*.ts\" , async f => { const c = await f . getContent (); const lineCount = c . split ( \"\\n\" ). length ; if ( lineCount > 1000 ) { return f . path ; } else { return undefined ; } }). filter ( path => path !== undefined ); const comments : ReviewComment [] = longFiles . map ( f => ({ severity : \"warn\" , detail : \"File has more than 1000 lines\" , category : \"file\" , subcategory : \"file-length\" , sourceLocation : { path : f }, })); return { repoId : p.id , comments }; };","title":"Make your inspection return a review"},{"location":"developer/inspect/#decide-what-should-happen","text":"What qualifies as a failed inspection and what should happen when an inspection fails? Decide this in a function that listens for your code inspection results and returns a PushImpactResponse : proceed , failGoals , or requireApprovalToProceed . You also get access to an invocation object, in case you want to post a message as well. Let\u2019s use that to send the message from this function and no longer use the now out-of-date sendFilesWithTooManyLinesMessage function. import { ReviewListener } from \"@atomist/sdm\" ; const failGoalsIfCommentsReviewListener : ReviewListener = async rli => { if ( rli . review . comments && rli . review . comments . length > 0 ) { await rli . addressChannels ( \"The following files have more than 1000 lines:\\n\" + rli . review . comments . map ( c => c . sourceLocation . path ). join ( \"\\n\" )); return PushImpactResponse . failGoals ; } return PushImpactResponse . proceed ; }; There are some handy ReviewListeners available: slackReviewListenerRegistration sends messages to Slack about the review. By default, the goal proceeeds after sending the message. To change this, send { pushReactionResponse: PushImpactResponse.failGoals } (for instance) in its options. singleIssueManagingReviewListener and friends create GitHub issues per category or per branch. You\u2019ll need the sdm-pack-issue extension pack.","title":"Decide what should happen"},{"location":"developer/inspect/#update-the-registrations","text":"Update the registration to reflect the new return type, ProjectReview , and remove the onInspectionResults property. import { NoParameters , ProjectReview , } from \"@atomist/automation-client\" ; import { CodeInspectionRegistration } from \"@atomist/sdm\" ; const InspectFileLengthsCommand : CodeInspectionRegistration < ProjectReview , NoParameters > = { name : \"InspectFileLengths\" , description : \"Files should be under 1000 lines\" , intent : \"inspect file lengths\" , inspection : InspectFileLengths , }; Also create a registration for the review listener: import { ReviewListenerRegistration } from \"@atomist/sdm\" ; const FailGoalsIfComments : ReviewListenerRegistration = { name : \"Fail Goals if any code inspections result in comments\" , listener : failGoalsIfCommentsReviewListener , };","title":"Update the registrations"},{"location":"developer/inspect/#autoinspect-goal","text":"Finally, attach this code inspection and its listener to your AutoCodeInspection goal: import { AutoCodeInspection } from \"@atomist/sdm\" ; const codeInspection = new AutoCodeInspection (); codeInspection . with ( AutoInspectFileLengths ) . withListener ( FailGoalsIfComments ); Activate your AutoCodeInspection by setting the goal when a push happens. See AutoInspect goal for details.","title":"AutoInspect goal"},{"location":"developer/invocation/","text":"Invocation objects provide information to your implementations of goals and event listeners . Invocations These objects, passed to listener functions, contain properties useful for learning about the project and for sending messages. As with all good frameworks, we\u2019ve tried to make the API consistent. All listener invocations include at least the following generally useful information: export interface SdmContext { /** * If available, provides a way to address the channel(s) related to this event. * This is usually, but not always, the channels linked to a repo * In local mode, this sends to `atomist feed` * In some cases, such as repo creation or a push to a repo where there is no linked channel, * addressChannels will go to dev/null without error. */ addressChannels : AddressChannels ; /** * Credentials for use with source control hosts such as GitHub * (team mode only) */ credentials : ProjectOperationCredentials ; /** * Context of the Atomist EventHandler invocation. Use to run GraphQL * queries, use the messageClient directly and find * the workspace and correlation id */ context : HandlerContext ; } Most events concern a specific repository, and hence most listener invocations extend RepoContext : export interface RepoContext extends SdmContext { /** * The repo this relates to. Fields include `owner`, `repo`, `sha` and `branch` */ id : RemoteRepoRef ; } Many repo-specific listeners are given access to the repository source, via the Project abstraction: export interface ProjectListenerInvocation extends RepoListenerInvocation { /** * The project to which this event relates. It will have been cloned * prior to this invocation. Modifications made during listener invocation will * not be committed back to the project (although they are acceptable if necessary, for * example to run particular commands against the project). * As well as working with * project files using the Project superinterface, we can use git-related * functionality fro the GitProject subinterface: For example to check * for previous shas. * We can also easily run shell commands against the project using its baseDir. */ project : GitProject ; } The Project interface provides an abstraction to the present repository, with Atomist taking care of Git cloning and (if necessary) writing back any changes via a push. It is abstracted from the file system, making it easy to unit test with mocked repository contents, using the InMemoryProject and InMemoryFile classes. Note The Project API and sophisticated parsing functionality available on top of it is a core Atomist capability. Many events can only be understood in the context of the impacted code, and many actions are achieved by modifying code. Push listeners also have access to the details of the relevant push: export interface PushListenerInvocation extends ProjectListenerInvocation { /** * Information about the push, including repo and commit */ readonly push : OnPushToAnyBranch.Push ; }","title":"Invocation"},{"location":"developer/invocation/#invocations","text":"These objects, passed to listener functions, contain properties useful for learning about the project and for sending messages. As with all good frameworks, we\u2019ve tried to make the API consistent. All listener invocations include at least the following generally useful information: export interface SdmContext { /** * If available, provides a way to address the channel(s) related to this event. * This is usually, but not always, the channels linked to a repo * In local mode, this sends to `atomist feed` * In some cases, such as repo creation or a push to a repo where there is no linked channel, * addressChannels will go to dev/null without error. */ addressChannels : AddressChannels ; /** * Credentials for use with source control hosts such as GitHub * (team mode only) */ credentials : ProjectOperationCredentials ; /** * Context of the Atomist EventHandler invocation. Use to run GraphQL * queries, use the messageClient directly and find * the workspace and correlation id */ context : HandlerContext ; } Most events concern a specific repository, and hence most listener invocations extend RepoContext : export interface RepoContext extends SdmContext { /** * The repo this relates to. Fields include `owner`, `repo`, `sha` and `branch` */ id : RemoteRepoRef ; } Many repo-specific listeners are given access to the repository source, via the Project abstraction: export interface ProjectListenerInvocation extends RepoListenerInvocation { /** * The project to which this event relates. It will have been cloned * prior to this invocation. Modifications made during listener invocation will * not be committed back to the project (although they are acceptable if necessary, for * example to run particular commands against the project). * As well as working with * project files using the Project superinterface, we can use git-related * functionality fro the GitProject subinterface: For example to check * for previous shas. * We can also easily run shell commands against the project using its baseDir. */ project : GitProject ; } The Project interface provides an abstraction to the present repository, with Atomist taking care of Git cloning and (if necessary) writing back any changes via a push. It is abstracted from the file system, making it easy to unit test with mocked repository contents, using the InMemoryProject and InMemoryFile classes. Note The Project API and sophisticated parsing functionality available on top of it is a core Atomist capability. Many events can only be understood in the context of the impacted code, and many actions are achieved by modifying code. Push listeners also have access to the details of the relevant push: export interface PushListenerInvocation extends ProjectListenerInvocation { /** * Information about the push, including repo and commit */ readonly push : OnPushToAnyBranch.Push ; }","title":"Invocations"},{"location":"developer/local/","text":"When you run an SDM in local mode, it operates in the privacy of your laptop. Everything is open source. This SDM can: run goals in respond to a commit the SDM can run your tests in the background deploy locally, and be sure that you\u2019re doing manual testing on committed code apply autofixes directly in your repository check code inspections and tell you when you\u2019ve violated them execute commands generate new projects perform transforms on one repository or on many repositories do inspections on one or many repositories In local mode, events come in from local commits (with git hooks) and from within the SDM. Directory structure In local mode, an SDM looks for projects on your filesystem. It looks in only one place: the Atomist projects root. This defaults to $HOME/atomist/projects . Override this location by setting an ATOMIST_ROOT environment variable (it\u2019ll still expect a projects directory under it), or by providing local.repositoryOwnerParentDirectory in your SDM\u2019s configuration . Underneath the projects root directory are directories for each project owner (GitHub user or organization; BitBucket project). Underneath each owner directory are all the projects belonging to it. Each project is a directory and a git repository. atomist clone When you run atomist clone <clone url> , atomist puts the cloned project under the projects directory, under its owner. It also installs git hooks so that commits to that project will trigger push events. atomist feed When your SDM is running in local mode in the background, it wants to send you messages. When it hears about a commit to one of your projects, it sends messages about that. When you run a command with the atomist CLI, it sends messages both to where you ran the command and to the feed. Type atomist feed to start up a terminal-based message receiver. Some of these messages contain action-links. These correspond to buttons on chat messages. In iTerm2 on Mac, I can Ctrl-click on these to open them, which triggers my SDM to run the action. It also works to paste the link into the browser. In the browser, you\u2019ll see the JSON response. Check your atomist feed window to see messages about the results of the action. See also: troubleshooting Differences from team mode No connection to the Atomist service Push events come from git hooks on each commit Repositories are cloned from the local filesystem Messages go to the terminal running atomist feed (and for commands, also where you ran them) Nothing happens in GitHub, only locally Some events are not available. See the list of listeners for the full list.","title":"Local Mode"},{"location":"developer/local/#directory-structure","text":"In local mode, an SDM looks for projects on your filesystem. It looks in only one place: the Atomist projects root. This defaults to $HOME/atomist/projects . Override this location by setting an ATOMIST_ROOT environment variable (it\u2019ll still expect a projects directory under it), or by providing local.repositoryOwnerParentDirectory in your SDM\u2019s configuration . Underneath the projects root directory are directories for each project owner (GitHub user or organization; BitBucket project). Underneath each owner directory are all the projects belonging to it. Each project is a directory and a git repository.","title":"Directory structure"},{"location":"developer/local/#atomist-clone","text":"When you run atomist clone <clone url> , atomist puts the cloned project under the projects directory, under its owner. It also installs git hooks so that commits to that project will trigger push events.","title":"atomist clone"},{"location":"developer/local/#atomist-feed","text":"When your SDM is running in local mode in the background, it wants to send you messages. When it hears about a commit to one of your projects, it sends messages about that. When you run a command with the atomist CLI, it sends messages both to where you ran the command and to the feed. Type atomist feed to start up a terminal-based message receiver. Some of these messages contain action-links. These correspond to buttons on chat messages. In iTerm2 on Mac, I can Ctrl-click on these to open them, which triggers my SDM to run the action. It also works to paste the link into the browser. In the browser, you\u2019ll see the JSON response. Check your atomist feed window to see messages about the results of the action. See also: troubleshooting","title":"atomist feed"},{"location":"developer/local/#differences-from-team-mode","text":"No connection to the Atomist service Push events come from git hooks on each commit Repositories are cloned from the local filesystem Messages go to the terminal running atomist feed (and for commands, also where you ran them) Nothing happens in GitHub, only locally Some events are not available. See the list of listeners for the full list.","title":"Differences from team mode"},{"location":"developer/logging/","text":"Logging inside an SDM comes in two varieties. The important logs are the progress logs of goal executions. These are transmitted to a logging service, so that the goals can link to them. Then there are logs for the SDM itself, where it outputs information about its operation. These go to stdout. Goal Progress Logs To write to these within a goal execution, call invocation.progressLog.write(\"stuff\") . You can also send output from an external command . In local mode , goal progress logs all go to a single file in $HOME/.atomist/log . When a goal fails, that file\u2019s path is printed to the feed . In team mode , goal progress logs are sent to Atomist\u2019s log service. Each goal, as reported in chat or on the web interface, links to its progress log. To see it, you must be logged in to the Atomist web interface. When goal output is short, it is also sent to the SDM logs. Custom Progress Logs To send goal progress logs somewhere else, implement ProgressLogFactory and then set logFactory in SDM Configuration. In index.ts : const configuration : Configuration & Partial < SoftwareDeliveryMachineOptions > = { //... sdm : { logFactory : new MySpecialProgressLogFactory (); } // ... } SDM Logs To log to the operational SDM logs, import logger from automation-client. This wraps the winston library. import { logger } from \"@atomist/automation-client\" ; logger . info ( \"This is nice\" ); Configuring SDM Logs You can set the log level in the configuration object in index.ts: logging : { level : \"info\" , // \"warn\" | \"error\" | \"debug\" } You can enable logging to a file at a different level; see API Docs . Custom log transports If you want to send operational SDM logs to a place of your choosing, you can add a custom log transport. There is an example in Atomist\u2019s own SDM. To add logzio support, it registers a postProcessor, which gets called after the SDM configuration is loaded: code , This can modify the configuration: code . In that postProcessor, a new custom logging transport is added: code . That postProcessor also adds a listener to SDM operational events. Logging in tests If you want to turn on logging in a mocha test, put before(() => configureLogging(MinimalLogging)); within the the outermost describe .","title":"Logging"},{"location":"developer/logging/#goal-progress-logs","text":"To write to these within a goal execution, call invocation.progressLog.write(\"stuff\") . You can also send output from an external command . In local mode , goal progress logs all go to a single file in $HOME/.atomist/log . When a goal fails, that file\u2019s path is printed to the feed . In team mode , goal progress logs are sent to Atomist\u2019s log service. Each goal, as reported in chat or on the web interface, links to its progress log. To see it, you must be logged in to the Atomist web interface. When goal output is short, it is also sent to the SDM logs.","title":"Goal Progress Logs"},{"location":"developer/logging/#custom-progress-logs","text":"To send goal progress logs somewhere else, implement ProgressLogFactory and then set logFactory in SDM Configuration. In index.ts : const configuration : Configuration & Partial < SoftwareDeliveryMachineOptions > = { //... sdm : { logFactory : new MySpecialProgressLogFactory (); } // ... }","title":"Custom Progress Logs"},{"location":"developer/logging/#sdm-logs","text":"To log to the operational SDM logs, import logger from automation-client. This wraps the winston library. import { logger } from \"@atomist/automation-client\" ; logger . info ( \"This is nice\" );","title":"SDM Logs"},{"location":"developer/logging/#configuring-sdm-logs","text":"You can set the log level in the configuration object in index.ts: logging : { level : \"info\" , // \"warn\" | \"error\" | \"debug\" } You can enable logging to a file at a different level; see API Docs .","title":"Configuring SDM Logs"},{"location":"developer/logging/#custom-log-transports","text":"If you want to send operational SDM logs to a place of your choosing, you can add a custom log transport. There is an example in Atomist\u2019s own SDM. To add logzio support, it registers a postProcessor, which gets called after the SDM configuration is loaded: code , This can modify the configuration: code . In that postProcessor, a new custom logging transport is added: code . That postProcessor also adds a listener to SDM operational events.","title":"Custom log transports"},{"location":"developer/logging/#logging-in-tests","text":"If you want to turn on logging in a mocha test, put before(() => configureLogging(MinimalLogging)); within the the outermost describe .","title":"Logging in tests"},{"location":"developer/parseutils/","text":"When you want to look for or change a particular piece of code, we have our algorithms for that when we\u2019re using our eyes. For instance, \u201cI want to find all files that import this class, so I will look at the top of a file for lines that start with \u2018import\u2019 and include the class\u2019s name or its package.\u201d You could duplicate that with regular expressions, running over each file. But regular expressions don\u2019t work well across lines, they\u2019re cryptic as all get out, and their complexity scales exponentially with their intricacy. Atomist lets you seek out and update code with a relatively intuitive parsing language, that asks you to describe only the piece of code you want to see (not the whole file), in a way that\u2019s more bearable than regular expressions at a medium scale. The parseUtils collection of functions helps you work with a Project using microgrammars. microgrammar library parseUtils API Doc Writing a microgrammar You\u2019ll want to npm install @atomist/microgrammar to get the latest library version. Then, envision the code that you want, and replace the varying bits with ${variables} . For instance, if you wanted to know what functions from the lodash library your TypeScript code uses, you might look for code like: _.${functionName}( You don\u2019t care about anything after the opening parenthesis. lodash is always referred to by the name _ , by convention. And conventions are good enough, because your code inspection and transform don\u2019t have to work on all the code in the world. They only need to work on the code in your projects. Once you have that string (it\u2019s called a \u201cphrase\u201d here), you will want to describe what the contents of each variable might contain. ${functionName} is definitely going to be a valid JavaScript function identifier. More than valid, it\u2019s going to be an ordinary one, nothing weird. We can describe it with a very simple regular expression. Do this in an object, and this object becomes a TermsDefinition . { functionName : /[a-zA-Z0-9_]/ , } Pass these two things in: const lodashFunctionCallMicrogrammar = microgrammar ({ phrase : \"_.${functionName}(\" , terms : { functionName : /[a-zA-Z0-9_]/ , } }); Pointers: If you don\u2019t provide a definition for a variable that you use in the phrase, it will match whatever exists before the next token. In this case, if we hadn\u2019t defined functionName as a term, it would have matched any text until the next opening parenthesis. (watch out: don\u2019t put an undefined variable like this at the end of your phrase. It needs to have something after it, or else be defined in the terms.) If you put a space (or newline, etc) between any variables or any other words in the phrase, this is interpreted as \u201cany amount of whitespace.\u201d You can put ... in your phrase to match any characters up to the next whatever-comes-next. The term definitions can be string literals, regular expressions, or other microgrammars. Handy microgrammars to compose: RestOfLine JavaBlock optional(anotherMicrogrammar) atLeastOne(anotherMicrogrammar) zeroOrMore(anotherMicrogrammar) firstOf(possibleMicrogrammar, anotherPossibleMicrogrammar, \u2026) For more details on how to write a microgrammar, check out the microgrammar library , especially the string-based definition examples . finding code that looks like this Within your SDM, you can use parseUtils.findMatches to locate all of the code that looks like your microgrammar in your entire project. If you want to know what functions from lodash you use, you could do this: import { parseUtils } from \"@atomist/automation-client\" ; import { microgrammar } from \"@atomist/microgrammar\" ; import * as _ from \"lodash\" ; const lodashFunctionCallMicrogrammar = microgrammar < { functionName : string } > ({ phrase : \"_.${functionName}(\" , terms : { functionName : /[a-zA-Z0-9_]/ , }, }); const matches = await parseUtils . findMatches ( project , \"**/*.ts\" , lodashFunctionCallMicrogrammar ); const functionsCalledOnLodash = _ . uniq ( matches . map ( m => m . functionName )); Notice that here, the microgrammar constructor function accepts a type parameter that describes the terms on the microgrammar. If this type matches the structure of the grammar, then those properties will exist on the returned match. If you also want information on the file that each match is in, then check out parseUtils.findFileMatches . changing code that looks like this You can update the matched code in place. To do this, use a different function: parseUtils.doWithMatches . This lets you pass in an action, which can update the properties on the match. If you wanted to change some of the function calls on lodash, you could do this: import { parseUtils } from \"@atomist/automation-client\" ; import { microgrammar } from \"@atomist/microgrammar\" ; import * as _ from \"lodash\" ; const lodashFunctionCallMicrogrammar = microgrammar < { functionName : string } > ({ phrase : \"_.${functionName}(\" , terms : { functionName : /[a-zA-Z0-9_]/ , }, }); await parseUtils . doWithMatches ( project , \"**/*.ts\" , lodashFunctionCallMicrogrammar , m => { if ( m . functionName === \"oldBoringFunction\" ) { m . functionName = \"newExcitingFunction\" ; } }); This will change the code in every .ts file in the project that called _.oldBoringFunction to call _.newExcitingFunction instead. Put this kind of stuff in your code transforms . Note: if you want information about the file that the match is in, try parseUtil.doWithFileMatches . See also the Project API do simpler manipulations of file content with projectUtils dig into the abstract syntax tree (AST) of your programming language with astUtils","title":"Parseutils"},{"location":"developer/parseutils/#writing-a-microgrammar","text":"You\u2019ll want to npm install @atomist/microgrammar to get the latest library version. Then, envision the code that you want, and replace the varying bits with ${variables} . For instance, if you wanted to know what functions from the lodash library your TypeScript code uses, you might look for code like: _.${functionName}( You don\u2019t care about anything after the opening parenthesis. lodash is always referred to by the name _ , by convention. And conventions are good enough, because your code inspection and transform don\u2019t have to work on all the code in the world. They only need to work on the code in your projects. Once you have that string (it\u2019s called a \u201cphrase\u201d here), you will want to describe what the contents of each variable might contain. ${functionName} is definitely going to be a valid JavaScript function identifier. More than valid, it\u2019s going to be an ordinary one, nothing weird. We can describe it with a very simple regular expression. Do this in an object, and this object becomes a TermsDefinition . { functionName : /[a-zA-Z0-9_]/ , } Pass these two things in: const lodashFunctionCallMicrogrammar = microgrammar ({ phrase : \"_.${functionName}(\" , terms : { functionName : /[a-zA-Z0-9_]/ , } }); Pointers: If you don\u2019t provide a definition for a variable that you use in the phrase, it will match whatever exists before the next token. In this case, if we hadn\u2019t defined functionName as a term, it would have matched any text until the next opening parenthesis. (watch out: don\u2019t put an undefined variable like this at the end of your phrase. It needs to have something after it, or else be defined in the terms.) If you put a space (or newline, etc) between any variables or any other words in the phrase, this is interpreted as \u201cany amount of whitespace.\u201d You can put ... in your phrase to match any characters up to the next whatever-comes-next. The term definitions can be string literals, regular expressions, or other microgrammars. Handy microgrammars to compose: RestOfLine JavaBlock optional(anotherMicrogrammar) atLeastOne(anotherMicrogrammar) zeroOrMore(anotherMicrogrammar) firstOf(possibleMicrogrammar, anotherPossibleMicrogrammar, \u2026) For more details on how to write a microgrammar, check out the microgrammar library , especially the string-based definition examples .","title":"Writing a microgrammar"},{"location":"developer/parseutils/#finding-code-that-looks-like-this","text":"Within your SDM, you can use parseUtils.findMatches to locate all of the code that looks like your microgrammar in your entire project. If you want to know what functions from lodash you use, you could do this: import { parseUtils } from \"@atomist/automation-client\" ; import { microgrammar } from \"@atomist/microgrammar\" ; import * as _ from \"lodash\" ; const lodashFunctionCallMicrogrammar = microgrammar < { functionName : string } > ({ phrase : \"_.${functionName}(\" , terms : { functionName : /[a-zA-Z0-9_]/ , }, }); const matches = await parseUtils . findMatches ( project , \"**/*.ts\" , lodashFunctionCallMicrogrammar ); const functionsCalledOnLodash = _ . uniq ( matches . map ( m => m . functionName )); Notice that here, the microgrammar constructor function accepts a type parameter that describes the terms on the microgrammar. If this type matches the structure of the grammar, then those properties will exist on the returned match. If you also want information on the file that each match is in, then check out parseUtils.findFileMatches .","title":"finding code that looks like this"},{"location":"developer/parseutils/#changing-code-that-looks-like-this","text":"You can update the matched code in place. To do this, use a different function: parseUtils.doWithMatches . This lets you pass in an action, which can update the properties on the match. If you wanted to change some of the function calls on lodash, you could do this: import { parseUtils } from \"@atomist/automation-client\" ; import { microgrammar } from \"@atomist/microgrammar\" ; import * as _ from \"lodash\" ; const lodashFunctionCallMicrogrammar = microgrammar < { functionName : string } > ({ phrase : \"_.${functionName}(\" , terms : { functionName : /[a-zA-Z0-9_]/ , }, }); await parseUtils . doWithMatches ( project , \"**/*.ts\" , lodashFunctionCallMicrogrammar , m => { if ( m . functionName === \"oldBoringFunction\" ) { m . functionName = \"newExcitingFunction\" ; } }); This will change the code in every .ts file in the project that called _.oldBoringFunction to call _.newExcitingFunction instead. Put this kind of stuff in your code transforms . Note: if you want information about the file that the match is in, try parseUtil.doWithFileMatches .","title":"changing code that looks like this"},{"location":"developer/parseutils/#see-also","text":"the Project API do simpler manipulations of file content with projectUtils dig into the abstract syntax tree (AST) of your programming language with astUtils","title":"See also"},{"location":"developer/prerequisites/","text":"You can run a Software Delivery Machine (SDM) locally without any signup or authentication. See the Developer Quick Start to get started. This document describes the prerequisites for running an SDM for your whole team , connecting to your source control manager, chat system, and continuous integration tools. Before you begin developing and running your own software deliver machine (SDM), you need an Atomist account and several other prerequisites. Atomist workspace As part of creating an account with Atomist, you created an Atomist workspace. To run SDMs, you will need the ID of your Atomist workspace. You can find your Atomist workspace ID on your workspace\u2019s settings page in the Atomist web application . Node.js The reference implementation of the Atomist SDM is implemented in TypeScript , a superset of JavaScript . To develop and run it, you must install Node.js. The easiest way to install Node.js is to go to the Node.js web site and follow the installation instructions for your platform. This makes the node and npm programs available on your system. Alternatively, macOS users with Homebrew can install Node.js with the following command: brew install node Once you have node and npm available, it is a good idea to update to the latest version of npm using the following command. npm install -g npm Git Atomist supports software development using Git and uses the Git command-line tool to perform many of its actions. You must have the Git CLI installed for Atomist tools to function properly. Atomist CLI The Atomist CLI performs several useful functions that are referred to throughout this documentation. Once you have Node.js installed, install the Atomist CLI with the following command: npm install -g @atomist/cli Installation on GNU/Linux On GNU/Linux systems, including when running in a Docker environment, you may need to add the --unsafe-perm=true --allow-root command-line options to the above command to avoid permission errors and successfully install. If you are using Homebrew on macOS, you can install the Atomist CLI with the following command: brew install atomist-cli Atomist API key To start your own SDM, you will need an Atomist API key so the client can properly register with the API. You can generate an Atomist API key on the API key page of the Atomist web application . You will need an Atomist API key in the next section when running configure. Configure There are a few ways you can configure Atomist SDMs. While any of the approaches below will work in any scenario, some approaches are better for some use cases than others. If you are developing an SDM and running it locally on your workstation or laptop, user configuration is likely your best choice. If you are running an SDM on a server in a testing or production environment, you will likely want to use the environment variable approach. Regardless of the approach you take, the minimum information required to successfully start an SDM is an API key and a workspace ID . Depending on the SDM or other client you are trying to run, you may need to provide more configuration values. User configuration If you have a user configuration file on your system, it will be read and merged with any client-specific configuration whenever you start an SDM. In other words, it serves as a base configuration for all SDMs you run on your system. Run the following command to create and persist a user configuration on your local system. atomist config The above command will prompt you for your Atomist API key and workspace ID. The user configuration is a JSON-formatted object saved in the file $HOME/.atomist/client.config.json on Unix-like operating systems including macOS and %USERPROFILE%\\.atomist\\client.config.json on MS Windows operating systems. After running the above command, the contents of the user configuration file will look something like: { \"apiKey\" : \"API_KEY\" , \"workspaceIds\" : [ \"WORKSPACE_ID\" ] } with API_KEY and WORKSPACE_ID replaced with your Atomist API key and workspace ID, respectively. If you are in multiple Atomist workspaces and want to run your SDMs in all of them, simply add all of their workspace IDs to the workspaceIds array in the user configuration file. Environment variable When running an SDM on a server, especially when running in a containerized environment, it is typically better to provide the necessary configuration using environment variables. When an SDM starts up, it will attempt to parse a JSON-formatted configuration object from the ATOMIST_CONFIG environment variable and from the file provided by the ATOMIST_CONFIG_PATH environment variable. For example, to use the ATOMIST_CONFIG environment variable to provide the same configuration as that shown above in the user configuration section, you could run the following commands to set the environment variable and start the client. export ATOMIST_CONFIG='{\"apiKey\":\"API_KEY\",\"workspaceIds\":[\"WORKSPACE_ID\"]}' atomist start Similarly, if you created a file with the same contents as that show above in the user configuration section at /opt/sdm/sdm-config.json , then you tell the SDM to load that file by setting the following environment variable prior to starting the SDM. export ATOMIST_CONFIG_PATH=/opt/sdm/sdm-config.json atomist start If both environment variables are defined, their configuration values are merged with values in the ATOMIST_CONFIG environment variable taking precedence over those defined in the ATOMIST_CONFIG_PATH file. If the user configuration file also exists, its values are also merged in with lower precedence than either environment variable.","title":"Prerequisites"},{"location":"developer/prerequisites/#atomist-workspace","text":"As part of creating an account with Atomist, you created an Atomist workspace. To run SDMs, you will need the ID of your Atomist workspace. You can find your Atomist workspace ID on your workspace\u2019s settings page in the Atomist web application .","title":"Atomist workspace"},{"location":"developer/prerequisites/#nodejs","text":"The reference implementation of the Atomist SDM is implemented in TypeScript , a superset of JavaScript . To develop and run it, you must install Node.js. The easiest way to install Node.js is to go to the Node.js web site and follow the installation instructions for your platform. This makes the node and npm programs available on your system. Alternatively, macOS users with Homebrew can install Node.js with the following command: brew install node Once you have node and npm available, it is a good idea to update to the latest version of npm using the following command. npm install -g npm","title":"Node.js"},{"location":"developer/prerequisites/#git","text":"Atomist supports software development using Git and uses the Git command-line tool to perform many of its actions. You must have the Git CLI installed for Atomist tools to function properly.","title":"Git"},{"location":"developer/prerequisites/#atomist-cli","text":"The Atomist CLI performs several useful functions that are referred to throughout this documentation. Once you have Node.js installed, install the Atomist CLI with the following command: npm install -g @atomist/cli Installation on GNU/Linux On GNU/Linux systems, including when running in a Docker environment, you may need to add the --unsafe-perm=true --allow-root command-line options to the above command to avoid permission errors and successfully install. If you are using Homebrew on macOS, you can install the Atomist CLI with the following command: brew install atomist-cli","title":"Atomist CLI"},{"location":"developer/prerequisites/#atomist-api-key","text":"To start your own SDM, you will need an Atomist API key so the client can properly register with the API. You can generate an Atomist API key on the API key page of the Atomist web application . You will need an Atomist API key in the next section when running configure.","title":"Atomist API key"},{"location":"developer/prerequisites/#configure","text":"There are a few ways you can configure Atomist SDMs. While any of the approaches below will work in any scenario, some approaches are better for some use cases than others. If you are developing an SDM and running it locally on your workstation or laptop, user configuration is likely your best choice. If you are running an SDM on a server in a testing or production environment, you will likely want to use the environment variable approach. Regardless of the approach you take, the minimum information required to successfully start an SDM is an API key and a workspace ID . Depending on the SDM or other client you are trying to run, you may need to provide more configuration values.","title":"Configure"},{"location":"developer/prerequisites/#user-configuration","text":"If you have a user configuration file on your system, it will be read and merged with any client-specific configuration whenever you start an SDM. In other words, it serves as a base configuration for all SDMs you run on your system. Run the following command to create and persist a user configuration on your local system. atomist config The above command will prompt you for your Atomist API key and workspace ID. The user configuration is a JSON-formatted object saved in the file $HOME/.atomist/client.config.json on Unix-like operating systems including macOS and %USERPROFILE%\\.atomist\\client.config.json on MS Windows operating systems. After running the above command, the contents of the user configuration file will look something like: { \"apiKey\" : \"API_KEY\" , \"workspaceIds\" : [ \"WORKSPACE_ID\" ] } with API_KEY and WORKSPACE_ID replaced with your Atomist API key and workspace ID, respectively. If you are in multiple Atomist workspaces and want to run your SDMs in all of them, simply add all of their workspace IDs to the workspaceIds array in the user configuration file.","title":"User configuration"},{"location":"developer/prerequisites/#environment-variable","text":"When running an SDM on a server, especially when running in a containerized environment, it is typically better to provide the necessary configuration using environment variables. When an SDM starts up, it will attempt to parse a JSON-formatted configuration object from the ATOMIST_CONFIG environment variable and from the file provided by the ATOMIST_CONFIG_PATH environment variable. For example, to use the ATOMIST_CONFIG environment variable to provide the same configuration as that shown above in the user configuration section, you could run the following commands to set the environment variable and start the client. export ATOMIST_CONFIG='{\"apiKey\":\"API_KEY\",\"workspaceIds\":[\"WORKSPACE_ID\"]}' atomist start Similarly, if you created a file with the same contents as that show above in the user configuration section at /opt/sdm/sdm-config.json , then you tell the SDM to load that file by setting the following environment variable prior to starting the SDM. export ATOMIST_CONFIG_PATH=/opt/sdm/sdm-config.json atomist start If both environment variables are defined, their configuration values are merged with values in the ATOMIST_CONFIG environment variable taking precedence over those defined in the ATOMIST_CONFIG_PATH file. If the user configuration file also exists, its values are also merged in with lower precedence than either environment variable.","title":"Environment variable"},{"location":"developer/project/","text":"The Project abstraction lets us write code to understand and modify code, at a level above the filesystem. A Project represents the contents of a repository at a particular point in time. For most SDM operations, it is backed by a clone of the repository on the filesystem. For testing, you can use a project backed by a local directory or stored in memory . See the API Doc for the full interface, and the methods in projectUtils for related helpers. Obtaining a Project The SDM has many APIs where you define a function that receives a Project as an argument. For instance, code transforms and code inspections receive already-cloned projects. A push test gets a Project to look at, which is cloned lazily if the push test uses it. If you\u2019re working in another goal, then you have access to a GoalInvocation , and you can get request a clone and then do something with it. See an example under running a command . For Testing To get a project for testing, use [InMemoryProject][apidoc-imp] . Its of factory method accepts any number of objects. Each specifies the path and contents of a file in the project. For example: const input = InMemoryProject . of ({ path : \"README.me\" , content : `# Hello There and some stuff ` , }, { path : \"empty.md\" , content : \"\" , }); This example uses TypeScript\u2019s multiline strings (delimited with backtick) to specify the file content. Checking the content There are many ways to look around the Project. Does a particular file exist? Call hasFile on the project. const hasMyFile = await project . hasFile ( \"path/to/file\" ); There is also hasDirectory to check for directory existence. What is in a file? Call getFile and then getContent . const myFile = await project . getFile ( \"path/to/file\" ); if ( myFile ) { const content : string = await myFile . getContent (); } Does a file exist, for various conditions? Use projectUtils.fileExists to look for files with a certain extension or property. The second argument is a glob , and the third is a function from File to boolean. const result = await projectUtils . fileExists ( project , \"**/*\" , f => f . isExecutable () ); Extract information from files Use projectUtils.gatherFromFiles to extract information from all the files with matching names. Pass the project, a glob , and a function from File to whatever it is you want to get back. This example returns an array with the first line of every Java file: const firstLines = await gatherFromFiles < string > ( project , \"**/*.java\" , async f => { const lines = await f . getContent (). then ( c => c . split ( \"\\n\" )); return lines . length > 0 ? lines [ 0 ] : \"\" ; }) File Globs Serveral methods in [projectUtils][apidoc-projectUtils] accept a GlobOptions as a parameter. The GlobOptions is a string or an array of strings. In a glob: * `*` stands for any string or part of a string in a filename * `**` stands for any number of directories, so matches recursively in a path * Pass any number of pattern strings to include, followed by any number of negative patterns to exclude * Start a pattern with `!` to make it a negation For example, all TypeScript files that aren\u2019t tests: [\"**/*.ts\", \"!**/*.test.ts\"] Parse Code Code is more than text. Express what you\u2019re looking for in terms of your programming language using Atomist Path Expressions . Modifying the content Check the Project API for methods like: addFile deleteFile deleteDirectory (and all its content) makeExecutable (give a file execute permissions) moveFile Update Code Code is more than text. Change code in place based on contextual understanding. Use Path Expressions . Saving modifications If you\u2019re writing a code transform , your changes will be saved for you, by a commit in an autofix or in a pull request in a transform command . If you\u2019re writing a custom goal of some kind, and working with a clone that you requested, then check the GitProject interface for methods like: commit createBranch push raisePullRequest checkout hasBranch Accessing the filesystem directly If the Project is on the filesystem (usually a GitProject ), then project.baseDir will give you its path on the filesystem.","title":"Project"},{"location":"developer/project/#obtaining-a-project","text":"The SDM has many APIs where you define a function that receives a Project as an argument. For instance, code transforms and code inspections receive already-cloned projects. A push test gets a Project to look at, which is cloned lazily if the push test uses it. If you\u2019re working in another goal, then you have access to a GoalInvocation , and you can get request a clone and then do something with it. See an example under running a command .","title":"Obtaining a Project"},{"location":"developer/project/#for-testing","text":"To get a project for testing, use [InMemoryProject][apidoc-imp] . Its of factory method accepts any number of objects. Each specifies the path and contents of a file in the project. For example: const input = InMemoryProject . of ({ path : \"README.me\" , content : `# Hello There and some stuff ` , }, { path : \"empty.md\" , content : \"\" , }); This example uses TypeScript\u2019s multiline strings (delimited with backtick) to specify the file content.","title":"For Testing"},{"location":"developer/project/#checking-the-content","text":"There are many ways to look around the Project.","title":"Checking the content"},{"location":"developer/project/#does-a-particular-file-exist","text":"Call hasFile on the project. const hasMyFile = await project . hasFile ( \"path/to/file\" ); There is also hasDirectory to check for directory existence.","title":"Does a particular file exist?"},{"location":"developer/project/#what-is-in-a-file","text":"Call getFile and then getContent . const myFile = await project . getFile ( \"path/to/file\" ); if ( myFile ) { const content : string = await myFile . getContent (); }","title":"What is in a file?"},{"location":"developer/project/#does-a-file-exist-for-various-conditions","text":"Use projectUtils.fileExists to look for files with a certain extension or property. The second argument is a glob , and the third is a function from File to boolean. const result = await projectUtils . fileExists ( project , \"**/*\" , f => f . isExecutable () );","title":"Does a file exist, for various conditions?"},{"location":"developer/project/#extract-information-from-files","text":"Use projectUtils.gatherFromFiles to extract information from all the files with matching names. Pass the project, a glob , and a function from File to whatever it is you want to get back. This example returns an array with the first line of every Java file: const firstLines = await gatherFromFiles < string > ( project , \"**/*.java\" , async f => { const lines = await f . getContent (). then ( c => c . split ( \"\\n\" )); return lines . length > 0 ? lines [ 0 ] : \"\" ; })","title":"Extract information from files"},{"location":"developer/project/#file-globs","text":"Serveral methods in [projectUtils][apidoc-projectUtils] accept a GlobOptions as a parameter. The GlobOptions is a string or an array of strings. In a glob: * `*` stands for any string or part of a string in a filename * `**` stands for any number of directories, so matches recursively in a path * Pass any number of pattern strings to include, followed by any number of negative patterns to exclude * Start a pattern with `!` to make it a negation For example, all TypeScript files that aren\u2019t tests: [\"**/*.ts\", \"!**/*.test.ts\"]","title":"File Globs"},{"location":"developer/project/#parse-code","text":"Code is more than text. Express what you\u2019re looking for in terms of your programming language using Atomist Path Expressions .","title":"Parse Code"},{"location":"developer/project/#modifying-the-content","text":"Check the Project API for methods like: addFile deleteFile deleteDirectory (and all its content) makeExecutable (give a file execute permissions) moveFile","title":"Modifying the content"},{"location":"developer/project/#update-code","text":"Code is more than text. Change code in place based on contextual understanding. Use Path Expressions .","title":"Update Code"},{"location":"developer/project/#saving-modifications","text":"If you\u2019re writing a code transform , your changes will be saved for you, by a commit in an autofix or in a pull request in a transform command . If you\u2019re writing a custom goal of some kind, and working with a clone that you requested, then check the GitProject interface for methods like: commit createBranch push raisePullRequest checkout hasBranch","title":"Saving modifications"},{"location":"developer/project/#accessing-the-filesystem-directly","text":"If the Project is on the filesystem (usually a GitProject ), then project.baseDir will give you its path on the filesystem.","title":"Accessing the filesystem directly"},{"location":"developer/projectutils/","text":"Code inspections and transforms work with the code inside repositories. You can use the Project API for simple actions like adding or removing a file. When you want to work on multiple files, Atomist project utils can help. API Doc gathering information from files In a code inspection , you might want to look at every file and put some information together. Try gatherFromFiles . For example, this gathers the path and number of lines in every YAML file: import { projectUtils } from \"@atomist/automation-client\" ; const fileAndLineCount = await projectUtils . gatherFromFiles ( p , [ \"**/*.yml\" , \"**/*.yaml\" ], async file => ( { path : file.path , lines : ( await file . getContent ()). split ( \"\\n\" ). length , })); running an action on files In a code transform , you might want to change the contents of many files. Use doWithFiles for this. For example, if you want to mix up the word Atomist everywhere it appears in every Java file: await projectUtils . doWithFiles ( project , \"**/*.java\" , f => f . replaceAll ( \"atomist\" , _ . shuffle ( \"atomist\" . split ( \"\" )). join ( \"\" ))); See also the Project API get at the relevant parts of files with microgrammars and parseUtils dig into the abstract syntax tree (AST) of your programming language with astUtils","title":"Projectutils"},{"location":"developer/projectutils/#gathering-information-from-files","text":"In a code inspection , you might want to look at every file and put some information together. Try gatherFromFiles . For example, this gathers the path and number of lines in every YAML file: import { projectUtils } from \"@atomist/automation-client\" ; const fileAndLineCount = await projectUtils . gatherFromFiles ( p , [ \"**/*.yml\" , \"**/*.yaml\" ], async file => ( { path : file.path , lines : ( await file . getContent ()). split ( \"\\n\" ). length , }));","title":"gathering information from files"},{"location":"developer/projectutils/#running-an-action-on-files","text":"In a code transform , you might want to change the contents of many files. Use doWithFiles for this. For example, if you want to mix up the word Atomist everywhere it appears in every Java file: await projectUtils . doWithFiles ( project , \"**/*.java\" , f => f . replaceAll ( \"atomist\" , _ . shuffle ( \"atomist\" . split ( \"\" )). join ( \"\" )));","title":"running an action on files"},{"location":"developer/projectutils/#see-also","text":"the Project API get at the relevant parts of files with microgrammars and parseUtils dig into the abstract syntax tree (AST) of your programming language with astUtils","title":"See also"},{"location":"developer/push-test/","text":"A PushTest tests an aspect of a push at a point in time. Most push tests test the Project returned by the push: that is, the state of the repository after the push. However push tests can also look at the push itself: for example, considering the branch or commit message. Push tests are a central part of the Atomist API, being combined in push rules to determine how to handle pushes and drive delivery. Push tests are often reused, so it is good practice to extract them into constants. Many extension packs export push test constants. API Doc Examples include: Is this a Java project? Was this a push to the default branch? Did a specific file change? A push test maps from a PushListenerInvocation to a Promise<boolean> . It decides whether this push is relevant (true) or not relevant (false), returning a Promise so that it can invoke asynchronous operations. To help your test make a decision, the PushListenerInvocation provides push: context around the push itself, such as the before and after commits, who made it, the repository name, and more. project: access to the code, through the Project interface the inherited RepoContext fields common to all SDM events Creating push tests When you only need the project, use the predicatePushTest function: import { predicatePushTest } from \"@atomist/sdm\" ; export const IsMkdocsProject = predicatePushTest ( \"IsMkdocsProject\" , project => project . hasFile ( \"mkdocs.yml\" )); For maximum flexibility, construct a push test with a name and a mapping function. This provides access to both the push and project. The previous example would look like this: import { pushTest } from \"@atomist/sdm\" ; export const IsMkdocsProject = pushTest ( \"IsMkdocsProject\" , ( pli : PushListenerInvocation ) : Promise < boolean > => { return pli . project . hasFile ( \"mkdocs.yml\" ); }); This allows us to check the push itself. For example: import { pushTest } from \"@atomist/sdm\" ; export const ToDefaultBranch = pushTest ( \"ToDefaultBranch\" , async pu => pu . push . branch === pu . repo . defaultBranch ); Testing push tests As with the rest of the SDM API, we can write unit tests for push tests. This helps ensure that the decisions made in our delivery flows are solid. The following example uses Mocha and construct in memory projects and verify the behavior of the above push tests. describe ( \"IsMkdocsProject\" , () => { it ( \"should not find MkDocs in empty repo\" , async () => { const project = InMemoryProject . of (); // We need to cast as we want to ignore properties other than project of the invocation const r = await IsMkdocsProject . mapping ({ project } as any as PushListenerInvocation ); assert ( ! r ); }); it ( \"should find Mkdocs in repo with mkdocs file\" , async () => { const project = InMemoryProject . of ({ path : \"mkdocs.yml\" , content : \"here: yes\" }); const r = await IsMkdocsProject . mapping ({ project } as any as PushListenerInvocation ); assert ( r ); }); ... }","title":"Push Tests"},{"location":"developer/push-test/#creating-push-tests","text":"When you only need the project, use the predicatePushTest function: import { predicatePushTest } from \"@atomist/sdm\" ; export const IsMkdocsProject = predicatePushTest ( \"IsMkdocsProject\" , project => project . hasFile ( \"mkdocs.yml\" )); For maximum flexibility, construct a push test with a name and a mapping function. This provides access to both the push and project. The previous example would look like this: import { pushTest } from \"@atomist/sdm\" ; export const IsMkdocsProject = pushTest ( \"IsMkdocsProject\" , ( pli : PushListenerInvocation ) : Promise < boolean > => { return pli . project . hasFile ( \"mkdocs.yml\" ); }); This allows us to check the push itself. For example: import { pushTest } from \"@atomist/sdm\" ; export const ToDefaultBranch = pushTest ( \"ToDefaultBranch\" , async pu => pu . push . branch === pu . repo . defaultBranch );","title":"Creating push tests"},{"location":"developer/push-test/#testing-push-tests","text":"As with the rest of the SDM API, we can write unit tests for push tests. This helps ensure that the decisions made in our delivery flows are solid. The following example uses Mocha and construct in memory projects and verify the behavior of the above push tests. describe ( \"IsMkdocsProject\" , () => { it ( \"should not find MkDocs in empty repo\" , async () => { const project = InMemoryProject . of (); // We need to cast as we want to ignore properties other than project of the invocation const r = await IsMkdocsProject . mapping ({ project } as any as PushListenerInvocation ); assert ( ! r ); }); it ( \"should find Mkdocs in repo with mkdocs file\" , async () => { const project = InMemoryProject . of ({ path : \"mkdocs.yml\" , content : \"here: yes\" }); const r = await IsMkdocsProject . mapping ({ project } as any as PushListenerInvocation ); assert ( r ); }); ... }","title":"Testing push tests"},{"location":"developer/pxe/","text":"Path Expressions are a way to comprehend code from other code. They provide an XPath-like navigation into the abstract syntax tree (AST), returning nodes that can be inspected and updated. When you update the value of a node, the code is updated in place . The idea is to duplicate the changes we as humans would make to the code. Path expressions are implemented in the tree-path library. Check the syntax documentation there.","title":"Path Expressions"},{"location":"developer/reporef/","text":"A RepoRef identifies a repository. Properties: owner the higher-level entity containing a repository. Organization, user, project - it goes by different names in different version control managers. repo the repository name url full location of this repository. Could be file:// or http(s):// path? if you only want to work with a directory within the repository, put the relative path here. sha? commit SHA within that repository. Optional; default to the tip of the default branch branch? if you want to work from a branch other than the default, put its name here Usually Atomist works with a RemoteRepoRef, which adds cloneUrl and apiUrl for communicating to version control. Get a RepoRef GitHub Use [GitHubRepoRef][apidoc-ghrr].from({...}) to instantiate a RepoRef for either GitHub.com or GitHub Enterprise. Provide the usual RepoRef properties except: instead of url , provide rawApiBase to post to your GitHub Enterprise instance. BitBucket On-prem and online BitBucket work differently.s BitBucket Server For on-prem BitBucket, use new [BitBucketServerRepoRef][apidoc-bbsrr](...) . Pass it: remoteBase where is your BitBucket? owner the BitBucket user or project repo string isProject? true if the owner is a project; false if the owner is a user sha? string path? string Set the branch on the returned object if you don\u2019t want the default one. BitBucket Cloud For BitBucket Cloud, use new [BitBucketRepoRef][apidoc-bbrr](...) . For Testing You can usually use any of the concrete instances for local testing, with dummy information.","title":"RepoRef"},{"location":"developer/reporef/#get-a-reporef","text":"","title":"Get a RepoRef"},{"location":"developer/reporef/#github","text":"Use [GitHubRepoRef][apidoc-ghrr].from({...}) to instantiate a RepoRef for either GitHub.com or GitHub Enterprise. Provide the usual RepoRef properties except: instead of url , provide rawApiBase to post to your GitHub Enterprise instance.","title":"GitHub"},{"location":"developer/reporef/#bitbucket","text":"On-prem and online BitBucket work differently.s","title":"BitBucket"},{"location":"developer/reporef/#bitbucket-server","text":"For on-prem BitBucket, use new [BitBucketServerRepoRef][apidoc-bbsrr](...) . Pass it: remoteBase where is your BitBucket? owner the BitBucket user or project repo string isProject? true if the owner is a project; false if the owner is a user sha? string path? string Set the branch on the returned object if you don\u2019t want the default one.","title":"BitBucket Server"},{"location":"developer/reporef/#bitbucket-cloud","text":"For BitBucket Cloud, use new [BitBucketRepoRef][apidoc-bbrr](...) .","title":"BitBucket Cloud"},{"location":"developer/reporef/#for-testing","text":"You can usually use any of the concrete instances for local testing, with dummy information.","title":"For Testing"},{"location":"developer/sdm-concepts/","text":"The Software Delivery Machine, or SDM, is your interface for using Atomist to deliver your software your way, but better. An SDM automates all steps in the flow from project creation to production, and many other actions, using the consistent model provided by the Atomist API for software . Core Concepts An SDM builds on other Atomist core functionality available from global automations, such as Atomist lifecycle messages showing commit, pull request, and other activity through actionable messages in your chat client. GraphQL The Atomist automation API provides you access to the events and data from your development platforms using GraphQL , a widely-used query language and runtime for APIs. You can use GraphQL with the Atomist automation API for: Queries that fetch data directly Subscriptions to register the types of events you want to receive Mutations to change data and make connections WebSockets An Atomist SDM must maintain contact with the API server so that it can receive the events and commands it\u2019s interested in as they occur. SDMs access the Atomist automation API via a WebSocket connection. WebSockets allow the API server to send events and commands to the SDM without constant polling via HTTP calls. The WebSocket connection is initiated by the SDM when it starts up, establishing a persistent two-way communication channel between the SDM and API that is resilient to interruptions in connectivity. Events The heart of Atomist is its event handling. As your code flows from commit through to deployment and beyond, Atomist receives events, correlates the incoming data with its previous knowledge, and invokes your event handlers with rich context. This enables your automations to perform tasks such as: Scanning code for security or quality issues on every push Driving deployments and promotion between environments Performing custom actions on deployment, such as kicking off integration test suites. The Atomist correlated event model also enables Atomist to provide you with visibility throughout the commit to deployment flow, in Slack or through the Atomist web interface. See Events for more information. Event handlers subscribe to events using GraphQL subscriptions against the Atomist cortex. The following GraphQL subscribes to completed builds, returning related data such as the last commit and any linked Slack channels: subscription OnBuildComplete { Build { buildId buildUrl compareUrl name status commit { sha message repo { name owner gitHubId allowRebaseMerge channels { name id } } statuses { context description state targetUrl } } } } When using TypeScript (our recommended language), an event handler can subscribe to such events with the benefit of strong typing. For example, this Atomist event handler can respond to the above GraphQL subscription: @EventHandler ( \"Set status on build complete\" , GraphQL . subscriptionFromFile ( \"graphql/subscription/OnBuildComplete.graphql\" )) export class SetStatusOnBuildComplete implements HandleEvent < OnBuildComplete . Subscription > { public async handle ( event : EventFired < OnBuildComplete . Subscription > , ctx : HandlerContext , params : this ) : Promise < HandlerResult > { This underlying GraphQL/event handler infrastructure is generic and powerful. However, many things are better done at a higher level. This project provides a framework above this infrastructure that makes typical tasks far easier, while not preventing you from breaking out into lower level functionality. SDM process lifecycle The SDM lifecycle will be familiar to those developing persistent applications. Authentication - When the SDM starts up, it connects to the Atomist API and authenticates using the API key you have provided in your configuration file. Registration - Once your identity has been established, the client registers its automations, i.e., the bot commands it provides and the events it wants to receive, with the Atomist workspaces specified in your configuration. If Atomist does not recognize your workspace ID or the provided API key is not connected to any member of that workspace, registration will fail and the SDM will exit with an unsuccessful status. Listening - After authentication and registration is completed successfully, the WebSocket connection is established and the client begins listening for incoming messages from the API: bot commands and events fired. Shutdown - When the client receives a shutdown signal, typically SIGINT delivered by the PaaS or Ctrl-C , it de-registers with the API and gracefully shuts down. SDM state An SDM, once registered, will continue to receive all the events it has subscribed to until shuts down or one of the following scenarios occurs. Multiple identical SDMs register If another client with the same name and version (typically obtained from the package.json \u201cname\u201d and \u201cversion\u201d properties) registers, then all of the registered identical SDMs will receive the events in a round-robin fashion. Each event will only be sent to one of the identical SDMs. This allows you to horizontally scale. A different version registers If another SDM having the same name but different version registers, it will begin receiving all of the events for the client and any previously registered versions cease receiving events. Note that no version comparisons are done: the last registration wins . If the new client has registered with a policy of \u201cephemeral\u201d and the prior client was registered with a policy of \u201cdurable\u201d, then when the new client shuts down, events again be sent to the \u201cdurable\u201d registration clients. The reason for this logic is to allow for production, testing, and local use to all coexist without taking the same action multiple times. For example, if you are running an SDM in production but want to test something, you can run it locally, steal events for a bit, kill the local process, and then traffic will return to the production instance. If you want the same events to be sent to multiple SDMs, just make sure the SDMs have different names. Custom Ingestion Any custom ingestion types can only be registered once within an Atomist workspace. Therefore it is recommended to register these in a dedicated API client. SDM Framework concepts Push Mappings Let\u2019s now return to push mappings and goal setting. The PushMapping interface is used to decide how to handle pushes. Normally it is used via the DSL we\u2019ve seen. export interface PushMapping < V > { /** * Name of the PushMapping. Must be unique */ readonly name : string ; /** * Compute a value for the given push. Return undefined * if we don't find a mapped value. * Return DoNotSetAnyGoals (null) to shortcut evaluation of the present set of rules, * terminating evaluation and guarantee the return of undefined if we've reached this point. * Only do so if you are sure * that this evaluation must be short circuited if it has reached this point. * If a previous rule has matched, it will still be used. * The value may be static * or computed on demand, depending on the implementation. * @param {PushListenerInvocation} p * @return {Promise<V | undefined | NeverMatch>} */ valueForPush ( p : PushListenerInvocation ) : Promise < V | undefined | NeverMatch > ; } PushMapping is a central interface used in many places. A GoalSetter is a PushMapping that returns Goals . A PushTest is simply a PushMapping that returns boolean . Code Examples Let\u2019s look at some examples. Issue Creation When a new issue is created, you may want to notify people or perform an action. Listener interfaces NewIssueListener : NewIssueListener Examples The following example notifies any user who raises an issue with insufficient detail in the body, via a direct message in Slack, and provides them with a helpful link to the issue. Note that we make use of the person available via the openedBy field: export async function requestDescription ( inv : NewIssueInvocation ) { if ( ! inv . issue . body || inv . issue . body . length < 10 ) { await inv . context . messageClient . addressUsers ( `Please add a description for new issue ${ inv . issue . number } : _ ${ inv . issue . title } _: ${ inv . id . url } /issues/ ${ inv . issue . number } ` , inv . issue . openedBy . person . chatId . screenName ); } } This is registed with a SoftwareDeliveryMachine instance as follows: sdm . addNewIssueListeners ( requestDescription ) Using the credentials on the NewIssueInvocation , you can easily use the GitHub API to modify the issue, for example correcting spelling errors. Repo Creation We frequently want to respond to the creation of a new repository: For example, we may want to notify people, provision infrastructure, or tag it with GitHub topics based on its contents. Listener interfaces There are two scenarios to consider: The creation of a new repository. RepoCreationListener : RepoCreationListener The first push to a repository, which uses the more generic ProjectListener The second scenario is usually more important, as it is possible to create a repository without any source code or a master branch, which isn\u2019t enough to work with for common actions. Example The following example publishes a message to the #general channel in Slack when a new repo has been created: export const PublishNewRepo : SdmListener = ( i : ListenerInvocation ) => { return i . context . messageClient . addressChannels ( `A new repo was created: \\` ${ i . id . owner } : ${ i . id . repo } \\`` , \"general\" ); }; Tagging a repo with topics based on its content is a useful action. tagRepo is a convenient function to construct a ProjectListener for this. It tags as an argument a Tagger , which looks at the project content and returns a Tags object. The following example from atomist.config.ts tags Spring Boot repos, using a Tagger from the spring-automation project, in addition to suggesting the addition of a Cloud Foundry manifest, and publishing the repo using the listener previously shown: sdm . addNewRepoWithCodeActions ( tagRepo ( springBootTagger ), suggestAddingCloudFoundryManifest , PublishNewRepo ) Project Generators Another important concern is project creation. Consistent project creation is important to governance and provides a way of sharing knowledge across a team. See the Project Creation page. Code Transforms Another core concept is a code transform . This is a command that transforms project content. Atomist infrastructure can help persist such transformations through branch commits or pull requests, with clean diffs. See the Code Transform page. More elaborate transforms use helper APIs on top of the Project API such as Atomist\u2019s microgrammar API and ANTLR integration. Dry Run Transforms There\u2019s also an important capability called \u201cdry run transform\u201d: Performing a transform on a branch, and then either raising either a PR or an issue, depending on build success or failure. This allows us to safely apply transforms across many repositories. There\u2019s a simple wrapper function to enable this: Tip Dry run transforms are another example of how commands and events can work hand in hand with Atomist to provide a uniquely powerful solution. Arbitrary Commands Both generators and transforms are special cases of Atomist command handlers , which can be invoked via Slack or HTTP. You can write commands to ensure that anything that needs to be repeated gets done the right way each time, and that the solution isn\u2019t hidden on someone\u2019s machine. Pulling it All Together: The SoftwareDeliveryMachine class Your ideal delivery blueprint spans delivery flow, generators, editors and other commands. All we need is something to pull it together. Your event listeners need to be invoked by Atomist handlers. The SoftwareDeliveryMachine takes care of this, ensuring that the correct handlers are emitted for use in atomist.config.ts , without you needing to worry about the event handler registrations on underlying GraphQL. The SoftwareDeliveryMachine class offers a fluent builder approach to adding command handlers, generators and editors. Example For example: const sdm = createSoftwareDeliveryMachine ( { builder : K8sBuildOnSuccessStatus , deployers : [ K8sStagingDeployOnSuccessStatus , K8sProductionDeployOnSuccessStatus , ], artifactStore , }, whenPushSatisfies ( PushToDefaultBranch , IsMaven , IsSpringBoot , HasK8Spec , PushToPublicRepo ) . setGoals ( HttpServiceGoals ), whenPushSatisfies ( not ( PushFromAtomist ), IsMaven , IsSpringBoot ) . setGoals ( LocalDeploymentGoals ), whenPushSatisfies ( IsMaven , MaterialChangeToJavaRepo ) . setGoals ( LibraryGoals ), whenPushSatisfies ( IsNode ). setGoals ( NpmGoals ), ); sdm . addNewRepoWithCodeActions ( suggestAddingK8sSpec ) . addSupportingCommands (() => addK8sSpec ) . addSupportingEvents (() => NoticeK8sTestDeployCompletion , () => NoticeK8sProdDeployCompletion ) . addEndpointVerificationListeners ( lookFor200OnEndpointRootGet ({ retries : 15 , maxTimeout : 5000 , minTimeout : 3000 , }), ); sdm . addNewIssueListeners ( requestDescription ) . addEditors (() => tryToUpgradeSpringBootVersion ) . addGenerators (() => springBootGenerator ({ seedOwner : \"spring-team\" , seedRepo : \"spring-rest-seed\" , groupId : \"myco\" , })) . addNewRepoWithCodeActions ( tagRepo ( springBootTagger ), suggestAddingCloudFoundryManifest , PublishNewRepo ) . addProjectReviewers ( logReview ) . addPushReactions ( listChangedFiles ) . addFingerprinters ( mavenFingerprinter ) . addDeploymentListeners ( PostToDeploymentsChannel ) . addEndpointVerificationListeners ( LookFor200OnEndpointRootGet ) . addVerifiedDeploymentListeners ( presentPromotionButton ) . addSupersededListeners ( inv => { logger . info ( \"Will undeploy application %j\" , inv . id ); return LocalMavenDeployer . deployer . undeploy ( inv . id ); }) . addSupportingCommands ( () => addCloudFoundryManifest , DescribeStagingAndProd , () => disposeProjectHandler , ) . addSupportingEvents ( OnDryRunBuildComplete ); The SoftwareDeliveryMachine instance will create the necessary Atomist event handlers to export. In atomist.config.ts you can bring them in simply as follows: commands : assembled.commandHandlers , events : assembled.eventHandlers , Plugging in Third Party Tools In addition to the core capabilities of the Atomist platform, an SDM can integrate with third-party tools to execute goals and commands. Integrating CI tools One of the tools you are most likely to integrate is Continuous Integration (CI). For example, you can integrate Jenkins, Travis or Circle CI with Atomist so that these tools are responsible for build. This has potential advantages in terms of scheduling and repeatability of environments. Integrating a CI tool with Atomist is simple. Simply invoke Atomist hooks to send events around build and artifact creation. If integrating CI tools, we recommend the following: CI tools are great for building and generating artifacts. They are often abused as a PaaS for bash . If you find your CI usage has you programming in bash or YML, consider whether invoking such operations from Atomist event handlers might be a better model. Use Atomist generators to create your CI files, and Atomist editors to keep them in synch, minimizing inconsistency. Integrating with Static Analysis Tools Any tool that runs on code, such as Checkstyle, can easily be integrated. If the tool doesn\u2019t have a Node API (which Checkstyle doesn\u2019t as it\u2019s written in Java), you can invoke it via Node spawn , as Node excels at working with child processes. Advanced Push Rules Computed Values You can use computed boolean values or the results of synchronous or asynchronous functions returning boolean in the DSL, making it possible to bring in any state you wish. For example: whenPushSatisfies ( IsMaven , HasSpringBootApplicationClass , deploymentsToday < 25 ) . itMeans ( \"Not tired of deploying Spring apps yet\" ) . setGoals ( LocalDeploymentGoals ), Decision Trees You can write decision trees in push rules or other push mappings. These can be nested to arbitrary depth, and can use computed state. For example: let count = 0 ; const pm : PushMapping < Goals > = given < Goals > ( IsNode ) // Compute a value we'll use later . init (() => count = 0 ) . itMeans ( \"node\" ) . then ( given < Goals > ( IsExpress ). itMeans ( \"express\" ) . compute (() => count ++ ) // Go into tree branch rule set . then ( whenPushSatisfies ( count > 0 ). itMeans ( \"nope\" ). setGoals ( NoGoals ), whenPushSatisfies ( TruePushTest ). itMeans ( \"yes\" ). setGoals ( HttpServiceGoals ), ), );","title":"SDM Concepts"},{"location":"developer/sdm-concepts/#core-concepts","text":"An SDM builds on other Atomist core functionality available from global automations, such as Atomist lifecycle messages showing commit, pull request, and other activity through actionable messages in your chat client.","title":"Core Concepts"},{"location":"developer/sdm-concepts/#graphql","text":"The Atomist automation API provides you access to the events and data from your development platforms using GraphQL , a widely-used query language and runtime for APIs. You can use GraphQL with the Atomist automation API for: Queries that fetch data directly Subscriptions to register the types of events you want to receive Mutations to change data and make connections","title":"GraphQL"},{"location":"developer/sdm-concepts/#websockets","text":"An Atomist SDM must maintain contact with the API server so that it can receive the events and commands it\u2019s interested in as they occur. SDMs access the Atomist automation API via a WebSocket connection. WebSockets allow the API server to send events and commands to the SDM without constant polling via HTTP calls. The WebSocket connection is initiated by the SDM when it starts up, establishing a persistent two-way communication channel between the SDM and API that is resilient to interruptions in connectivity.","title":"WebSockets"},{"location":"developer/sdm-concepts/#events","text":"The heart of Atomist is its event handling. As your code flows from commit through to deployment and beyond, Atomist receives events, correlates the incoming data with its previous knowledge, and invokes your event handlers with rich context. This enables your automations to perform tasks such as: Scanning code for security or quality issues on every push Driving deployments and promotion between environments Performing custom actions on deployment, such as kicking off integration test suites. The Atomist correlated event model also enables Atomist to provide you with visibility throughout the commit to deployment flow, in Slack or through the Atomist web interface. See Events for more information. Event handlers subscribe to events using GraphQL subscriptions against the Atomist cortex. The following GraphQL subscribes to completed builds, returning related data such as the last commit and any linked Slack channels: subscription OnBuildComplete { Build { buildId buildUrl compareUrl name status commit { sha message repo { name owner gitHubId allowRebaseMerge channels { name id } } statuses { context description state targetUrl } } } } When using TypeScript (our recommended language), an event handler can subscribe to such events with the benefit of strong typing. For example, this Atomist event handler can respond to the above GraphQL subscription: @EventHandler ( \"Set status on build complete\" , GraphQL . subscriptionFromFile ( \"graphql/subscription/OnBuildComplete.graphql\" )) export class SetStatusOnBuildComplete implements HandleEvent < OnBuildComplete . Subscription > { public async handle ( event : EventFired < OnBuildComplete . Subscription > , ctx : HandlerContext , params : this ) : Promise < HandlerResult > { This underlying GraphQL/event handler infrastructure is generic and powerful. However, many things are better done at a higher level. This project provides a framework above this infrastructure that makes typical tasks far easier, while not preventing you from breaking out into lower level functionality.","title":"Events"},{"location":"developer/sdm-concepts/#sdm-process-lifecycle","text":"The SDM lifecycle will be familiar to those developing persistent applications. Authentication - When the SDM starts up, it connects to the Atomist API and authenticates using the API key you have provided in your configuration file. Registration - Once your identity has been established, the client registers its automations, i.e., the bot commands it provides and the events it wants to receive, with the Atomist workspaces specified in your configuration. If Atomist does not recognize your workspace ID or the provided API key is not connected to any member of that workspace, registration will fail and the SDM will exit with an unsuccessful status. Listening - After authentication and registration is completed successfully, the WebSocket connection is established and the client begins listening for incoming messages from the API: bot commands and events fired. Shutdown - When the client receives a shutdown signal, typically SIGINT delivered by the PaaS or Ctrl-C , it de-registers with the API and gracefully shuts down.","title":"SDM process lifecycle"},{"location":"developer/sdm-concepts/#sdm-state","text":"An SDM, once registered, will continue to receive all the events it has subscribed to until shuts down or one of the following scenarios occurs.","title":"SDM state"},{"location":"developer/sdm-concepts/#multiple-identical-sdms-register","text":"If another client with the same name and version (typically obtained from the package.json \u201cname\u201d and \u201cversion\u201d properties) registers, then all of the registered identical SDMs will receive the events in a round-robin fashion. Each event will only be sent to one of the identical SDMs. This allows you to horizontally scale.","title":"Multiple identical SDMs register"},{"location":"developer/sdm-concepts/#a-different-version-registers","text":"If another SDM having the same name but different version registers, it will begin receiving all of the events for the client and any previously registered versions cease receiving events. Note that no version comparisons are done: the last registration wins . If the new client has registered with a policy of \u201cephemeral\u201d and the prior client was registered with a policy of \u201cdurable\u201d, then when the new client shuts down, events again be sent to the \u201cdurable\u201d registration clients. The reason for this logic is to allow for production, testing, and local use to all coexist without taking the same action multiple times. For example, if you are running an SDM in production but want to test something, you can run it locally, steal events for a bit, kill the local process, and then traffic will return to the production instance. If you want the same events to be sent to multiple SDMs, just make sure the SDMs have different names. Custom Ingestion Any custom ingestion types can only be registered once within an Atomist workspace. Therefore it is recommended to register these in a dedicated API client.","title":"A different version registers"},{"location":"developer/sdm-concepts/#sdm-framework-concepts","text":"","title":"SDM Framework concepts"},{"location":"developer/sdm-concepts/#push-mappings","text":"Let\u2019s now return to push mappings and goal setting. The PushMapping interface is used to decide how to handle pushes. Normally it is used via the DSL we\u2019ve seen. export interface PushMapping < V > { /** * Name of the PushMapping. Must be unique */ readonly name : string ; /** * Compute a value for the given push. Return undefined * if we don't find a mapped value. * Return DoNotSetAnyGoals (null) to shortcut evaluation of the present set of rules, * terminating evaluation and guarantee the return of undefined if we've reached this point. * Only do so if you are sure * that this evaluation must be short circuited if it has reached this point. * If a previous rule has matched, it will still be used. * The value may be static * or computed on demand, depending on the implementation. * @param {PushListenerInvocation} p * @return {Promise<V | undefined | NeverMatch>} */ valueForPush ( p : PushListenerInvocation ) : Promise < V | undefined | NeverMatch > ; } PushMapping is a central interface used in many places. A GoalSetter is a PushMapping that returns Goals . A PushTest is simply a PushMapping that returns boolean .","title":"Push Mappings"},{"location":"developer/sdm-concepts/#code-examples","text":"Let\u2019s look at some examples.","title":"Code Examples"},{"location":"developer/sdm-concepts/#issue-creation","text":"When a new issue is created, you may want to notify people or perform an action.","title":"Issue Creation"},{"location":"developer/sdm-concepts/#listener-interfaces","text":"NewIssueListener : NewIssueListener","title":"Listener interfaces"},{"location":"developer/sdm-concepts/#examples","text":"The following example notifies any user who raises an issue with insufficient detail in the body, via a direct message in Slack, and provides them with a helpful link to the issue. Note that we make use of the person available via the openedBy field: export async function requestDescription ( inv : NewIssueInvocation ) { if ( ! inv . issue . body || inv . issue . body . length < 10 ) { await inv . context . messageClient . addressUsers ( `Please add a description for new issue ${ inv . issue . number } : _ ${ inv . issue . title } _: ${ inv . id . url } /issues/ ${ inv . issue . number } ` , inv . issue . openedBy . person . chatId . screenName ); } } This is registed with a SoftwareDeliveryMachine instance as follows: sdm . addNewIssueListeners ( requestDescription ) Using the credentials on the NewIssueInvocation , you can easily use the GitHub API to modify the issue, for example correcting spelling errors.","title":"Examples"},{"location":"developer/sdm-concepts/#repo-creation","text":"We frequently want to respond to the creation of a new repository: For example, we may want to notify people, provision infrastructure, or tag it with GitHub topics based on its contents.","title":"Repo Creation"},{"location":"developer/sdm-concepts/#listener-interfaces_1","text":"There are two scenarios to consider: The creation of a new repository. RepoCreationListener : RepoCreationListener The first push to a repository, which uses the more generic ProjectListener The second scenario is usually more important, as it is possible to create a repository without any source code or a master branch, which isn\u2019t enough to work with for common actions.","title":"Listener interfaces"},{"location":"developer/sdm-concepts/#example","text":"The following example publishes a message to the #general channel in Slack when a new repo has been created: export const PublishNewRepo : SdmListener = ( i : ListenerInvocation ) => { return i . context . messageClient . addressChannels ( `A new repo was created: \\` ${ i . id . owner } : ${ i . id . repo } \\`` , \"general\" ); }; Tagging a repo with topics based on its content is a useful action. tagRepo is a convenient function to construct a ProjectListener for this. It tags as an argument a Tagger , which looks at the project content and returns a Tags object. The following example from atomist.config.ts tags Spring Boot repos, using a Tagger from the spring-automation project, in addition to suggesting the addition of a Cloud Foundry manifest, and publishing the repo using the listener previously shown: sdm . addNewRepoWithCodeActions ( tagRepo ( springBootTagger ), suggestAddingCloudFoundryManifest , PublishNewRepo )","title":"Example"},{"location":"developer/sdm-concepts/#project-generators","text":"Another important concern is project creation. Consistent project creation is important to governance and provides a way of sharing knowledge across a team. See the Project Creation page.","title":"Project Generators"},{"location":"developer/sdm-concepts/#code-transforms","text":"Another core concept is a code transform . This is a command that transforms project content. Atomist infrastructure can help persist such transformations through branch commits or pull requests, with clean diffs. See the Code Transform page. More elaborate transforms use helper APIs on top of the Project API such as Atomist\u2019s microgrammar API and ANTLR integration.","title":"Code Transforms"},{"location":"developer/sdm-concepts/#dry-run-transforms","text":"There\u2019s also an important capability called \u201cdry run transform\u201d: Performing a transform on a branch, and then either raising either a PR or an issue, depending on build success or failure. This allows us to safely apply transforms across many repositories. There\u2019s a simple wrapper function to enable this: Tip Dry run transforms are another example of how commands and events can work hand in hand with Atomist to provide a uniquely powerful solution.","title":"Dry Run Transforms"},{"location":"developer/sdm-concepts/#arbitrary-commands","text":"Both generators and transforms are special cases of Atomist command handlers , which can be invoked via Slack or HTTP. You can write commands to ensure that anything that needs to be repeated gets done the right way each time, and that the solution isn\u2019t hidden on someone\u2019s machine.","title":"Arbitrary Commands"},{"location":"developer/sdm-concepts/#pulling-it-all-together-the-softwaredeliverymachine-class","text":"Your ideal delivery blueprint spans delivery flow, generators, editors and other commands. All we need is something to pull it together. Your event listeners need to be invoked by Atomist handlers. The SoftwareDeliveryMachine takes care of this, ensuring that the correct handlers are emitted for use in atomist.config.ts , without you needing to worry about the event handler registrations on underlying GraphQL. The SoftwareDeliveryMachine class offers a fluent builder approach to adding command handlers, generators and editors.","title":"Pulling it All Together: The SoftwareDeliveryMachine class"},{"location":"developer/sdm-concepts/#example_1","text":"For example: const sdm = createSoftwareDeliveryMachine ( { builder : K8sBuildOnSuccessStatus , deployers : [ K8sStagingDeployOnSuccessStatus , K8sProductionDeployOnSuccessStatus , ], artifactStore , }, whenPushSatisfies ( PushToDefaultBranch , IsMaven , IsSpringBoot , HasK8Spec , PushToPublicRepo ) . setGoals ( HttpServiceGoals ), whenPushSatisfies ( not ( PushFromAtomist ), IsMaven , IsSpringBoot ) . setGoals ( LocalDeploymentGoals ), whenPushSatisfies ( IsMaven , MaterialChangeToJavaRepo ) . setGoals ( LibraryGoals ), whenPushSatisfies ( IsNode ). setGoals ( NpmGoals ), ); sdm . addNewRepoWithCodeActions ( suggestAddingK8sSpec ) . addSupportingCommands (() => addK8sSpec ) . addSupportingEvents (() => NoticeK8sTestDeployCompletion , () => NoticeK8sProdDeployCompletion ) . addEndpointVerificationListeners ( lookFor200OnEndpointRootGet ({ retries : 15 , maxTimeout : 5000 , minTimeout : 3000 , }), ); sdm . addNewIssueListeners ( requestDescription ) . addEditors (() => tryToUpgradeSpringBootVersion ) . addGenerators (() => springBootGenerator ({ seedOwner : \"spring-team\" , seedRepo : \"spring-rest-seed\" , groupId : \"myco\" , })) . addNewRepoWithCodeActions ( tagRepo ( springBootTagger ), suggestAddingCloudFoundryManifest , PublishNewRepo ) . addProjectReviewers ( logReview ) . addPushReactions ( listChangedFiles ) . addFingerprinters ( mavenFingerprinter ) . addDeploymentListeners ( PostToDeploymentsChannel ) . addEndpointVerificationListeners ( LookFor200OnEndpointRootGet ) . addVerifiedDeploymentListeners ( presentPromotionButton ) . addSupersededListeners ( inv => { logger . info ( \"Will undeploy application %j\" , inv . id ); return LocalMavenDeployer . deployer . undeploy ( inv . id ); }) . addSupportingCommands ( () => addCloudFoundryManifest , DescribeStagingAndProd , () => disposeProjectHandler , ) . addSupportingEvents ( OnDryRunBuildComplete ); The SoftwareDeliveryMachine instance will create the necessary Atomist event handlers to export. In atomist.config.ts you can bring them in simply as follows: commands : assembled.commandHandlers , events : assembled.eventHandlers ,","title":"Example"},{"location":"developer/sdm-concepts/#plugging-in-third-party-tools","text":"In addition to the core capabilities of the Atomist platform, an SDM can integrate with third-party tools to execute goals and commands.","title":"Plugging in Third Party Tools"},{"location":"developer/sdm-concepts/#integrating-ci-tools","text":"One of the tools you are most likely to integrate is Continuous Integration (CI). For example, you can integrate Jenkins, Travis or Circle CI with Atomist so that these tools are responsible for build. This has potential advantages in terms of scheduling and repeatability of environments. Integrating a CI tool with Atomist is simple. Simply invoke Atomist hooks to send events around build and artifact creation. If integrating CI tools, we recommend the following: CI tools are great for building and generating artifacts. They are often abused as a PaaS for bash . If you find your CI usage has you programming in bash or YML, consider whether invoking such operations from Atomist event handlers might be a better model. Use Atomist generators to create your CI files, and Atomist editors to keep them in synch, minimizing inconsistency.","title":"Integrating CI tools"},{"location":"developer/sdm-concepts/#integrating-with-static-analysis-tools","text":"Any tool that runs on code, such as Checkstyle, can easily be integrated. If the tool doesn\u2019t have a Node API (which Checkstyle doesn\u2019t as it\u2019s written in Java), you can invoke it via Node spawn , as Node excels at working with child processes.","title":"Integrating with Static Analysis Tools"},{"location":"developer/sdm-concepts/#advanced-push-rules","text":"","title":"Advanced Push Rules"},{"location":"developer/sdm-concepts/#computed-values","text":"You can use computed boolean values or the results of synchronous or asynchronous functions returning boolean in the DSL, making it possible to bring in any state you wish. For example: whenPushSatisfies ( IsMaven , HasSpringBootApplicationClass , deploymentsToday < 25 ) . itMeans ( \"Not tired of deploying Spring apps yet\" ) . setGoals ( LocalDeploymentGoals ),","title":"Computed Values"},{"location":"developer/sdm-concepts/#decision-trees","text":"You can write decision trees in push rules or other push mappings. These can be nested to arbitrary depth, and can use computed state. For example: let count = 0 ; const pm : PushMapping < Goals > = given < Goals > ( IsNode ) // Compute a value we'll use later . init (() => count = 0 ) . itMeans ( \"node\" ) . then ( given < Goals > ( IsExpress ). itMeans ( \"express\" ) . compute (() => count ++ ) // Go into tree branch rule set . then ( whenPushSatisfies ( count > 0 ). itMeans ( \"nope\" ). setGoals ( NoGoals ), whenPushSatisfies ( TruePushTest ). itMeans ( \"yes\" ). setGoals ( HttpServiceGoals ), ), );","title":"Decision Trees"},{"location":"developer/sdm-debug/","text":"You can debug your SDM on your laptop. Instead of atomist start at the command line, start it up in a debugger in your favorite tool. VSCode In VSCode , the debug configuration looks like: { \"type\": \"node\", \"request\": \"launch\", \"name\": \"Launch SDM\", \"program\": \"${workspaceFolder}/node_modules/@atomist/automation-client/bin/start.js\", \"env\": { \"ATOMIST_MODE\": \"\" }, \"outputCapture\": \"std\", } If you want the SDM to run in local mode, put \u201clocal\u201d in the ATOMIST_MODE environment variable. IntelliJ IDEA In IntelliJ IDEA , perform the following steps: In the menu, click Run and go to Edit Configurations Click on the + sign in the top left corner to add a new configuration In the Name field, enter Debug Atomist In the JavaScript file field, enter node_modules/@atomist/automation-client/bin/start.js If you want run your SDM in local mode add an environment variable ATOMIST_MODE with value local Press Ok Now in your run configurations in the top right corner, choose Debug Atomist and press the Debug icon. Debugging through logging See also: Logging in an SDM","title":"Debugging an SDM"},{"location":"developer/sdm-debug/#vscode","text":"In VSCode , the debug configuration looks like: { \"type\": \"node\", \"request\": \"launch\", \"name\": \"Launch SDM\", \"program\": \"${workspaceFolder}/node_modules/@atomist/automation-client/bin/start.js\", \"env\": { \"ATOMIST_MODE\": \"\" }, \"outputCapture\": \"std\", } If you want the SDM to run in local mode, put \u201clocal\u201d in the ATOMIST_MODE environment variable.","title":"VSCode"},{"location":"developer/sdm-debug/#intellij-idea","text":"In IntelliJ IDEA , perform the following steps: In the menu, click Run and go to Edit Configurations Click on the + sign in the top left corner to add a new configuration In the Name field, enter Debug Atomist In the JavaScript file field, enter node_modules/@atomist/automation-client/bin/start.js If you want run your SDM in local mode add an environment variable ATOMIST_MODE with value local Press Ok Now in your run configurations in the top right corner, choose Debug Atomist and press the Debug icon.","title":"IntelliJ IDEA"},{"location":"developer/sdm-debug/#debugging-through-logging","text":"See also: Logging in an SDM","title":"Debugging through logging"},{"location":"developer/sdm-deploy/","text":"You can run Software Delivery Machines (SDMs) in many different environments, ranging from your laptop or data center to Platform-as-a-Service offerings like Heroku and Pivotal Cloud Foundry. Atomist also supports running SDMs as Docker containers. This allows you to operate them in Kubernetes clusters or Google Container Engine, for example. This document explains various ways to run SDMs. Running locally The easiest way to run an SDM is to start it up on your local development machine. Running the SDM locally is extremely helpful during development of your automations. You can debug commands and event handlers using local development tools like Visual Studio Code and Google Chrome. You can iterate rapidly because there is no deployment and only a minimal build process. To connect to the Atomist API and respond to events in your team and commands in your team chat, start the SDM by running the following commands: npm run compile && npm start Note The SDM requires an open internet connection to https://automation.atomist.com to successfully register event subscriptions and commands. To receive only your personal commits and commands that you initiate in your terminal, run in local mode: npm run compile && npm start --local Production Production mode Set the environment variable NODE_ENV=production This has two effects: it tells npm to install only runtime dependencies, not dev-dependencies. it changes the default config in the SDM to [production defaults][prod-default-config-apidoc] run in durable mode. If you want the npm effect, but not the Atomist configuration change, then set ATOMIST_ENV to \u201ctesting\u201d or \u201cdevelopment\u201d. This will override NODE_ENV for that purpose. [prod-default-config-apidoc: https://atomist.github.io/automation-client/modules/ lib_configuration .html#productiondefaultconfiguration (APIdoc for ProductionDefaultConfig) Node When running in a production environment, you typically want to avoid npm and run Node.js directly to ensure signals get delivered properly and you can provide guidance to Node.js\u2019s memory management subsystem. Here\u2019s an example startup command for production environments: node $NODE_DEBUG_OPTION --trace-warnings --expose_gc --optimize_for_size \\ --always_compact --max_old_space_size=384 node_modules/.bin/atomist start See node --help and node --v8-options for more detail on these options. Cloud Foundry To push your SDM to an instance of Pivotal Cloud Foundry, you need an account on the instance you want to target and you must have the Cloud Foundry CLI installed. For detailed information about the deployment process, consult the Cloud Foundry documentation . A push to Cloud Foundry needs some additional metadata in your project. First you need to create a manifest.yml file in the root of your SDM project: applications : - name : my-sdm command : node node_modules/.bin/atm-start memory : 128M routes : - route : my-sdm.mycompany.net buildpack : https://github.com/cloudfoundry/nodejs-buildpack env : SUPPRESS_NO_CONFIG_WARNING : true NODE_ENV : production Note Technically a manifest.yml is not required but it makes things simpler. Next add an \"engines\" top-level entry to your package.json file: \"engines\" : { \"node\" : \"8.x.x\" , \"npm\" : \"5.x.x\" } Finally, start the deployment with: cf push Docker Shipping your SDM as a Docker image allows you to package up all required tools and dependencies. This is especially useful if you plan on reusing existing scripts or command line tools in your automations. To set up a Docker image build, you need a Dockerfile . Read the documentation on building Docker images for more details. Your SDM probably already has a Dockerfile in it, from the Dockerfile in the seed . If not, copy that one in. You should also have .dockerignore . Running in Docker locally In Docker, the SDM will only run in team mode. Local mode does not work yet. Vote here if you want it. With the Dockerfile in place, you can now start the Docker build. Change the name and version of the tag in this command: npm run build && \\ docker build . -t your-sdm:0.1.0 Start by running the Docker container locally. This command lets it use the configuration set up when you ran atomist config : docker run --rm --mount source=$HOME/.atomist,target=/root/.atomist,type=bind your-sdm Deploying with Docker The Dockerfile supplied in the seeds runs the SDM in development mode. Change ATOMIST_ENV to [production][#production-mode] and rebuild the container for production deployment, so that when your SDM goes down or restarts, events will be queued. Deploying to Kubernetes If you deploy to kubernetes, you\u2019ll need kubectl installed. Add this to your Dockerfile: RUN curl -sL -o /usr/local/bin/kubectl https://storage.googleapis.com/kubernetes-release/release/v1.8.12/bin/linux/amd64/kubectl \\ && chmod +x /usr/local/bin/kubectl \\ && kubectl version --client You may prefer a later release of kubectl. I won\u2019t keep this documentation up-to-date on that.","title":"Deploying your SDM"},{"location":"developer/sdm-deploy/#running-locally","text":"The easiest way to run an SDM is to start it up on your local development machine. Running the SDM locally is extremely helpful during development of your automations. You can debug commands and event handlers using local development tools like Visual Studio Code and Google Chrome. You can iterate rapidly because there is no deployment and only a minimal build process. To connect to the Atomist API and respond to events in your team and commands in your team chat, start the SDM by running the following commands: npm run compile && npm start Note The SDM requires an open internet connection to https://automation.atomist.com to successfully register event subscriptions and commands. To receive only your personal commits and commands that you initiate in your terminal, run in local mode: npm run compile && npm start --local","title":"Running locally"},{"location":"developer/sdm-deploy/#production","text":"","title":"Production"},{"location":"developer/sdm-deploy/#production-mode","text":"Set the environment variable NODE_ENV=production This has two effects: it tells npm to install only runtime dependencies, not dev-dependencies. it changes the default config in the SDM to [production defaults][prod-default-config-apidoc] run in durable mode. If you want the npm effect, but not the Atomist configuration change, then set ATOMIST_ENV to \u201ctesting\u201d or \u201cdevelopment\u201d. This will override NODE_ENV for that purpose. [prod-default-config-apidoc: https://atomist.github.io/automation-client/modules/ lib_configuration .html#productiondefaultconfiguration (APIdoc for ProductionDefaultConfig)","title":"Production mode"},{"location":"developer/sdm-deploy/#node","text":"When running in a production environment, you typically want to avoid npm and run Node.js directly to ensure signals get delivered properly and you can provide guidance to Node.js\u2019s memory management subsystem. Here\u2019s an example startup command for production environments: node $NODE_DEBUG_OPTION --trace-warnings --expose_gc --optimize_for_size \\ --always_compact --max_old_space_size=384 node_modules/.bin/atomist start See node --help and node --v8-options for more detail on these options.","title":"Node"},{"location":"developer/sdm-deploy/#cloud-foundry","text":"To push your SDM to an instance of Pivotal Cloud Foundry, you need an account on the instance you want to target and you must have the Cloud Foundry CLI installed. For detailed information about the deployment process, consult the Cloud Foundry documentation . A push to Cloud Foundry needs some additional metadata in your project. First you need to create a manifest.yml file in the root of your SDM project: applications : - name : my-sdm command : node node_modules/.bin/atm-start memory : 128M routes : - route : my-sdm.mycompany.net buildpack : https://github.com/cloudfoundry/nodejs-buildpack env : SUPPRESS_NO_CONFIG_WARNING : true NODE_ENV : production Note Technically a manifest.yml is not required but it makes things simpler. Next add an \"engines\" top-level entry to your package.json file: \"engines\" : { \"node\" : \"8.x.x\" , \"npm\" : \"5.x.x\" } Finally, start the deployment with: cf push","title":"Cloud Foundry"},{"location":"developer/sdm-deploy/#docker","text":"Shipping your SDM as a Docker image allows you to package up all required tools and dependencies. This is especially useful if you plan on reusing existing scripts or command line tools in your automations. To set up a Docker image build, you need a Dockerfile . Read the documentation on building Docker images for more details. Your SDM probably already has a Dockerfile in it, from the Dockerfile in the seed . If not, copy that one in. You should also have .dockerignore .","title":"Docker"},{"location":"developer/sdm-deploy/#running-in-docker-locally","text":"In Docker, the SDM will only run in team mode. Local mode does not work yet. Vote here if you want it. With the Dockerfile in place, you can now start the Docker build. Change the name and version of the tag in this command: npm run build && \\ docker build . -t your-sdm:0.1.0 Start by running the Docker container locally. This command lets it use the configuration set up when you ran atomist config : docker run --rm --mount source=$HOME/.atomist,target=/root/.atomist,type=bind your-sdm","title":"Running in Docker locally"},{"location":"developer/sdm-deploy/#deploying-with-docker","text":"The Dockerfile supplied in the seeds runs the SDM in development mode. Change ATOMIST_ENV to [production][#production-mode] and rebuild the container for production deployment, so that when your SDM goes down or restarts, events will be queued.","title":"Deploying with Docker"},{"location":"developer/sdm-deploy/#deploying-to-kubernetes","text":"If you deploy to kubernetes, you\u2019ll need kubectl installed. Add this to your Dockerfile: RUN curl -sL -o /usr/local/bin/kubectl https://storage.googleapis.com/kubernetes-release/release/v1.8.12/bin/linux/amd64/kubectl \\ && chmod +x /usr/local/bin/kubectl \\ && kubectl version --client You may prefer a later release of kubectl. I won\u2019t keep this documentation up-to-date on that.","title":"Deploying to Kubernetes"},{"location":"developer/sdm/","text":"The software delivery machine is a service that runs automations in response to events like pushes and builds. See architecture for a high-level view. The SDM: is event driven : the SDM performs actions in response to events. The most significant event is a code push. The response to this event is defined by goals . The response to other events (repository or issue creation, for instance) is defined by listeners . uses common APIs across different automation scenarios. These let you write the important code specifying what you want to do, while calling APIs for the common work. For instance, the Project API lets you inspect and update the repository contents. Your SDM is in TypeScript. Start with our code and add what you choose. This section documents creating, building, and running an SDM, and details the structure and organization of a typical SDM project. To get started in local mode , make sure you have: Git Node.js the Atomist CLI Before you run in team mode , you\u2019ll need the prerequisites page. This page will help you: create an SDM project spin up your SDM know where to add functionality to your SDM For the quickest path to seeing an SDM do something, use the Quick Start instead. Creating an SDM project The Atomist CLI will generate a starter SDM for you. atomist create sdm For \u201cType of SDM to create, \u201cChoose \u201cblank\u201d to start with an empty SDM, or \u201cspring\u201d to start with an SDM that does useful things for Java Spring services. For \u201cname of the target repository\u201d enter a name for your SDM. For \u201ctarget-owner\u201d enter a name for the owner of your project. This corresponds to the GitHub/GitLab organization or BitBucket project you would put the repository under. The \u201ccreate sdm\u201d generator will transform the seed according to your answers. Because this generator operates in local mode, it will create a project on your filesystem. Look in $HOME/atomist/ target-owner / name for the new SDM. GitHub If you prefer the manual route, you can always fork the empty-sdm project on GitHub. Looking at the code You can use whatever editor or IDE you like. We recommend VSCode because it is built for TypeScript (among other languages), it\u2019s a good IDE, and it\u2019s free. With TypeScript and an IDE like VSCode, you get autocompletion that helps you discover functionality in the SDM framework. Run npm install first so that your IDE will see library code. In Node, all dependencies are stored within the project, under the directory node_modules . npm is the dependency manager that gets them there. The node_modules directory is listed in .gitignore , so it won\u2019t be committed. index.ts Start your inquiry in index.ts . When an SDM starts up, it looks here to find its configuration. The configuration object has opportunities for many, many configuration options. Click into the Configuration type or check the API Docs if you\u2019re curious. The important part, where you\u2019re going to add to your personal SDM, is the function passed to configureSdm in configuration.postProcessors . Unless you change it, that function is called machine . machine.ts Click into the machine function in your IDE, or open lib/machine/machine.ts to find it. This function instantiates and then returns a SoftwareDeliveryMachine( API docs ). Inside this function, add functionality to your SDM. You can: Add Goals to choose a flow to respond to code push Add listeners to various other events Add commands Add project generators Bring in extension packs Building an SDM SDM projects are written in TypeScript and run on Node.js . Building an SDM is the same as any standard TypeScript or JavaScript project. First you install the project\u2019s dependencies: npm install then build the project, linting the TypeScript, compiling the TypeScript into JavaScript, generating other required files, and running tests: npm run build Starting an SDM There are a few different ways to start the SDM, depending on how you are running it. If you are running the SDM locally, you can use the standard npm start command. npm start If you are writing your own SDMs, you probably want a more responsive testing environment, having the client restart any time you make changes to the source code. This development flow is available with the autostart command. npm run autostart When you deploy your SDM to production, check the recommendations under Deploying your SDM . Stop Control-C will stop the client. Restart it after code changes with atomist start again. Project structure SDM projects are organized and behave like any standard TypeScript project. package.json The package.json file defines the metadata and dependencies for the project. In addition, this file defines the standard \u201cnpm package scripts\u201d, i.e., npm run commands, typically available in Node.js projects. Here\u2019s a summary of the npm package scripts available in most SDM projects. Command Description npm install install all the required packages npm run autostart run, refreshing when files change npm run autotest run tests every time files change npm run build lint, compile, and test npm run clean remove stray compiled JavaScript files and build directory npm run compile compile all TypeScript into JavaScript npm run lint run tslint against the TypeScript npm run lint:fix run tslint --fix against the TypeScript npm start start the SDM npm test run tests lib The lib directory contains the TypeScript source code. index.ts This is the starting point when you want to look at what this SDM might do. lib/graphql The graphql directory contains .graphql files defining your GraphQL queries, subscriptions, and mutations. This directory is optional, as you can define your GraphQL in strings within the source code. That said, it is recommended that you define your GraphQL in .graphql files so you can realize the full benefit of its type bindings in TypeScript. lib/typings The lib/typings directory contains the auto-generated TypeScript types for your GraphQL queries, subscriptions, and mutations. node_modules The node_modules directory contains all the project dependencies, as defined in the package.json and installed by npm. scripts The scripts directory contains various ancillary scripts. For example, this directory might have scripts for building the project on CI, publishing the project as an Node.js package, and publishing the project\u2019s TypeDoc . test The test directory contains the automated tests for the project. Typically these are unit tests written using mocha and power-assert . Next steps Proceed to [add some functionality][add-functionality] to your SDM.","title":"About the SDM"},{"location":"developer/sdm/#creating-an-sdm-project","text":"The Atomist CLI will generate a starter SDM for you. atomist create sdm For \u201cType of SDM to create, \u201cChoose \u201cblank\u201d to start with an empty SDM, or \u201cspring\u201d to start with an SDM that does useful things for Java Spring services. For \u201cname of the target repository\u201d enter a name for your SDM. For \u201ctarget-owner\u201d enter a name for the owner of your project. This corresponds to the GitHub/GitLab organization or BitBucket project you would put the repository under. The \u201ccreate sdm\u201d generator will transform the seed according to your answers. Because this generator operates in local mode, it will create a project on your filesystem. Look in $HOME/atomist/ target-owner / name for the new SDM.","title":"Creating an SDM project"},{"location":"developer/sdm/#github","text":"If you prefer the manual route, you can always fork the empty-sdm project on GitHub.","title":"GitHub"},{"location":"developer/sdm/#looking-at-the-code","text":"You can use whatever editor or IDE you like. We recommend VSCode because it is built for TypeScript (among other languages), it\u2019s a good IDE, and it\u2019s free. With TypeScript and an IDE like VSCode, you get autocompletion that helps you discover functionality in the SDM framework. Run npm install first so that your IDE will see library code. In Node, all dependencies are stored within the project, under the directory node_modules . npm is the dependency manager that gets them there. The node_modules directory is listed in .gitignore , so it won\u2019t be committed.","title":"Looking at the code"},{"location":"developer/sdm/#indexts","text":"Start your inquiry in index.ts . When an SDM starts up, it looks here to find its configuration. The configuration object has opportunities for many, many configuration options. Click into the Configuration type or check the API Docs if you\u2019re curious. The important part, where you\u2019re going to add to your personal SDM, is the function passed to configureSdm in configuration.postProcessors . Unless you change it, that function is called machine .","title":"index.ts"},{"location":"developer/sdm/#machinets","text":"Click into the machine function in your IDE, or open lib/machine/machine.ts to find it. This function instantiates and then returns a SoftwareDeliveryMachine( API docs ). Inside this function, add functionality to your SDM. You can: Add Goals to choose a flow to respond to code push Add listeners to various other events Add commands Add project generators Bring in extension packs","title":"machine.ts"},{"location":"developer/sdm/#building-an-sdm","text":"SDM projects are written in TypeScript and run on Node.js . Building an SDM is the same as any standard TypeScript or JavaScript project. First you install the project\u2019s dependencies: npm install then build the project, linting the TypeScript, compiling the TypeScript into JavaScript, generating other required files, and running tests: npm run build","title":"Building an SDM"},{"location":"developer/sdm/#starting-an-sdm","text":"There are a few different ways to start the SDM, depending on how you are running it. If you are running the SDM locally, you can use the standard npm start command. npm start If you are writing your own SDMs, you probably want a more responsive testing environment, having the client restart any time you make changes to the source code. This development flow is available with the autostart command. npm run autostart When you deploy your SDM to production, check the recommendations under Deploying your SDM .","title":"Starting an SDM"},{"location":"developer/sdm/#stop","text":"Control-C will stop the client. Restart it after code changes with atomist start again.","title":"Stop"},{"location":"developer/sdm/#project-structure","text":"SDM projects are organized and behave like any standard TypeScript project.","title":"Project structure"},{"location":"developer/sdm/#packagejson","text":"The package.json file defines the metadata and dependencies for the project. In addition, this file defines the standard \u201cnpm package scripts\u201d, i.e., npm run commands, typically available in Node.js projects. Here\u2019s a summary of the npm package scripts available in most SDM projects. Command Description npm install install all the required packages npm run autostart run, refreshing when files change npm run autotest run tests every time files change npm run build lint, compile, and test npm run clean remove stray compiled JavaScript files and build directory npm run compile compile all TypeScript into JavaScript npm run lint run tslint against the TypeScript npm run lint:fix run tslint --fix against the TypeScript npm start start the SDM npm test run tests","title":"package.json"},{"location":"developer/sdm/#lib","text":"The lib directory contains the TypeScript source code.","title":"lib"},{"location":"developer/sdm/#indexts_1","text":"This is the starting point when you want to look at what this SDM might do.","title":"index.ts"},{"location":"developer/sdm/#libgraphql","text":"The graphql directory contains .graphql files defining your GraphQL queries, subscriptions, and mutations. This directory is optional, as you can define your GraphQL in strings within the source code. That said, it is recommended that you define your GraphQL in .graphql files so you can realize the full benefit of its type bindings in TypeScript.","title":"lib/graphql"},{"location":"developer/sdm/#libtypings","text":"The lib/typings directory contains the auto-generated TypeScript types for your GraphQL queries, subscriptions, and mutations.","title":"lib/typings"},{"location":"developer/sdm/#node_modules","text":"The node_modules directory contains all the project dependencies, as defined in the package.json and installed by npm.","title":"node_modules"},{"location":"developer/sdm/#scripts","text":"The scripts directory contains various ancillary scripts. For example, this directory might have scripts for building the project on CI, publishing the project as an Node.js package, and publishing the project\u2019s TypeDoc .","title":"scripts"},{"location":"developer/sdm/#test","text":"The test directory contains the automated tests for the project. Typically these are unit tests written using mocha and power-assert .","title":"test"},{"location":"developer/sdm/#next-steps","text":"Proceed to [add some functionality][add-functionality] to your SDM.","title":"Next steps"},{"location":"developer/security/","text":"When you run automations in Atomist, they run on your network, and connect to our service through a websocket for triggering, chat integration, and querying data in the graph of your events. The Atomist service receives and stores high-level data about repositories, commits, pull requests, issues, builds, and any custom events you send. Your code is accessed only in your software delivery machine (SDM) . Where do SDMs run? Your software delivery happens in an SDM running inside your network. You have control of where your SDM runs and what it does, in code. The SDM needs access to your source control manager; it will clone the code to decide what delivery goals to set for each push. The SDM needs external network access to the Atomist service; it opens a websocket and registers. This registration includes an authorization key, which can be generated in the Atomist web application. The registration includes a list of commands that this SDM responds to; the Atomist bot makes those available in chat. The registration includes GraphQL subscriptions for events, like pushes and repository creation, which your SDM can use to trigger a delivery flow and other automations. Note that when you run an SDM in local mode , no Atomist authorization applies, as your SDM does not connect to Atomist. Authentication The authentication and authorization points are: can you access the Atomist web application? do you have administrative access in the Atomist web application? is an SDM authorized to connect? does a connected SDM have access to act as the person who invoked the command, or only as the person who ran this SDM? Currently, access to the Atomist web application uses GitHub as an authorization provider. The Atomist administrator (who initially enrolls an organization in the Atomist service) can invite other team members to the Atomist workspace, which gives them access to the web application. Once you have access to the web application, you can create an API key, and then use that to run your SDM. Individual GitHub authorization for commands Certain commands and buttons, like creating a pull request or pushing \u201cClose\u201d on a GitHub Issue notification, can be performed on GitHub as the user invoking the command . This requires their authentication on GitHub. The Atomist bot will prompt them for this authorization. It will request the minimum authorization for this command; later if the same user invokes something else, they may need to extend this authorization. These tokens are stored by Atomist in a secure secret store. These individual GitHub tokens are used by automations and SDMs to carry out actions as the user who requested the action. These are not handed to every SDM that connects, however; if you run an SDM locally, in team mode, your SDM will carry out its work on GitHub as you. The individual tokens are used by the built-in chat automations . Data High-level historical event data for your organization is stored by Atomist. It can be accessed by people in your Atomist workspace using the GraphQL interface in the Atomist web application, and by SDMs running custom GraphQL queries.","title":"Security Model"},{"location":"developer/security/#where-do-sdms-run","text":"Your software delivery happens in an SDM running inside your network. You have control of where your SDM runs and what it does, in code. The SDM needs access to your source control manager; it will clone the code to decide what delivery goals to set for each push. The SDM needs external network access to the Atomist service; it opens a websocket and registers. This registration includes an authorization key, which can be generated in the Atomist web application. The registration includes a list of commands that this SDM responds to; the Atomist bot makes those available in chat. The registration includes GraphQL subscriptions for events, like pushes and repository creation, which your SDM can use to trigger a delivery flow and other automations. Note that when you run an SDM in local mode , no Atomist authorization applies, as your SDM does not connect to Atomist.","title":"Where do SDMs run?"},{"location":"developer/security/#authentication","text":"The authentication and authorization points are: can you access the Atomist web application? do you have administrative access in the Atomist web application? is an SDM authorized to connect? does a connected SDM have access to act as the person who invoked the command, or only as the person who ran this SDM? Currently, access to the Atomist web application uses GitHub as an authorization provider. The Atomist administrator (who initially enrolls an organization in the Atomist service) can invite other team members to the Atomist workspace, which gives them access to the web application. Once you have access to the web application, you can create an API key, and then use that to run your SDM.","title":"Authentication"},{"location":"developer/security/#individual-github-authorization-for-commands","text":"Certain commands and buttons, like creating a pull request or pushing \u201cClose\u201d on a GitHub Issue notification, can be performed on GitHub as the user invoking the command . This requires their authentication on GitHub. The Atomist bot will prompt them for this authorization. It will request the minimum authorization for this command; later if the same user invokes something else, they may need to extend this authorization. These tokens are stored by Atomist in a secure secret store. These individual GitHub tokens are used by automations and SDMs to carry out actions as the user who requested the action. These are not handed to every SDM that connects, however; if you run an SDM locally, in team mode, your SDM will carry out its work on GitHub as you. The individual tokens are used by the built-in chat automations .","title":"Individual GitHub authorization for commands"},{"location":"developer/security/#data","text":"High-level historical event data for your organization is stored by Atomist. It can be accessed by people in your Atomist workspace using the GraphQL interface in the Atomist web application, and by SDMs running custom GraphQL queries.","title":"Data"},{"location":"developer/set-goals/","text":"This page assumes you have created some goals . It shows how to: group goals set dependencies between goals choose which goals to execute on each push prevent the SDM from setting goals on a push Grouping goals You can group goals into sets. Start creating a goal set with the goals method; give it a name. Add goals to the set with the plan method. const BaseGoals = goals ( \"checks\" ) . plan ( codeInspection ) . plan ( autofix ); The plan method accepts one or more goals. The code below is equivalent to the code above: const BaseGoals = goals ( \"checks\" ) . plan ( codeInspection , autofix ); Dependencies By default, all goals execute in parallel. If some goals should wait for others to succeed, you can give them preconditions as you add them to a plan. To do this, call the after method immediately after plan . The following example constructs a goal set called \u201cbuild\u201d with three goals: autofix , codeInspection , and mavenBuild . The mavenBuild goal will execute only after autofix completes successfully. const BuildGoals = goals ( \"build\" ) . plan ( autofix , codeInspection ) . plan ( mavenBuild ) . after ( autofix ); Note that the after method affects only the goals in the last call to plan . Here, the mavenBuild goal gets a precondition that the autofix goal must complete successfully. The goals listed in after can be part of this goal set, but they don\u2019t have to be. They could be in another goal set that is also added to the push. If the goal in after is not attached to a particular push at all, then the precondition is ignored. See the next section for how to attach goal sets to a push. Set goals on push with \u201cpush rules\u201d Finally, you can tell the SDM which goals to run on each push. Here, we set the BaseGoals (inspection and autofix) on every push. Then if this is a Maven project (identified by having a pom.xml ), we do the build as well. sdm . withPushRules ( onAnyPush (). setGoals ( BaseGoals ), whenPushSatisfies ( IsMaven ). setGoals ( BuildGoals ), ); The rules are evaluated in order. The resulting goals are combined and de-duplicated to determine the goals that will be set on the push. The rules themselves are written in a simple internal DSL that aims to be human readable. The onAnyPush() function will return true on all pushes. The whenPushSatisfies function is used to combine other rules. For example, we could limit building to Java projects, rather than all Maven projects, as follows: whenPushSatisfies ( IsMaven , IsJava ). setGoals ( BuildGoals ), The DSL includes support for logical operations. For example, this will build all Maven projects except Kotlin projects: whenPushSatisfies ( IsMaven , not ( IsKotlin )). setGoals ( BuildGoals ), PushRule Each argument to sdm.withPushRules is a PushRule, contributing goals on a commit if a condition is met. That condition is a PushTest. PushTest Push tests are functions that look at the content of a push and decide whether this goal applies. See: Documentation on Push Tests Here\u2019s a quick example of a push test: export const IsMaven : PredicatePushTest = predicatePushTest ( \"Is Maven\" , p => p . hasFile ( \"pom.xml\" )); To establish a PushTest for whether a project uses Maven as a build tool, this code calls a constructor function predicatePushTest with a name for the PushTest and a function from a Project to a Promise<Boolean> . The example spring-sdm uses this PushTest to create a PushRule, which sets build goals only on Maven projects: whenPushSatisfies ( IsMaven ). setGoals ( buildGoals ) Stop setting goals Sometimes we want to stop setting goals after a particular rule evaluates to true. For example, we can modify the earlier example to do nothing at all if the project has a leaveMeAlone file in the root directory: sdm . withPushRules ( whenPushSatisfies ( async pu => pu . project . hasFile ( \"leaveMeAlone\" )). setGoals ( goals ( \"none\" ). andLock ()), onAnyPush (). setGoals ( BaseGoals ), whenPushSatisfies ( IsMaven ). setGoals ( BuildGoals ), ); The andLock method on the Goals class causes further goal evaluation to be ignored.","title":"Setting Goals"},{"location":"developer/set-goals/#grouping-goals","text":"You can group goals into sets. Start creating a goal set with the goals method; give it a name. Add goals to the set with the plan method. const BaseGoals = goals ( \"checks\" ) . plan ( codeInspection ) . plan ( autofix ); The plan method accepts one or more goals. The code below is equivalent to the code above: const BaseGoals = goals ( \"checks\" ) . plan ( codeInspection , autofix );","title":"Grouping goals"},{"location":"developer/set-goals/#dependencies","text":"By default, all goals execute in parallel. If some goals should wait for others to succeed, you can give them preconditions as you add them to a plan. To do this, call the after method immediately after plan . The following example constructs a goal set called \u201cbuild\u201d with three goals: autofix , codeInspection , and mavenBuild . The mavenBuild goal will execute only after autofix completes successfully. const BuildGoals = goals ( \"build\" ) . plan ( autofix , codeInspection ) . plan ( mavenBuild ) . after ( autofix ); Note that the after method affects only the goals in the last call to plan . Here, the mavenBuild goal gets a precondition that the autofix goal must complete successfully. The goals listed in after can be part of this goal set, but they don\u2019t have to be. They could be in another goal set that is also added to the push. If the goal in after is not attached to a particular push at all, then the precondition is ignored. See the next section for how to attach goal sets to a push.","title":"Dependencies"},{"location":"developer/set-goals/#set-goals-on-push-with-push-rules","text":"Finally, you can tell the SDM which goals to run on each push. Here, we set the BaseGoals (inspection and autofix) on every push. Then if this is a Maven project (identified by having a pom.xml ), we do the build as well. sdm . withPushRules ( onAnyPush (). setGoals ( BaseGoals ), whenPushSatisfies ( IsMaven ). setGoals ( BuildGoals ), ); The rules are evaluated in order. The resulting goals are combined and de-duplicated to determine the goals that will be set on the push. The rules themselves are written in a simple internal DSL that aims to be human readable. The onAnyPush() function will return true on all pushes. The whenPushSatisfies function is used to combine other rules. For example, we could limit building to Java projects, rather than all Maven projects, as follows: whenPushSatisfies ( IsMaven , IsJava ). setGoals ( BuildGoals ), The DSL includes support for logical operations. For example, this will build all Maven projects except Kotlin projects: whenPushSatisfies ( IsMaven , not ( IsKotlin )). setGoals ( BuildGoals ),","title":"Set goals on push with \"push rules\""},{"location":"developer/set-goals/#pushrule","text":"Each argument to sdm.withPushRules is a PushRule, contributing goals on a commit if a condition is met. That condition is a PushTest.","title":"PushRule"},{"location":"developer/set-goals/#pushtest","text":"Push tests are functions that look at the content of a push and decide whether this goal applies. See: Documentation on Push Tests Here\u2019s a quick example of a push test: export const IsMaven : PredicatePushTest = predicatePushTest ( \"Is Maven\" , p => p . hasFile ( \"pom.xml\" )); To establish a PushTest for whether a project uses Maven as a build tool, this code calls a constructor function predicatePushTest with a name for the PushTest and a function from a Project to a Promise<Boolean> . The example spring-sdm uses this PushTest to create a PushRule, which sets build goals only on Maven projects: whenPushSatisfies ( IsMaven ). setGoals ( buildGoals )","title":"PushTest"},{"location":"developer/set-goals/#stop-setting-goals","text":"Sometimes we want to stop setting goals after a particular rule evaluates to true. For example, we can modify the earlier example to do nothing at all if the project has a leaveMeAlone file in the root directory: sdm . withPushRules ( whenPushSatisfies ( async pu => pu . project . hasFile ( \"leaveMeAlone\" )). setGoals ( goals ( \"none\" ). andLock ()), onAnyPush (). setGoals ( BaseGoals ), whenPushSatisfies ( IsMaven ). setGoals ( BuildGoals ), ); The andLock method on the Goals class causes further goal evaluation to be ignored.","title":"Stop setting goals"},{"location":"developer/slack/","text":"Atomist supports sending rich , actionable and updatable Slack messages. Messages can be sent by an event handler or a command handler. Rich messages take full advantage of Slack\u2019s native message formatting capabilities Actionable messages contain buttons and menus that trigger new commands on behalf of the user who clicked them Updatable messages can be rewritten with new content over time in response to new events and actions. This helps reduce the number of messages from the Atomist bot in a Slack channel. Here\u2019s an example of a message with different Attachments and Actions from the Atomist open source community Slack workspace. If you\u2019re not familiar with the main concepts of Slack message formatting, you may want to read Slack\u2019s documentation before you read the following sections. MessageClient interface Let\u2019s take a look at the MessageClient interface. export interface MessageClient { respond ( msg : string | SlackMessage , options? : MessageOptions ) : Promise < any > ; addressUsers ( msg : string | SlackMessage , userNames : string | string [], options? : MessageOptions ) : Promise < any > ; addressChannels ( msg : string | SlackMessage , channelNames : string | string [], options? : MessageOptions ) : Promise < any > ; ... } The MessageClient provides access to methods for sending messages to Slack. It allows you to address messages to users or channels by name or to simply send a response message. Generally the MessageClient is available from the HandlerContext parameter to the handle method of command and event handlers. Response messages A response message is a message that is sent while handling a request to run a certain command; they can therefore only be sent by command handlers. Use the respond method to sending a response message. The Atomist platform takes care of delivering the message into the right conversation in Slack. The following example shows how to send a response message from a command handler. export class HelloWorld implements HandleCommand { public handle ( ctx : HandlerContext ) : Promise < HandlerResult > { return ctx . messageClient . respond ( \"Hello from Atomist\" ) . then (() => Success , failure ); } } User and channel messages Address messages to users by calling the addressUsers method, providing one or more names of Slack users. To send a message to one or more channels, call the addressChannels method. Note If you want to send a direct message to a user in your Slack workspace, use the addressUsers method with the user name of the recipient. Here is an example of sending a simple message into the #general channel of your Slack workspace: export class HelloWorld implements HandleCommand { public handle ( ctx : HandlerContext ) : Promise < HandlerResult > { return ctx . messageClient . addressChannels ( \"Hello from Atomist\" , \"general\" ) . then (() => Success , failure ); } } In this example, you are sending the message only to the #general channel. It is possible to send the same message into more than one channel by simply providing an array of channel names to the addressChannels method. The same works for addressUsers . Formatting messages In the previous section you saw how to address and send messages to Slack. This section covers formatting simple and complex Slack messages. It also demonstrates how to add buttons and menus to messages. Simple messages The addressUsers , addressChannels and respond methods accept a string message as first argument. A simple string message can still have some basic formatting. Here are a couple of examples of simple messages: Code Output messageClient.respond(\"This is a plain message\"); This is a plan message messageClient.respond(\"This some *bold* text\"); This is some bold text messageClient.respond(\"This some _italics_ text\"); This is some italics text messageClient.respond(\"Some multiline\\ntext\"); Some multiline text More details on Slack text formatting can be found their the documentation . Rich messages For more complex, rich messages, Atomist provides the SlackMessage type as part of the @atomist/slack-messages npm module. The SlackMessage type can have Attachments and Actions . More details on those concepts can be found in the Slack documentation . In order to create a formatted Slack message, simply build an instance of SlackMessage with all desired properties. Here is an example: import * as slack from \"@atomist/slack-messages\" ; const message : slack.SlackMessage = { attachments : [{ fallback : \"How to filter by parent or ancestor directory with sysdig\" , author_name : \"Janek Bogucki\" , author_link : \"https://stackoverflow.com/users/148440/janek-bogucki\" , author_icon : \"https://www.gravatar.com/avatar/5ccd05d83049593205406ac74eacb323?s=128&d=identicon&r=PG\" , title : \"How to filter by parent or ancestor directory withsysdig\" , title_link : \"https://stackoverflow.com/questions/41827350/how-to-filter-by-parent-or-ancestor-directory-with-sysdig\" , thumb_url : \"https://slack-imgs.com/?c=1&o1=wi75.he75&url=https%3A%2F%2Fcdn.sstatic.net%2FSites%2Fstackoverflow%2Fimg%2Fapple-touch-icon%402.png%3Fv%3D73d79a89bded\" , footer : \"file, sysdig\" , ts : 1485258115 }, { fallback : \"Show more...\" , title : \"Show more...\" , title_link : \"http://stackoverflow.com/search?order=desc&sort=relevance&q=atomist\" }] }; Once the SlackMessage is created you can send it via the MessageClient : ctx . messageClient . respond ( message ); This renders the following in Slack: Adding message buttons In the previous section you saw how rich messages can be created and posted to Slack. Now you\u2019ll see how to turn this message into an actionable message by adding a button to it. With Atomist, it\u2019s easy to bind Slack action buttons to command handlers. Such a binding consists of three parts: the specification of the button as required by Slack, a reference to the command handler , and optional parameters that should be pre-populated when invoking the command. The button specification is defined by Slack in the field guide . Here is an example of a button with a confirmation pop-up: import { ButtonSpecification } from \"@atomist/sdm\" ; const buttonSpec : ButtonSpecification = { text : \"Search Again\" , confirm : { title : \"Search Again?\" , text : \"Do you really want to run the search again?\" , dismiss_text : \"No\" , ok_text : \"Yes\" }, }; Adding message menus Message menus are very similar to message buttons in the way they are created and added to the message. The main difference is that menus are defined with a MenuSpecification instead of a ButtonSpecification . Besides the name of the menu, a MenuSpecification allows you to define menu options and option groups. See the following example: import { MenuSpecification } from \"@atomist/sdm\" ; const menuSpec : MenuSpecification = { text : \"Issue Labels\" , options : [{ text : \"Bug\" , value : \"bug\" , }, { text : \"Enhancement\" , value : \"enhancement\" , }, { text : \"Invalid\" , value : \"invalid\" , }], }; const message : slack.SlackMessage = { attachments : [{ // ... actions : [ menuForCommand ( menuSpec , handler , \"label\" ), ], }], }; To create the menu, menuForCommand is called with the menu details, the reference to the command handler and the name of the parameter on the command handler that the selected value of the menu should be bound to; in this example, the value of the option will be bound to the label parameter. Message options With MessageOptions actionable Slack message can be turned into updatable messages; the MessageOptions interface provides important options to handle and tune message updates and rewrites in Slack. The following section describes the properties on the MessageOptions interface and what they can be used for. See also: [APIDoc][message-options-apidoc] For example: const messageOptions = { id: `build-summary/${owner}/${repo}/${sha}`, // sending another message with this ID will update this one ts: Date.now(), ttl: 60 * 60 * 1000, // update this message for up to one hour; after that, post anew post: \"always\", // if this message didn't exist, create it } The id property uniquely identifies a message in a channel or direct message. But it\u2019s optional! Use it if you want to update this message later. Otherwise we\u2019ll generate something unique. ts specifies the time in milliseconds of the message. If not set, it defaults to the current time. This property is important to maintain correct order of messages: the Atomist bot will not post a message with a ts if there is a message for the same id but a later ts already in the channel or direct message. ttl or time-to-live defines the amount of time in milliseconds that a message can be updated, after which a new instance of the message is posted to the bottom of the Slack stream. So, when a message is received by the bot, it compares the ts + ttl of the existing message with ts of the new message; if ts + ttl is smaller, a new message ia posted to the bottom of the Slack stream and the existing message is not rewritten. As long ts + ttl is greater then ts of the new message, the existing message will be overwritten. Lastly, the post property specifies whether a message should be posted only if it is an update to a previously posted message with the same id . If post === \"always\" , the message is always posted as a new message and never rewrites a previous message. will never rewrite a previous message. [message-options-apidoc]: https://atomist.github.io/automation-client/interfaces/ lib_spi_message_messageclient .messageoptions.html (APIdoc for Message Options)","title":"Chat Messages"},{"location":"developer/slack/#messageclient-interface","text":"Let\u2019s take a look at the MessageClient interface. export interface MessageClient { respond ( msg : string | SlackMessage , options? : MessageOptions ) : Promise < any > ; addressUsers ( msg : string | SlackMessage , userNames : string | string [], options? : MessageOptions ) : Promise < any > ; addressChannels ( msg : string | SlackMessage , channelNames : string | string [], options? : MessageOptions ) : Promise < any > ; ... } The MessageClient provides access to methods for sending messages to Slack. It allows you to address messages to users or channels by name or to simply send a response message. Generally the MessageClient is available from the HandlerContext parameter to the handle method of command and event handlers.","title":"MessageClient interface"},{"location":"developer/slack/#response-messages","text":"A response message is a message that is sent while handling a request to run a certain command; they can therefore only be sent by command handlers. Use the respond method to sending a response message. The Atomist platform takes care of delivering the message into the right conversation in Slack. The following example shows how to send a response message from a command handler. export class HelloWorld implements HandleCommand { public handle ( ctx : HandlerContext ) : Promise < HandlerResult > { return ctx . messageClient . respond ( \"Hello from Atomist\" ) . then (() => Success , failure ); } }","title":"Response messages"},{"location":"developer/slack/#user-and-channel-messages","text":"Address messages to users by calling the addressUsers method, providing one or more names of Slack users. To send a message to one or more channels, call the addressChannels method. Note If you want to send a direct message to a user in your Slack workspace, use the addressUsers method with the user name of the recipient. Here is an example of sending a simple message into the #general channel of your Slack workspace: export class HelloWorld implements HandleCommand { public handle ( ctx : HandlerContext ) : Promise < HandlerResult > { return ctx . messageClient . addressChannels ( \"Hello from Atomist\" , \"general\" ) . then (() => Success , failure ); } } In this example, you are sending the message only to the #general channel. It is possible to send the same message into more than one channel by simply providing an array of channel names to the addressChannels method. The same works for addressUsers .","title":"User and channel messages"},{"location":"developer/slack/#formatting-messages","text":"In the previous section you saw how to address and send messages to Slack. This section covers formatting simple and complex Slack messages. It also demonstrates how to add buttons and menus to messages.","title":"Formatting messages"},{"location":"developer/slack/#simple-messages","text":"The addressUsers , addressChannels and respond methods accept a string message as first argument. A simple string message can still have some basic formatting. Here are a couple of examples of simple messages: Code Output messageClient.respond(\"This is a plain message\"); This is a plan message messageClient.respond(\"This some *bold* text\"); This is some bold text messageClient.respond(\"This some _italics_ text\"); This is some italics text messageClient.respond(\"Some multiline\\ntext\"); Some multiline text More details on Slack text formatting can be found their the documentation .","title":"Simple messages"},{"location":"developer/slack/#rich-messages","text":"For more complex, rich messages, Atomist provides the SlackMessage type as part of the @atomist/slack-messages npm module. The SlackMessage type can have Attachments and Actions . More details on those concepts can be found in the Slack documentation . In order to create a formatted Slack message, simply build an instance of SlackMessage with all desired properties. Here is an example: import * as slack from \"@atomist/slack-messages\" ; const message : slack.SlackMessage = { attachments : [{ fallback : \"How to filter by parent or ancestor directory with sysdig\" , author_name : \"Janek Bogucki\" , author_link : \"https://stackoverflow.com/users/148440/janek-bogucki\" , author_icon : \"https://www.gravatar.com/avatar/5ccd05d83049593205406ac74eacb323?s=128&d=identicon&r=PG\" , title : \"How to filter by parent or ancestor directory withsysdig\" , title_link : \"https://stackoverflow.com/questions/41827350/how-to-filter-by-parent-or-ancestor-directory-with-sysdig\" , thumb_url : \"https://slack-imgs.com/?c=1&o1=wi75.he75&url=https%3A%2F%2Fcdn.sstatic.net%2FSites%2Fstackoverflow%2Fimg%2Fapple-touch-icon%402.png%3Fv%3D73d79a89bded\" , footer : \"file, sysdig\" , ts : 1485258115 }, { fallback : \"Show more...\" , title : \"Show more...\" , title_link : \"http://stackoverflow.com/search?order=desc&sort=relevance&q=atomist\" }] }; Once the SlackMessage is created you can send it via the MessageClient : ctx . messageClient . respond ( message ); This renders the following in Slack:","title":"Rich messages"},{"location":"developer/slack/#adding-message-buttons","text":"In the previous section you saw how rich messages can be created and posted to Slack. Now you\u2019ll see how to turn this message into an actionable message by adding a button to it. With Atomist, it\u2019s easy to bind Slack action buttons to command handlers. Such a binding consists of three parts: the specification of the button as required by Slack, a reference to the command handler , and optional parameters that should be pre-populated when invoking the command. The button specification is defined by Slack in the field guide . Here is an example of a button with a confirmation pop-up: import { ButtonSpecification } from \"@atomist/sdm\" ; const buttonSpec : ButtonSpecification = { text : \"Search Again\" , confirm : { title : \"Search Again?\" , text : \"Do you really want to run the search again?\" , dismiss_text : \"No\" , ok_text : \"Yes\" }, };","title":"Adding message buttons"},{"location":"developer/slack/#adding-message-menus","text":"Message menus are very similar to message buttons in the way they are created and added to the message. The main difference is that menus are defined with a MenuSpecification instead of a ButtonSpecification . Besides the name of the menu, a MenuSpecification allows you to define menu options and option groups. See the following example: import { MenuSpecification } from \"@atomist/sdm\" ; const menuSpec : MenuSpecification = { text : \"Issue Labels\" , options : [{ text : \"Bug\" , value : \"bug\" , }, { text : \"Enhancement\" , value : \"enhancement\" , }, { text : \"Invalid\" , value : \"invalid\" , }], }; const message : slack.SlackMessage = { attachments : [{ // ... actions : [ menuForCommand ( menuSpec , handler , \"label\" ), ], }], }; To create the menu, menuForCommand is called with the menu details, the reference to the command handler and the name of the parameter on the command handler that the selected value of the menu should be bound to; in this example, the value of the option will be bound to the label parameter.","title":"Adding message menus"},{"location":"developer/slack/#message-options","text":"With MessageOptions actionable Slack message can be turned into updatable messages; the MessageOptions interface provides important options to handle and tune message updates and rewrites in Slack. The following section describes the properties on the MessageOptions interface and what they can be used for. See also: [APIDoc][message-options-apidoc] For example: const messageOptions = { id: `build-summary/${owner}/${repo}/${sha}`, // sending another message with this ID will update this one ts: Date.now(), ttl: 60 * 60 * 1000, // update this message for up to one hour; after that, post anew post: \"always\", // if this message didn't exist, create it } The id property uniquely identifies a message in a channel or direct message. But it\u2019s optional! Use it if you want to update this message later. Otherwise we\u2019ll generate something unique. ts specifies the time in milliseconds of the message. If not set, it defaults to the current time. This property is important to maintain correct order of messages: the Atomist bot will not post a message with a ts if there is a message for the same id but a later ts already in the channel or direct message. ttl or time-to-live defines the amount of time in milliseconds that a message can be updated, after which a new instance of the message is posted to the bottom of the Slack stream. So, when a message is received by the bot, it compares the ts + ttl of the existing message with ts of the new message; if ts + ttl is smaller, a new message ia posted to the bottom of the Slack stream and the existing message is not rewritten. As long ts + ttl is greater then ts of the new message, the existing message will be overwritten. Lastly, the post property specifies whether a message should be posted only if it is an update to a previously posted message with the same id . If post === \"always\" , the message is always posted as a new message and never rewrites a previous message. will never rewrite a previous message. [message-options-apidoc]: https://atomist.github.io/automation-client/interfaces/ lib_spi_message_messageclient .messageoptions.html (APIdoc for Message Options)","title":"Message options"},{"location":"developer/spawn-builder/","text":"This page describes creating a generic builder for your Build Goal . You can construct a Builder around any shell command that can run in whatever environment your SDM runs in. This uses the Node child_process library to spawn another process for each command you supply. For instance, this documentation site uses a builder that runs these commands: [ \"pip install -r requirements.txt\" , \"mkdocs build\" , ] spawnBuilder To turn a set of operating system commands into a Builder, use the spawnBuilder function in the Build pack. It accepts a SpawnBuilderOptions object, with the following necessary properties: name: a string that helps you identify the builder commands: an array of SpawnCommands to run as child processes. logInterpreter: a function to pull out the interesting bit of the log projectToAppInfo: determine a name and version based on the code. SpawnCommand The commands property contains a list of SpawnCommands to run, sequentially, in a separate process in the project directory. Create a SpawnCommand object for each command, with a single-word command and the arguments separated: { command : \"pip\" , argument : [ \"install\" , \"-r\" , \"requirements.txt\" ], } You can add options to the SpawnCommand, and they\u2019ll be passed on to the child_process npm package. LogInterpreter The logInterpreter is a function that extracts the interesting bit from the build log. You can customize this function to highlight the particular errors that you see in your own builds, and put exactly what you want to see into chat messages. A good default is a log interpreter that pulls out the last few lines of the log. There\u2019s a convenience function for that: lastLinesLogInterpreter(\"Tail of the log:\", 10); If you provide your own function, make it take a string(the contents of the log) and return an InterpretedLog : { message : \"Here is what you need to know:\" , relevantPart : usefulBitOfLog , } projectToAppInfo Look at the content of your project and determine the name and version.Here\u2019s one implementation: async ( p : Project ) => { return { name : p.id.repo , version : p.id.sha , id : p.id as RemoteRepoRef , }; }, Put it together Assemble these properties into a SpawnBuilderObject and get a Builder: const mkdocsBuilder = spawnBuilder ({ name : \"mkdocs spawn builder\" , logInterpreter , projectToAppInfo , commands : [ \"pip install -r requirements.txt\" , \"mkdocs build\" , ]. map ( m => asSpawnCommand ( m )), }); Use the Builder in your BuilderRegistration that you register with a Build Goal .","title":"Generic Builder"},{"location":"developer/spawn-builder/#spawnbuilder","text":"To turn a set of operating system commands into a Builder, use the spawnBuilder function in the Build pack. It accepts a SpawnBuilderOptions object, with the following necessary properties: name: a string that helps you identify the builder commands: an array of SpawnCommands to run as child processes. logInterpreter: a function to pull out the interesting bit of the log projectToAppInfo: determine a name and version based on the code.","title":"spawnBuilder"},{"location":"developer/spawn-builder/#spawncommand","text":"The commands property contains a list of SpawnCommands to run, sequentially, in a separate process in the project directory. Create a SpawnCommand object for each command, with a single-word command and the arguments separated: { command : \"pip\" , argument : [ \"install\" , \"-r\" , \"requirements.txt\" ], } You can add options to the SpawnCommand, and they\u2019ll be passed on to the child_process npm package.","title":"SpawnCommand"},{"location":"developer/spawn-builder/#loginterpreter","text":"The logInterpreter is a function that extracts the interesting bit from the build log. You can customize this function to highlight the particular errors that you see in your own builds, and put exactly what you want to see into chat messages. A good default is a log interpreter that pulls out the last few lines of the log. There\u2019s a convenience function for that: lastLinesLogInterpreter(\"Tail of the log:\", 10); If you provide your own function, make it take a string(the contents of the log) and return an InterpretedLog : { message : \"Here is what you need to know:\" , relevantPart : usefulBitOfLog , }","title":"LogInterpreter"},{"location":"developer/spawn-builder/#projecttoappinfo","text":"Look at the content of your project and determine the name and version.Here\u2019s one implementation: async ( p : Project ) => { return { name : p.id.repo , version : p.id.sha , id : p.id as RemoteRepoRef , }; },","title":"projectToAppInfo"},{"location":"developer/spawn-builder/#put-it-together","text":"Assemble these properties into a SpawnBuilderObject and get a Builder: const mkdocsBuilder = spawnBuilder ({ name : \"mkdocs spawn builder\" , logInterpreter , projectToAppInfo , commands : [ \"pip install -r requirements.txt\" , \"mkdocs build\" , ]. map ( m => asSpawnCommand ( m )), }); Use the Builder in your BuilderRegistration that you register with a Build Goal .","title":"Put it together"},{"location":"developer/spawn/","text":"From within your automations, every other tool is also at your disposal. You can trigger any operating system command from within Node.js. Since this is common and important, the Atomist SDM has wrapped other Node.js libraries to make running commands and handling errors easier from within TypeScript, in async functions. This page describes how to run an externam command when you implement a goal and anywhere else in an SDM Any of the options below accepts an optional last argument for options that are passed through to the underlying libraries. You can pass any of the options documented in the underlying Node library . In a goal If you\u2019re implementing a custom goal , then you\u2019re writing a function of type ExecuteGoal , which receives a GoalInvocation . To run external commands within your function, wrap it in doWithProject . Then your function can receive ProjectAwareGoalInvocation , which has convenience methods to run an external command in your project\u2019s directory. Send command output to the log If you want the output of the command to go to the goal\u2019s progress log , then use spawn . It returns an object that includes information on whether the command succeeded, so check it. This will send stderr and stdout to the goal\u2019s log. Here is an example with error handling: export const executeMkdocsStrict : ExecuteGoal = doWithProject ( async ( inv : ProjectAwareGoalInvocation ) => { const mkdocsResult = await inv . spawn ( \"mkdocs\" , [ \"build\" , \"--strict\" ]); if ( mkdocsResult . code !== 0 ) { const message = mkdocsResult . error ? mkdocsResult . error . message : \"See the log for output\" ; return { code : mkdocsResult.status || 2 , message }; } return { code : 0 }; }); If the success of the command depends on its output, then consider providing an errorFinder option to spawn . Get the command output back If you want to analyze the command output instead of sending it to the log, then use exec . It returns an object containing stdout and stderr strings. If the command fails, the returned Promise is rejected with an ExecPromiseError . Here is an example with error handling: export const executeMkdocsStrict : ExecuteGoal = doWithProject ( async ( inv : ProjectAwareGoalInvocation ) => { try { const mkdocsResult = await inv . exec ( \"mkdocs\" , [ \"build\" , \"--strict\" ]); inv . progressLog . write ( mkdocsResult . stdout ); inv . progressLog . write ( mkdocsResult . stderr ); // do stuff with output return { code : 0 }; } catch ( e ) { const epe = e as ExecPromiseError ; inv . addressChannels ( `mkdocs --strict failed on ${ inv . id . sha } on ${ inv . id . branch } : ${ epe . message } ` ); return { code : epe.status || 1 , message : epe.message }; } }); Anywhere else The simplest way to run an external command is with execPromise . Pass the command as a string and its parameters as an array of strings. It returns a Promise of an object containing the output of the command in stderr and stdout . If the command fails (including if it exits with an error code), the Promise is rejected. Unless you provide a cwd option, this will run in the SDM\u2019s root directory. await execPromise ( \"docker\" , [ \"push\" , \"anImageTag\" ]); Here\u2019s a full example with some error handling and some indication of what is available in the result or the error: import { execPromise , ExecPromiseError } from \"@atomist/sdm\" ; async function demoExecPromise() { try { const dockerPushResult = await execPromise ( \"docker\" , [ \"push\" , \"anImageTag\" ]); const description = `docker push completed successfully. Stdout: ${ dockerPushResult . stdout } Stderr: ${ dockerPushResult . stderr } ` ; } catch ( e ) { const epe = e as ExecPromiseError ; if ( e . error ) { // an exception happened starting it up throw e ; } const description = `Exit code: ${ e . status } , stderr: ${ e . stderr } ` ; } } A little more flexibility You can also use spawnPromise . This function will always give you data back, and you can check it for errors. You can get the output back in stderr and stdout , or you can pass a log in the options. Use a log when the command might produce a lot of output. Here\u2019s an example with error handling, where we both write the (short) output to the log and use it for error reporting. import { spawnPromise , GoalInvocation } from \"@atomist/sdm\" ; async function demoSpawnPromise ( inv : GoalInvocation ) { const dockerPushResult = await spawnPromise ( \"docker\" , [ \"push\" , \"anImageTag\" ]); if ( dockerPushResult . error ) { return { code : 1 , message : dockerPushResult.error.message } } if ( dockerPushResult . status !== 0 ) { inv . addressChannels ( `docker push failed on ${ inv . id . sha } on ${ inv . id . branch } : ${ dockerPushResult . stderr } ` ); return { code : dockerPushResult.status || 1 , message : dockerPushResult.stderr } } const description = `docker push completed successfully. Stdout: ${ dockerPushResult . stdout } Stderr: ${ dockerPushResult . stderr } ` ; // do stuff with output } Running a command in a Project Most of the time you\u2019ll want to run in the directory of your project. The trick is to add { cwd: project.baseDir } to any call to any of the above methods. When you write a function to describe a custom build or autofix , you\u2019ll have access to the Project. When creating a goal , use doWithProject (easier!), or you can clone the project explicitly using the SDM\u2019s configured ProjectLoader. Here is a full example. In this code, configuration is the second argument passed to your SDM configuration function, typically in machine.ts . inv . configuration . sdm . projectLoader . doWithProject ({ credentials : inv.credentials , id : inv.id , readOnly : true , // tell it whether it can reuse this clone later cloneOptions : { detachHead : true }, }, async project => { // run the command const mkdocsResult = await spawnPromise ( \"mkdocs\" , [ \"build\" , \"--strict\" ], { cwd : project.baseDir }); // the rest is logging and error handling inv . progressLog . write ( mkdocsResult . stdout ); inv . progressLog . write ( mkdocsResult . stderr ); if ( mkdocsResult . error ) { // this is an unexpected error return { code : mkdocsResult.status || 2 , message : mkdocsResult.error.message } } if ( mkdocsResult . status !== 0 ) { // this is an expected kind of error; it means the tests failed inv . addressChannels ( `mkdocs --strict failed on ${ inv . id . sha } on ${ inv . id . branch } : ${ mkdocsResult . stderr } ` ); return { code : mkdocsResult.status || 1 , message : mkdocsResult.stderr } } return { code : 0 }; }); }","title":"Running External Commands"},{"location":"developer/spawn/#in-a-goal","text":"If you\u2019re implementing a custom goal , then you\u2019re writing a function of type ExecuteGoal , which receives a GoalInvocation . To run external commands within your function, wrap it in doWithProject . Then your function can receive ProjectAwareGoalInvocation , which has convenience methods to run an external command in your project\u2019s directory.","title":"In a goal"},{"location":"developer/spawn/#send-command-output-to-the-log","text":"If you want the output of the command to go to the goal\u2019s progress log , then use spawn . It returns an object that includes information on whether the command succeeded, so check it. This will send stderr and stdout to the goal\u2019s log. Here is an example with error handling: export const executeMkdocsStrict : ExecuteGoal = doWithProject ( async ( inv : ProjectAwareGoalInvocation ) => { const mkdocsResult = await inv . spawn ( \"mkdocs\" , [ \"build\" , \"--strict\" ]); if ( mkdocsResult . code !== 0 ) { const message = mkdocsResult . error ? mkdocsResult . error . message : \"See the log for output\" ; return { code : mkdocsResult.status || 2 , message }; } return { code : 0 }; }); If the success of the command depends on its output, then consider providing an errorFinder option to spawn .","title":"Send command output to the log"},{"location":"developer/spawn/#get-the-command-output-back","text":"If you want to analyze the command output instead of sending it to the log, then use exec . It returns an object containing stdout and stderr strings. If the command fails, the returned Promise is rejected with an ExecPromiseError . Here is an example with error handling: export const executeMkdocsStrict : ExecuteGoal = doWithProject ( async ( inv : ProjectAwareGoalInvocation ) => { try { const mkdocsResult = await inv . exec ( \"mkdocs\" , [ \"build\" , \"--strict\" ]); inv . progressLog . write ( mkdocsResult . stdout ); inv . progressLog . write ( mkdocsResult . stderr ); // do stuff with output return { code : 0 }; } catch ( e ) { const epe = e as ExecPromiseError ; inv . addressChannels ( `mkdocs --strict failed on ${ inv . id . sha } on ${ inv . id . branch } : ${ epe . message } ` ); return { code : epe.status || 1 , message : epe.message }; } });","title":"Get the command output back"},{"location":"developer/spawn/#anywhere-else","text":"The simplest way to run an external command is with execPromise . Pass the command as a string and its parameters as an array of strings. It returns a Promise of an object containing the output of the command in stderr and stdout . If the command fails (including if it exits with an error code), the Promise is rejected. Unless you provide a cwd option, this will run in the SDM\u2019s root directory. await execPromise ( \"docker\" , [ \"push\" , \"anImageTag\" ]); Here\u2019s a full example with some error handling and some indication of what is available in the result or the error: import { execPromise , ExecPromiseError } from \"@atomist/sdm\" ; async function demoExecPromise() { try { const dockerPushResult = await execPromise ( \"docker\" , [ \"push\" , \"anImageTag\" ]); const description = `docker push completed successfully. Stdout: ${ dockerPushResult . stdout } Stderr: ${ dockerPushResult . stderr } ` ; } catch ( e ) { const epe = e as ExecPromiseError ; if ( e . error ) { // an exception happened starting it up throw e ; } const description = `Exit code: ${ e . status } , stderr: ${ e . stderr } ` ; } }","title":"Anywhere else"},{"location":"developer/spawn/#a-little-more-flexibility","text":"You can also use spawnPromise . This function will always give you data back, and you can check it for errors. You can get the output back in stderr and stdout , or you can pass a log in the options. Use a log when the command might produce a lot of output. Here\u2019s an example with error handling, where we both write the (short) output to the log and use it for error reporting. import { spawnPromise , GoalInvocation } from \"@atomist/sdm\" ; async function demoSpawnPromise ( inv : GoalInvocation ) { const dockerPushResult = await spawnPromise ( \"docker\" , [ \"push\" , \"anImageTag\" ]); if ( dockerPushResult . error ) { return { code : 1 , message : dockerPushResult.error.message } } if ( dockerPushResult . status !== 0 ) { inv . addressChannels ( `docker push failed on ${ inv . id . sha } on ${ inv . id . branch } : ${ dockerPushResult . stderr } ` ); return { code : dockerPushResult.status || 1 , message : dockerPushResult.stderr } } const description = `docker push completed successfully. Stdout: ${ dockerPushResult . stdout } Stderr: ${ dockerPushResult . stderr } ` ; // do stuff with output }","title":"A little more flexibility"},{"location":"developer/spawn/#running-a-command-in-a-project","text":"Most of the time you\u2019ll want to run in the directory of your project. The trick is to add { cwd: project.baseDir } to any call to any of the above methods. When you write a function to describe a custom build or autofix , you\u2019ll have access to the Project. When creating a goal , use doWithProject (easier!), or you can clone the project explicitly using the SDM\u2019s configured ProjectLoader. Here is a full example. In this code, configuration is the second argument passed to your SDM configuration function, typically in machine.ts . inv . configuration . sdm . projectLoader . doWithProject ({ credentials : inv.credentials , id : inv.id , readOnly : true , // tell it whether it can reuse this clone later cloneOptions : { detachHead : true }, }, async project => { // run the command const mkdocsResult = await spawnPromise ( \"mkdocs\" , [ \"build\" , \"--strict\" ], { cwd : project.baseDir }); // the rest is logging and error handling inv . progressLog . write ( mkdocsResult . stdout ); inv . progressLog . write ( mkdocsResult . stderr ); if ( mkdocsResult . error ) { // this is an unexpected error return { code : mkdocsResult.status || 2 , message : mkdocsResult.error.message } } if ( mkdocsResult . status !== 0 ) { // this is an expected kind of error; it means the tests failed inv . addressChannels ( `mkdocs --strict failed on ${ inv . id . sha } on ${ inv . id . branch } : ${ mkdocsResult . stderr } ` ); return { code : mkdocsResult.status || 1 , message : mkdocsResult.stderr } } return { code : 0 }; }); }","title":"Running a command in a Project"},{"location":"developer/team/","text":"In team mode, your SDM connects to the Atomist service. You get: triggering, on GraphQL subscriptions. Events are saved up while your SDM is down or restarting. chat integration. The addressChannels function on listener and goal invocations sends messages to linked channels in Slack or MS Teams. queries to a persistent model. Execute GraphQL against the history of your commits, deployments, builds, etc. linkable goal progress logs What is necessary to enable team mode You\u2019ll need an Atomist workspace for your team or organization. See Getting started to sign up, or ask your Atomist administrator to invite you to the team\u2019s workspace. You\u2019ll need the workspace ID and an API key. Find the workspace ID On the web interface , you can find the Workspace ID on the settings page (click the gear). Get an API key You\u2019ll need an API key that identifies you to the Atomist service. Get one here Obtain this from the web interface , by clicking on your username in the upper right. Provide the API key to the SDM Supply the API in configuration \u2013 the easiest way is by running atomist config in your terminal, or by populating the API key in your $HOME/.atomist/client.config.json file. See your SDM registration When your SDM registers with the Atomist service, you can see this registration in the Atomist web interface. Go to app.atomist.com , log in, and make sure your team is selected. Then click on the little \u201cSettings\u201d gear. ] Choose \u201cAutomation Clients\u201d from the tab. (This includes SDMs.) This will show you a list of registered SDMs and built-in automations. Click the little down arrow to expand information. ] The detailed information on the registered SDM includes commands, event subscriptions, and a metadata section. The metadata section has clues about where it\u2019s running, such as the system.hostname . It also shows the atomist.policy : durable or ephemeral. Durable subscriptions An SDM that starts up as durable (usually because you ran it with ATOMIST_ENV=production) will get all the events it subscribes to, even if it is not up all the time. The Atomist service saves events for it (up to a point). This registration will remain active even when the SDM is down. Every unique name/version combination will remain active until you delete the registration in the web interface. Click \u201cdelete\u201d to remove a durable registration. You\u2019ll need to do this when you upgrade your SDM to a new version, after you shut down the old version. ] In development mode, like when you\u2019re experimenting with an SDM on your laptop, you want atomist.policy to be ephemeral . Events are sent while the SDM is up, and ignored while it is down. The registration disappears when the SDM disconnects. More info See more about deploying SDMs in production Contrast with local mode","title":"Team Mode"},{"location":"developer/team/#what-is-necessary-to-enable-team-mode","text":"You\u2019ll need an Atomist workspace for your team or organization. See Getting started to sign up, or ask your Atomist administrator to invite you to the team\u2019s workspace. You\u2019ll need the workspace ID and an API key.","title":"What is necessary to enable team mode"},{"location":"developer/team/#find-the-workspace-id","text":"On the web interface , you can find the Workspace ID on the settings page (click the gear).","title":"Find the workspace ID"},{"location":"developer/team/#get-an-api-key","text":"You\u2019ll need an API key that identifies you to the Atomist service. Get one here Obtain this from the web interface , by clicking on your username in the upper right.","title":"Get an API key"},{"location":"developer/team/#provide-the-api-key-to-the-sdm","text":"Supply the API in configuration \u2013 the easiest way is by running atomist config in your terminal, or by populating the API key in your $HOME/.atomist/client.config.json file.","title":"Provide the API key to the SDM"},{"location":"developer/team/#see-your-sdm-registration","text":"When your SDM registers with the Atomist service, you can see this registration in the Atomist web interface. Go to app.atomist.com , log in, and make sure your team is selected. Then click on the little \u201cSettings\u201d gear. ] Choose \u201cAutomation Clients\u201d from the tab. (This includes SDMs.) This will show you a list of registered SDMs and built-in automations. Click the little down arrow to expand information. ] The detailed information on the registered SDM includes commands, event subscriptions, and a metadata section. The metadata section has clues about where it\u2019s running, such as the system.hostname . It also shows the atomist.policy : durable or ephemeral.","title":"See your SDM registration"},{"location":"developer/team/#durable-subscriptions","text":"An SDM that starts up as durable (usually because you ran it with ATOMIST_ENV=production) will get all the events it subscribes to, even if it is not up all the time. The Atomist service saves events for it (up to a point). This registration will remain active even when the SDM is down. Every unique name/version combination will remain active until you delete the registration in the web interface. Click \u201cdelete\u201d to remove a durable registration. You\u2019ll need to do this when you upgrade your SDM to a new version, after you shut down the old version. ] In development mode, like when you\u2019re experimenting with an SDM on your laptop, you want atomist.policy to be ephemeral . Events are sent while the SDM is up, and ignored while it is down. The registration disappears when the SDM disconnects.","title":"Durable subscriptions"},{"location":"developer/team/#more-info","text":"See more about deploying SDMs in production Contrast with local mode","title":"More info"},{"location":"developer/transform/","text":"As developers, we change code. When we know exactly how we want to change the code, we can automate that. Compared to doing it by hand, automation is consistent and repeatable. Atomist gives us the superpower to change code on demand, in one project or hundreds, and in response to events. These changes become commits, branches, or pull requests. Begin with a Code Transform: a function that acts on a project. You write this part, and test it with unit tests. Turn that into a command to run on demand, then an Autofix to run on every push. This page shows how to: Create a code transform that runs on-demand Require parameters to your code transform Customize the automated pull request Make Atomist wait for a build to succeed before creating the pull request Make Atomist merge the PR automatically when a build succeeds After that, you might want to make your code transform into an Autofix . Create a code transform Code transforms are functions that receive the project as an input and changes the content of the project as a result. For a quick example, assume we want to add an Apache licence file to the project. The transform would retrieve the license content and add a LICENSE file with that content. export const AddApacheLicenseFileTransform : CodeTransform < NoParameters > = async ( p : Project ) => { const httpClient = DefaultHttpClientFactory . create (); const license = await httpClient . exchange ( \"https://www.apache.org/licenses/LICENSE-2.0.txt\" ); return p . addFile ( \"LICENSE\" , license . body as string ); }; When you want to do more in a code transform, you might want to: To add or remove files, you can use the Project interface (the API for modifying files in the project). To do basic operations (like a text replacement) on multiple files, check out projectUtils To change code based on a language\u2019s abstract syntax tree (AST), try astUtils To change code based on a more intuitive selection criteria, try the microgrammars in parseUtils . make HTTP calls in an SDM (if you\u2019re curious why that example uses DefaultHttpClientFactory) Creating a command for a transform A code transform can be called through various means. One of those means is directly through issuing a command. This command needs to be defined and the transform needs to be referenced in that definition. export const AddApacheLicenseFile : CodeTransformRegistration < NoParameters > = { transform : AddApacheLicenseFileTransform , name : \"add apache license file\" , description : `Add Apache 2.0 license file` , intent : [ \"add apache license file\" , \"add license file\" ], }; Each intent acts as an alias for invoking the command. The description is going to be the title of an automatic pull request. The transform\u2019s name will appear in the branch. See also: CodeTransformRegistration API doc Adding the transform command to the SDM Tell the SDM about the command. In order to achieve this you need to register the command with the SDM. In your SDM definition where you have access to the SDM instance, add the following registration: sdm . addCodeTransformCommand ( AddApacheLicenseFile ); Calling the command Local To test your command, run your SDM in local mode and then atomist start --local then, in a separate terminal, change directory to one of your repositories under your Atomist project root (usually $HOME/atomist). Then: atomist add apache license file Atomist will create a new branch with the changed code on it. List all your branches to find it: git branch Team When you run your SDM in team mode , your command will be available in chat. Go to a channel associated with a repository , and talk to the Atomist bot: @atomist add apache license file Atomist will create a branch and apply the code transform on that branch. It will also create a pull request for the commits generated by that branch. By default, the name of the pull request will be the description of the code transform. If you want to run the transform against a branch other than the default branch, add targets.branch=other-branch-name to the command in chat. See also: Invoking commands Adding parameters to the code transform command Sometimes you need additional input after issuing the command to transform a certain piece of code. Say that we wish to make the license file transformation a bit more flexible and allow of different types of licences. First we need to define the data structure that will hold the parameters. @Parameters () class AddApacheLicenseFileParameters { @Parameter ({ displayName : \"License type\" , validInput : \"apache20, gpl, lgpl\" , pattern : /(apache20|gpl|lgpl)/ , required : false , }) public license : \"apache20\" | \"gpl\" | \"lgpl\" = \"apache20\" ; } Next we need to make the transform aware of the new parameters and alter the internal logic in order to take those parameters into account. export const AddApacheLicenseFileTransform : CodeTransform < AddApacheLicenseFileParameters > = async ( p , params ) => { const licenses = { apache20 : \"https://www.apache.org/licenses/LICENSE-2.0.txt\" , gpl : \"https://www.gnu.org/licenses/gpl-2.0.txt\" , lgpl : \"https://www.gnu.org/licenses/lgpl-3.0.txt\" , }; const httpClient = DefaultHttpClientFactory . create (); const license = await httpClient . exchange ( licenses [ params . parameters . license ]); return p . addFile ( \"LICENSE\" , license . body as string ); }; Finally, we need to alter the command registration so that it recognizes the command parameters and prompt for their values if they are required. export const AddApacheLicenseFile : CodeTransformRegistration < AddApacheLicenseFileParameters > = { transform : AddApacheLicenseFileTransform , paramsMaker : AddApacheLicenseFileParameters , name : \"add apache license file\" , description : `Add Apache 2.0 license file` , intent : [ \"add apache license file\" , \"add license file\" ], }; When issuing the command, it will prompt for the parameters values that are required. You can still issue the values for non-required parameters like this: @atomist add apache license file license=gpl Changing the branch and generated pull request If you want, you can alter the contents of the pull request by defining a transformPresentation on the code transform. export const AddApacheLicenseFile: CodeTransformRegistration<AddApacheLicenseFileParameters> = { transform: AddApacheLicenseFileTransform, paramsMaker: AddApacheLicenseFileParameters, name: \"add apache license file\", description: `Add Apache 2.0 license file`, intent: [\"add apache license file\", \"add license file\"], transformPresentation: () => new editModes.PullRequest(\"license-file\", \"Add license file\"), }; This will cause the transform to be run on the license-file branch and the resulting pull request have Add license file as a title. You can also specify the body of the pull request, and more. Check the docs on new PullRequest for more. If you don\u2019t want a pull request, you can specify that the transform should be applied as a commit to any branch. In local mode , there is no such thing as a pull request, so you\u2019ll see a branch in your repository. Defer pull request creation based on build outcome Atomist will automatically create a pull request when executing a code transform. However, the goal set execution can still fail. To mitigate unneeded unstable pull request creation, you can wrap your code transform registration in the makeBuildAware function. export const AddApacheLicenseFile : CodeTransformRegistration < AddApacheLicenseFileParameters > = makeBuildAware ({ transform : AddApacheLicenseFileTransform , paramsMaker : AddApacheLicenseFileParameters , name : \"add apache license file\" , description : `Add Apache 2.0 license file` , intent : [ \"add apache license file\" , \"add license file\" ], }); Enabling auto merge of pull request based on build outcome By default, you still need to manually merge the pull request. You can however configure code transforms to auto merge on a successful goalset execution. You can achieve this by pressing the Enable Auto Merge button that is shown in Slack in the pull request message. This will add a certain label ( auto-merge:on-check-success ) to the pull request, which indicates to Atomist that the pull request needs to be merged on a succesful goalset execution. You can also add that label manually in Github if you want to. Adding labels to Github If the labels are missing in Github, issue the @atomist add auto merge labels command in the channel linked to a repository Changing merge behavior of pull requests By default, Atomist will merge a pull request by adding the commits to the target branch using a merge commit. It is however also capable of using different merge strategies, like rebase or squash. In order to do this, you can add different labels to the pull request. The following labels are supported: auto-merge-method:merge : use a merge commit auto-merge-method:rebase : rebase the commits onto the target branch * auto-merge-method:squash : squash all the commits into a single commit In the event of a squash, the commit message of the new commit will be the title of the pull request. Adding labels to Github If the labels are missing in Github, issue the @atomist add auto merge labels command in the channel linked to a repository","title":"Transforms"},{"location":"developer/transform/#create-a-code-transform","text":"Code transforms are functions that receive the project as an input and changes the content of the project as a result. For a quick example, assume we want to add an Apache licence file to the project. The transform would retrieve the license content and add a LICENSE file with that content. export const AddApacheLicenseFileTransform : CodeTransform < NoParameters > = async ( p : Project ) => { const httpClient = DefaultHttpClientFactory . create (); const license = await httpClient . exchange ( \"https://www.apache.org/licenses/LICENSE-2.0.txt\" ); return p . addFile ( \"LICENSE\" , license . body as string ); }; When you want to do more in a code transform, you might want to: To add or remove files, you can use the Project interface (the API for modifying files in the project). To do basic operations (like a text replacement) on multiple files, check out projectUtils To change code based on a language\u2019s abstract syntax tree (AST), try astUtils To change code based on a more intuitive selection criteria, try the microgrammars in parseUtils . make HTTP calls in an SDM (if you\u2019re curious why that example uses DefaultHttpClientFactory)","title":"Create a code transform"},{"location":"developer/transform/#creating-a-command-for-a-transform","text":"A code transform can be called through various means. One of those means is directly through issuing a command. This command needs to be defined and the transform needs to be referenced in that definition. export const AddApacheLicenseFile : CodeTransformRegistration < NoParameters > = { transform : AddApacheLicenseFileTransform , name : \"add apache license file\" , description : `Add Apache 2.0 license file` , intent : [ \"add apache license file\" , \"add license file\" ], }; Each intent acts as an alias for invoking the command. The description is going to be the title of an automatic pull request. The transform\u2019s name will appear in the branch. See also: CodeTransformRegistration API doc","title":"Creating a command for a transform"},{"location":"developer/transform/#adding-the-transform-command-to-the-sdm","text":"Tell the SDM about the command. In order to achieve this you need to register the command with the SDM. In your SDM definition where you have access to the SDM instance, add the following registration: sdm . addCodeTransformCommand ( AddApacheLicenseFile );","title":"Adding the transform command to the SDM"},{"location":"developer/transform/#calling-the-command","text":"","title":"Calling the command"},{"location":"developer/transform/#local","text":"To test your command, run your SDM in local mode and then atomist start --local then, in a separate terminal, change directory to one of your repositories under your Atomist project root (usually $HOME/atomist). Then: atomist add apache license file Atomist will create a new branch with the changed code on it. List all your branches to find it: git branch","title":"Local"},{"location":"developer/transform/#team","text":"When you run your SDM in team mode , your command will be available in chat. Go to a channel associated with a repository , and talk to the Atomist bot: @atomist add apache license file Atomist will create a branch and apply the code transform on that branch. It will also create a pull request for the commits generated by that branch. By default, the name of the pull request will be the description of the code transform. If you want to run the transform against a branch other than the default branch, add targets.branch=other-branch-name to the command in chat. See also: Invoking commands","title":"Team"},{"location":"developer/transform/#adding-parameters-to-the-code-transform-command","text":"Sometimes you need additional input after issuing the command to transform a certain piece of code. Say that we wish to make the license file transformation a bit more flexible and allow of different types of licences. First we need to define the data structure that will hold the parameters. @Parameters () class AddApacheLicenseFileParameters { @Parameter ({ displayName : \"License type\" , validInput : \"apache20, gpl, lgpl\" , pattern : /(apache20|gpl|lgpl)/ , required : false , }) public license : \"apache20\" | \"gpl\" | \"lgpl\" = \"apache20\" ; } Next we need to make the transform aware of the new parameters and alter the internal logic in order to take those parameters into account. export const AddApacheLicenseFileTransform : CodeTransform < AddApacheLicenseFileParameters > = async ( p , params ) => { const licenses = { apache20 : \"https://www.apache.org/licenses/LICENSE-2.0.txt\" , gpl : \"https://www.gnu.org/licenses/gpl-2.0.txt\" , lgpl : \"https://www.gnu.org/licenses/lgpl-3.0.txt\" , }; const httpClient = DefaultHttpClientFactory . create (); const license = await httpClient . exchange ( licenses [ params . parameters . license ]); return p . addFile ( \"LICENSE\" , license . body as string ); }; Finally, we need to alter the command registration so that it recognizes the command parameters and prompt for their values if they are required. export const AddApacheLicenseFile : CodeTransformRegistration < AddApacheLicenseFileParameters > = { transform : AddApacheLicenseFileTransform , paramsMaker : AddApacheLicenseFileParameters , name : \"add apache license file\" , description : `Add Apache 2.0 license file` , intent : [ \"add apache license file\" , \"add license file\" ], }; When issuing the command, it will prompt for the parameters values that are required. You can still issue the values for non-required parameters like this: @atomist add apache license file license=gpl","title":"Adding parameters to the code transform command"},{"location":"developer/transform/#changing-the-branch-and-generated-pull-request","text":"If you want, you can alter the contents of the pull request by defining a transformPresentation on the code transform. export const AddApacheLicenseFile: CodeTransformRegistration<AddApacheLicenseFileParameters> = { transform: AddApacheLicenseFileTransform, paramsMaker: AddApacheLicenseFileParameters, name: \"add apache license file\", description: `Add Apache 2.0 license file`, intent: [\"add apache license file\", \"add license file\"], transformPresentation: () => new editModes.PullRequest(\"license-file\", \"Add license file\"), }; This will cause the transform to be run on the license-file branch and the resulting pull request have Add license file as a title. You can also specify the body of the pull request, and more. Check the docs on new PullRequest for more. If you don\u2019t want a pull request, you can specify that the transform should be applied as a commit to any branch. In local mode , there is no such thing as a pull request, so you\u2019ll see a branch in your repository.","title":"Changing the branch and generated pull request"},{"location":"developer/transform/#defer-pull-request-creation-based-on-build-outcome","text":"Atomist will automatically create a pull request when executing a code transform. However, the goal set execution can still fail. To mitigate unneeded unstable pull request creation, you can wrap your code transform registration in the makeBuildAware function. export const AddApacheLicenseFile : CodeTransformRegistration < AddApacheLicenseFileParameters > = makeBuildAware ({ transform : AddApacheLicenseFileTransform , paramsMaker : AddApacheLicenseFileParameters , name : \"add apache license file\" , description : `Add Apache 2.0 license file` , intent : [ \"add apache license file\" , \"add license file\" ], });","title":"Defer pull request creation based on build outcome"},{"location":"developer/transform/#enabling-auto-merge-of-pull-request-based-on-build-outcome","text":"By default, you still need to manually merge the pull request. You can however configure code transforms to auto merge on a successful goalset execution. You can achieve this by pressing the Enable Auto Merge button that is shown in Slack in the pull request message. This will add a certain label ( auto-merge:on-check-success ) to the pull request, which indicates to Atomist that the pull request needs to be merged on a succesful goalset execution. You can also add that label manually in Github if you want to. Adding labels to Github If the labels are missing in Github, issue the @atomist add auto merge labels command in the channel linked to a repository","title":"Enabling auto merge of pull request based on build outcome"},{"location":"developer/transform/#changing-merge-behavior-of-pull-requests","text":"By default, Atomist will merge a pull request by adding the commits to the target branch using a merge commit. It is however also capable of using different merge strategies, like rebase or squash. In order to do this, you can add different labels to the pull request. The following labels are supported: auto-merge-method:merge : use a merge commit auto-merge-method:rebase : rebase the commits onto the target branch * auto-merge-method:squash : squash all the commits into a single commit In the event of a squash, the commit message of the new commit will be the title of the pull request. Adding labels to Github If the labels are missing in Github, issue the @atomist add auto merge labels command in the channel linked to a repository","title":"Changing merge behavior of pull requests"},{"location":"developer/troubleshoot/","text":"This page contains a collection of troubleshooting techniques. SDM registration To answer questions like: Where is my SDM running? What version of my SDM is running? You can gather information in multiple ways: Check the web interface run the command: \u201cdescribe sdm your-sdms-name\u201d (If you aren\u2019t sure of the name, try \u201cdescribe sdm\u201d and check the help message.) run the command: \u201cshow skills\u201d Running SDM locally in team mode When you run an SDM locally with atomist start , you get to test your local version on real events. providing token If you see this error during goal or command execution: Error: Neither 'orgToken' nor 'clientToken' has been injected. Please add a repo-scoped GitHub token to your configuration. then add a token property at the top level in $HOME/.atomist/client.config.json containing your GitHub token. For example, mine is in an environment variable called GITHUB_TOKEN, so I added this: \"token\": \"${GITHUB_TOKEN}\", You need this because goal execution (for autofixes, for instance, which push commits) require GitHub authorization, and while in production your SDM gets the token from Atomist, by default Atomist does not send secrets like that to your locally-running SDM. Instead, provide your own GitHub token in configuration. Running SDM in local mode Basic diagnostics: When you run the SDM with atomist start --local , it will print that it has \u201c started in local mode \u201c. If you have atomist feed running in another terminal, then you\u2019ll see a message there when a local-mode SDM starts or stops. It looks something like: # general 2019-01-17 12:55:39 My Software Delivery Machine java-refactor-demo-sdm:0.1.0 is now connected . To see which SDMs are available to the command line, run atomist show sdms . To see the commands they supply, run atomist show skills . the CLI does not see my local SDM If your SDM does not show in atomist show sdms , perhaps it chose the wrong port. The command line looks for SDMs at ports 2866-2876. See the section on SDM logging for how to set log level to \u201cdebug\u201d. Then restart your SDM, and search its output for the log statement revealing the port where it listens: running at 'http://127.0.0.1:2866' (or similar). If yours is running on a port not in 2866-2876, you might have a PORT environment variable set. Try removing that or setting it to something in that range. The hostname defaults to 127.0.0.1, and can be overridden by a config value \"local\": { \"hostname\": \"your-local-hostname-goes-here\" } in either the configuration object in the SDM\u2019s index.ts or in your $HOME/atomist/client.config.json . atomist feed Lifecycle listener is already running If you type atomist feed and is says you have one already running, then something is listening on port 6660. When I get this, I go look in my other terminal windows for a running feed, and use that one or Ctrl-C out of it. If that doesn\u2019t work, I find out what process is on port 6660 and kill it. On Mac: lsof -i :6660 to find the process, then see its PID and pass that to kill .","title":"Troubleshooting"},{"location":"developer/troubleshoot/#sdm-registration","text":"To answer questions like: Where is my SDM running? What version of my SDM is running? You can gather information in multiple ways: Check the web interface run the command: \u201cdescribe sdm your-sdms-name\u201d (If you aren\u2019t sure of the name, try \u201cdescribe sdm\u201d and check the help message.) run the command: \u201cshow skills\u201d","title":"SDM registration"},{"location":"developer/troubleshoot/#running-sdm-locally-in-team-mode","text":"When you run an SDM locally with atomist start , you get to test your local version on real events.","title":"Running SDM locally in team mode"},{"location":"developer/troubleshoot/#providing-token","text":"If you see this error during goal or command execution: Error: Neither 'orgToken' nor 'clientToken' has been injected. Please add a repo-scoped GitHub token to your configuration. then add a token property at the top level in $HOME/.atomist/client.config.json containing your GitHub token. For example, mine is in an environment variable called GITHUB_TOKEN, so I added this: \"token\": \"${GITHUB_TOKEN}\", You need this because goal execution (for autofixes, for instance, which push commits) require GitHub authorization, and while in production your SDM gets the token from Atomist, by default Atomist does not send secrets like that to your locally-running SDM. Instead, provide your own GitHub token in configuration.","title":"providing token"},{"location":"developer/troubleshoot/#running-sdm-in-local-mode","text":"Basic diagnostics: When you run the SDM with atomist start --local , it will print that it has \u201c started in local mode \u201c. If you have atomist feed running in another terminal, then you\u2019ll see a message there when a local-mode SDM starts or stops. It looks something like: # general 2019-01-17 12:55:39 My Software Delivery Machine java-refactor-demo-sdm:0.1.0 is now connected . To see which SDMs are available to the command line, run atomist show sdms . To see the commands they supply, run atomist show skills .","title":"Running SDM in local mode"},{"location":"developer/troubleshoot/#the-cli-does-not-see-my-local-sdm","text":"If your SDM does not show in atomist show sdms , perhaps it chose the wrong port. The command line looks for SDMs at ports 2866-2876. See the section on SDM logging for how to set log level to \u201cdebug\u201d. Then restart your SDM, and search its output for the log statement revealing the port where it listens: running at 'http://127.0.0.1:2866' (or similar). If yours is running on a port not in 2866-2876, you might have a PORT environment variable set. Try removing that or setting it to something in that range. The hostname defaults to 127.0.0.1, and can be overridden by a config value \"local\": { \"hostname\": \"your-local-hostname-goes-here\" } in either the configuration object in the SDM\u2019s index.ts or in your $HOME/atomist/client.config.json .","title":"the CLI does not see my local SDM"},{"location":"developer/troubleshoot/#atomist-feed","text":"","title":"atomist feed"},{"location":"developer/troubleshoot/#lifecycle-listener-is-already-running","text":"If you type atomist feed and is says you have one already running, then something is listening on port 6660. When I get this, I go look in my other terminal windows for a running feed, and use that one or Ctrl-C out of it. If that doesn\u2019t work, I find out what process is on port 6660 and kill it. On Mac: lsof -i :6660 to find the process, then see its PID and pass that to kill .","title":"Lifecycle listener is already running"},{"location":"developer/typescript/","text":"TypeScript is a great language, but if you\u2019re coming from another language ecosystem, the toolchain can be confusing. Here are some of our learnings, in hopes they of use to you. We use: * for an editor or IDE, VSCode or IntelliJ * Mocha for unit tests * npm for dependencies and command-line utilities and running builds * tslint for finding some errors and formatting nitpicks VSCode We use VSCode , which is an excellent free IDE from Microsoft. It\u2019s highly configurable. By default it is set up to not surprise you much, so there are a lot of plugins to add and settings to configure. First thing to know: push Cmd-Shift-P (Mac, or Ctrl-Shift-P) and then type what you want to do. The \u201ccommand palette\u201d that comes up is searchable. This is useful for everything. For instance, Cmd-shift-P to open the command palette and type \u201ccommands\u201d and then choose the option for \u201cShell command: install \u2018code\u2019 command in PATH\u201d. From now on, you can type code . in a (bash-like) terminal to open the current directory in VSCode. VSCode Settings Open the settings with Cmd-, on Mac, or Cmd-shift-P and type \u201cSettings\u201d in the command palette. You can choose \u201cOpen Settings (JSON)\u201d to edit the JSON instead of a GUI. Note that there are user settings and workspace settings; the latter are local to the directory you have opened. User settings I always change: Autosave: set to onFocusChange; default is off. Format on save: I turn this on. exclude files: these are the files to not-show in the explorer. I set them to exclude anything in .git, all the TypeScript compilation output (any .js file that has a .ts or .tsx next to it; any .d.ts that has a .ts; and all .d.ts.map and .js.map files), and those darn .DS_Store files that Apple creates: \"files.exclude\" : { \"**/.git\" : true , \"**/*.js\" : { \"when\" : \"$(basename).ts\" }, \"**/**.js\" : { \"when\" : \"$(basename).tsx\" }, \"**/*.d.ts\" : { \"when\" : \"$(basename).ts\" }, \"**/*.d.ts.map\" : true , \"**/*.js.map\" : true , \"**/.DS_Store\" : true } I like the window title to show the whole path to the file, not just its name. \"window.title\": \"${rootName}${separator}${activeEditorMedium}\" Remember more lines the terminal log (useful while debugging): \"terminal.integrated.scrollback\": 10000 VSCode Plugins TSLint: I like to set \"tslint.alwaysShowRuleFailuresAsWarnings\": true so that tslint errors show in green, while real compile errors show in red. Mocha Sidebar: it is not spectacular with TypeScript. I can\u2019t get it to run tests in a way that shows me the output. I have in my settings: \"mocha.options\" : { \"compilers\" : { \"ts\" : \"ts-node/register\" } } , \"mocha.coverage\" : { \"enable\" : false , } , \"mocha.requires\" : [ \"ts-node/register\" , ] , \"mocha.files.glob\" : \"test/**/*.test.ts\" , Debugging For debugging a running SDM, check the SDM Debugging page. For debugging tests, this post is super useful. In particular, I use this launch configuration in the debugger: { \"type\" : \"node\" , \"request\" : \"launch\" , \"name\" : \"Mocha All\" , \"program\" : \"${workspaceFolder}/node_modules/mocha/bin/_mocha\" , \"args\" : [ \"-r\" , \"ts-node/register\" , \"--timeout\" , \"999999\" , \"--colors\" , \"${workspaceFolder}/test/**/*.test.ts\" , ], \"console\" : \"integratedTerminal\" , \"internalConsoleOptions\" : \"neverOpen\" , \"protocol\" : \"inspector\" } When I want to debug a particular test, I change *.test.ts to the name of my test file, and then launch it. Not ideal, but it works. IntelliJ Also called WebStorm, many of us who also work on Java use IntelliJ Ultimate for TypeScript development. It is generally better at refactoring than VSCode. It also works better for running individual tests or test suites. Mocha Mocha is a JavaScript testing framework that can work for TypeScript too. To run Mocha on TypeScript tests, you need to pass it an argument that lets it compile TypeScript on the fly. If you like extra detailed failure messages that give you a breakdown of the discrepancy between actual and expected output, use espower: mocha --require espower-typescript/guess path/to/test/files/* If you don\u2019t like the espower magic, you can --require ts-node/register instead, which does TS compilation but nothing else fancy. Something to watch out for: Sometimes it runs the tests on old code. The mocha command won\u2019t necessarily compile .ts when it finds a .js file next to it, and VSCode doesn\u2019t automatically compile .ts files on save. When in doubt, do an explicit compile before running tests. Contributions Please share your questions, frustrations, etc. in the #typescript channel in Atomist community slack ;","title":"TypeScript Hints"},{"location":"developer/typescript/#vscode","text":"We use VSCode , which is an excellent free IDE from Microsoft. It\u2019s highly configurable. By default it is set up to not surprise you much, so there are a lot of plugins to add and settings to configure. First thing to know: push Cmd-Shift-P (Mac, or Ctrl-Shift-P) and then type what you want to do. The \u201ccommand palette\u201d that comes up is searchable. This is useful for everything. For instance, Cmd-shift-P to open the command palette and type \u201ccommands\u201d and then choose the option for \u201cShell command: install \u2018code\u2019 command in PATH\u201d. From now on, you can type code . in a (bash-like) terminal to open the current directory in VSCode.","title":"VSCode"},{"location":"developer/typescript/#vscode-settings","text":"Open the settings with Cmd-, on Mac, or Cmd-shift-P and type \u201cSettings\u201d in the command palette. You can choose \u201cOpen Settings (JSON)\u201d to edit the JSON instead of a GUI. Note that there are user settings and workspace settings; the latter are local to the directory you have opened. User settings I always change: Autosave: set to onFocusChange; default is off. Format on save: I turn this on. exclude files: these are the files to not-show in the explorer. I set them to exclude anything in .git, all the TypeScript compilation output (any .js file that has a .ts or .tsx next to it; any .d.ts that has a .ts; and all .d.ts.map and .js.map files), and those darn .DS_Store files that Apple creates: \"files.exclude\" : { \"**/.git\" : true , \"**/*.js\" : { \"when\" : \"$(basename).ts\" }, \"**/**.js\" : { \"when\" : \"$(basename).tsx\" }, \"**/*.d.ts\" : { \"when\" : \"$(basename).ts\" }, \"**/*.d.ts.map\" : true , \"**/*.js.map\" : true , \"**/.DS_Store\" : true } I like the window title to show the whole path to the file, not just its name. \"window.title\": \"${rootName}${separator}${activeEditorMedium}\" Remember more lines the terminal log (useful while debugging): \"terminal.integrated.scrollback\": 10000","title":"VSCode Settings"},{"location":"developer/typescript/#vscode-plugins","text":"TSLint: I like to set \"tslint.alwaysShowRuleFailuresAsWarnings\": true so that tslint errors show in green, while real compile errors show in red. Mocha Sidebar: it is not spectacular with TypeScript. I can\u2019t get it to run tests in a way that shows me the output. I have in my settings: \"mocha.options\" : { \"compilers\" : { \"ts\" : \"ts-node/register\" } } , \"mocha.coverage\" : { \"enable\" : false , } , \"mocha.requires\" : [ \"ts-node/register\" , ] , \"mocha.files.glob\" : \"test/**/*.test.ts\" ,","title":"VSCode Plugins"},{"location":"developer/typescript/#debugging","text":"For debugging a running SDM, check the SDM Debugging page. For debugging tests, this post is super useful. In particular, I use this launch configuration in the debugger: { \"type\" : \"node\" , \"request\" : \"launch\" , \"name\" : \"Mocha All\" , \"program\" : \"${workspaceFolder}/node_modules/mocha/bin/_mocha\" , \"args\" : [ \"-r\" , \"ts-node/register\" , \"--timeout\" , \"999999\" , \"--colors\" , \"${workspaceFolder}/test/**/*.test.ts\" , ], \"console\" : \"integratedTerminal\" , \"internalConsoleOptions\" : \"neverOpen\" , \"protocol\" : \"inspector\" } When I want to debug a particular test, I change *.test.ts to the name of my test file, and then launch it. Not ideal, but it works.","title":"Debugging"},{"location":"developer/typescript/#intellij","text":"Also called WebStorm, many of us who also work on Java use IntelliJ Ultimate for TypeScript development. It is generally better at refactoring than VSCode. It also works better for running individual tests or test suites.","title":"IntelliJ"},{"location":"developer/typescript/#mocha","text":"Mocha is a JavaScript testing framework that can work for TypeScript too. To run Mocha on TypeScript tests, you need to pass it an argument that lets it compile TypeScript on the fly. If you like extra detailed failure messages that give you a breakdown of the discrepancy between actual and expected output, use espower: mocha --require espower-typescript/guess path/to/test/files/* If you don\u2019t like the espower magic, you can --require ts-node/register instead, which does TS compilation but nothing else fancy. Something to watch out for: Sometimes it runs the tests on old code. The mocha command won\u2019t necessarily compile .ts when it finds a .js file next to it, and VSCode doesn\u2019t automatically compile .ts files on save. When in doubt, do an explicit compile before running tests.","title":"Mocha"},{"location":"developer/typescript/#contributions","text":"Please share your questions, frustrations, etc. in the #typescript channel in Atomist community slack ;","title":"Contributions"},{"location":"pack/","text":"Extension packs bring ready-made integrations for your Atomist SDM. They are libraries; bring them in with npm install . Create your own with atomist create extension pack . Each pack has its own set of functionality, so check the page for each one for details.","title":"Extension Packs"},{"location":"pack/build/","text":"The most important parts of this pack are documented in the Developer Guide . If you want more information on how to build Java projects, check the Spring pack documentation. You can also see the full API Doc .","title":"Build"},{"location":"pack/changelog/","text":"This pack provides automations for keeping CHANGELOG.md up-to-date. GitHub API Doc Using","title":"Changelog"},{"location":"pack/changelog/#using","text":"","title":"Using"},{"location":"pack/checkstyle/","text":"This extension pack integrates with Checkstyle , which does static analysis on Java code. GitHub API Doc","title":"Checkstyle"},{"location":"pack/docker/","text":"This pack contains useful integrations with Docker . GitHub API Doc Building a Docker image Atomist has support for building a Docker image. You need to add the following goal to your SDM definition: const dockerBuild = new DockerBuild (). with ({ options : { push : false }, }) And plan this goal in your SDM: sdm . withPushRules ( whenPushSatisfies ( HasDockerfile ). setGoals ( dockerBuild )) Registratation parameters The DockerBuild goal can accept the following parameters in the goal registration: options push : whether a docker push needs to be performed registry : whether a specific registry need to be used user : the username when pushing to a registry password : the password when pushing to a registry dockerfileFinder : a function that determines where to find the Dockerfile . By default it expects the file to be in the root of the project imageNameCreator : define a custom image name creator (see DockerImageNameCreator ) to determine the name of the resulting Docker image Triggering application build steps before a Docker build A lot of times, before doing a Docker build, you need to perform a couple of actions in your codebase. Every goal in Atomist starts off from a clean codebase, so for example compiled sourcecode from a previous run of the Build goal is not known to the DockerBuild goal. When using the sdm-pack-spring a couple of goal hooks, which trigger code before the execution of a goal, have been built with this functionality in mind. const dockerBuild = new DockerBuild (). with ({ options : { push : false }, }) . withProjectListener ( MvnVersion ) . withProjectListener ( MvnPackage ); These listeners will: Perform an mvn version:set . The version will be derived from a previous Version goal run result. Perform an mvn package which will compile the code and build a JAR file that you can use in your docker file For NodeJS application, you can create your own listener that calls for example an NPM task.","title":"Docker"},{"location":"pack/docker/#building-a-docker-image","text":"Atomist has support for building a Docker image. You need to add the following goal to your SDM definition: const dockerBuild = new DockerBuild (). with ({ options : { push : false }, }) And plan this goal in your SDM: sdm . withPushRules ( whenPushSatisfies ( HasDockerfile ). setGoals ( dockerBuild ))","title":"Building a Docker image"},{"location":"pack/docker/#registratation-parameters","text":"The DockerBuild goal can accept the following parameters in the goal registration: options push : whether a docker push needs to be performed registry : whether a specific registry need to be used user : the username when pushing to a registry password : the password when pushing to a registry dockerfileFinder : a function that determines where to find the Dockerfile . By default it expects the file to be in the root of the project imageNameCreator : define a custom image name creator (see DockerImageNameCreator ) to determine the name of the resulting Docker image","title":"Registratation parameters"},{"location":"pack/docker/#triggering-application-build-steps-before-a-docker-build","text":"A lot of times, before doing a Docker build, you need to perform a couple of actions in your codebase. Every goal in Atomist starts off from a clean codebase, so for example compiled sourcecode from a previous run of the Build goal is not known to the DockerBuild goal. When using the sdm-pack-spring a couple of goal hooks, which trigger code before the execution of a goal, have been built with this functionality in mind. const dockerBuild = new DockerBuild (). with ({ options : { push : false }, }) . withProjectListener ( MvnVersion ) . withProjectListener ( MvnPackage ); These listeners will: Perform an mvn version:set . The version will be derived from a previous Version goal run result. Perform an mvn package which will compile the code and build a JAR file that you can use in your docker file For NodeJS application, you can create your own listener that calls for example an NPM task.","title":"Triggering application build steps before a Docker build"},{"location":"pack/issue/","text":"This pack contains useful automations around GitHub Issues. GitHub API Doc Code Inspection Listener When a code inspection fails, you might want it to create an issue on the repository. This pack has a code inspection listener for this. Call singleIssuePerCategoryManaging to get a listener, and register it on your code inspection goal. For instance: autoCodeInspection . with ( RunTslint ) . withListener ( singleIssuePerCategoryManaging ( \"tslint\" ) Here, the RunTsLint inspection will create ReviewComments with a category of \u201ctslint\u201d. Then the singleIssuePerCategory inspection listener will create, maintain, and close one issue per branch on the repository, according to the latest results from that inspection. By default this listener will assign the issue to the person who pushed the change that triggered inspection comments, and will only create an issue for the master branch. You can pass arguments to change this; see the API docs for details.","title":"Issue"},{"location":"pack/issue/#code-inspection-listener","text":"When a code inspection fails, you might want it to create an issue on the repository. This pack has a code inspection listener for this. Call singleIssuePerCategoryManaging to get a listener, and register it on your code inspection goal. For instance: autoCodeInspection . with ( RunTslint ) . withListener ( singleIssuePerCategoryManaging ( \"tslint\" ) Here, the RunTsLint inspection will create ReviewComments with a category of \u201ctslint\u201d. Then the singleIssuePerCategory inspection listener will create, maintain, and close one issue per branch on the repository, according to the latest results from that inspection. By default this listener will assign the issue to the person who pushed the change that triggered inspection comments, and will only create an issue for the master branch. You can pass arguments to change this; see the API docs for details.","title":"Code Inspection Listener"},{"location":"pack/kubernetes/","text":"Atomist provides the easiest and most flexible way to get from ideas and customer requests to a solution deployed in Kubernetes . Once deployed, Atomist provides feedback on the health of running applications and uses standard Kubernetes mechanism for zero-downtime deployments. Overview Before getting started, it is helpful to provide some information about how Atomist interacts with Kubernetes. Atomist is able to deploy and update applications to Kubernetes as well as report back on the health of those applications, providing feedback in the Atomist web interface or Slack on deployments running containers across clusters and namespaces in the concise, correlated manner users of Atomist expect. This integration has three parts: the SDM extension pack , a process for executing deploys and a process for transmitting events . SDM Extension Pack The extension pack ( github , [API doc]) adds functions to your SDM for deploying to Kubernetes. apidoc Deploying and updating applications The Atomist k8-automation utility manages deploying and updating applications. It is able to create deployments to manage the runtime of the application container, services to provide standard Kubernetes discovery capabilities, and ingresses to provide the properly hosted and secured external access to services. The k8-automation utility runs inside each Kubernetes cluster you want to deploy applications to, using a Kubernetes service account with only the permissions needed to create, read, update, and delete namespaces, deployments, services, and ingresses. Container status The Atomist k8vent utility watches pods in your Kubernetes cluster and sends change events, e.g., container started and container crashed, back to Atomist. Like k8-automation, the k8vent utility runs inside each Kubernetes cluster you want events from, using a Kubernetes service account with only the permissions needed to watch pod events. Role-Based Access Control (RBAC) To perform their tasks, the Atomist utilities running within a Kubernetes cluster need access to do so. In modern, i.e., version 1.6 or greater, Kubernetes clusters, this access is provided using role-based access control (RBAC) . Briefly, a service account is created and bound to roles with the appropriate privileges. The pod is then configured to use the service account when accessing the Kubernetes API using the in-cluster client. Part of deploying the Atomist utilities to your Kubernetes cluster is creating the needed RBAC resources. To create RBAC resources, your Kubernetes user needs admin privileges. If your Kubernetes user does not have admin privileges in the cluster or a namespace, someone whose Kuberetes user has those privileges will need to deploy the Atomist utilities. If you see errors like the following when you try to deploy the Atomist utilities to your Kubernetes cluster, Error from server (Forbidden): error when creating \"rbac.yaml\": clusterroles.rbac.authorization.k8s.io \"k8-automation-clusterrole\" is forbidden: attempt to grant extra privileges: [...] user=&{YOUR_USER [system:authenticated] map[]} ownerrules=[PolicyRule{Resources:[\"selfsubjectaccessreviews\"], APIGroups:[\"authorization.k8s.io\"], Verbs:[\"create\"]} PolicyRule{NonResourceURLs:[\"/api\" \"/api/*\" \"/apis\" \"/apis/*\" \"/healthz\" \"/swagger-2.0.0.pb-v1\" \"/swagger.json\" \"/swaggerapi\" \"/swaggerapi/*\" \"/version\"], Verbs:[\"get\"]}] ruleResolutionErrors=[] then your Kubernetes user does not have administrative privileges on your cluster/namespace. You will either need to ask someone who has admin privileges on the cluster/namespace to create the RBAC resources or try to escalate your privileges in the cluster/namespace. In the following commands, replace USER with your Kubernetes user name. To attempt to provide your Kubernetes user with cluster admin privileges, run: kubectl create clusterrolebinding USER-cluster-admin-binding \\ --clusterrole=cluster-admin --user=USER To attempt to provide your Kubernetes user with namespace admin privileges, run: kubectl create --namespace=NAMESPACE rolebinding USER-admin-binding \\ --clusterrole=admin --user=USER Then run the command to deploy the Atomist utilities again. GKE and RBAC By default, the user you authenticate with a GKE cluster does not have sufficient permissions to install the Atomist Kubernetes utilities. To grant your user the necessary permissions, run the cluster-wide command above replacing USER in the commands above with $(gcloud config get-value account) : kubectl create clusterrolebinding \\ $(gcloud config get-value account)-cluster-admin-binding \\ --clusterrole=cluster-admin --user=$(gcloud config get-value account) If you see errors like the following when you try to deploy the Atomist utilities to your Kubernetes cluster, unable to decode \"https://raw.githubusercontent.com/atomist/k8vent/master/kube/kubectl/cluster-wide.yaml\": no kind \"ClusterRole\" is registered for version \"rbac.authorization.k8s.io/v1beta1\" unable to decode \"https://raw.githubusercontent.com/atomist/k8vent/master/kube/kubectl/cluster-wide.yaml\": no kind \"ClusterRoleBinding\" is registered for version \"rbac.authorization.k8s.io/v1beta1\" then either your kubectl CLI, Kubernetes cluster, or both are too old and do not support RBAC. Upgrade your kubectl CLI and Kubernetes cluster or contact us for help in deploying the Atomist utilities. Cluster vs. namespace The Atomist utilities can run in two modes: cluster wide and namespace scoped. If your Kubernetes user has cluster-admin role access, which is typically the case if you created the cluster, you can and probably should deploy Atomist utilities in cluster-wide mode. This allows these utilities to manage and report on applications across all namespaces in your cluster. If you are limited to managing Kubernetes resources in a single namespace and your user has admin role access to that namespace, you should probably install in namespace-scoped mode. If your Kubernetes user has neither cluster-admin or admin role access, you will need to ask someone who does to install the Atomist utilities in your cluster. If you want the Atomist Kubernetes utilities to report on and manage resources in several but not all namespaces, you can deploy the Atomist utilities using namespace-scoped mode multiple times, one time for each namespace you want reported on and managed. Cluster environment The Atomist Kubernetes utilities use the concept of a cluster environment . While the cluster environment is an arbitrary description of the Kubernetes cluster to which you are deploying the Atomist Kubernetes utilities, it is used to link application deployment requests and cluster activity to the other activity in your development flow. Therefore it should be meaningful to you and your team and unique across your organization\u2019s Kubernetes clusters. Examples of good cluster environments are \u201cproduction\u201d, \u201cend-user\u201d, \u201cuat\u201d, \u201cstaging\u201d, etc. The cluster environment you provide when installing the Atomist Kubernetes utilities will be used when reporting on Kubernetes pod container activity in development lifecycle messages. For example, the following image shows the containers that are running a specific Docker image from a specific commit and build in various namespaces in the Kubernetes cluster environment \u201cgke-int-demo\u201d. The cluster environment is used by k8-automation and your software delivery machine (SDM) to coordinate application deployments and upgrades. Since you may be deploying k8-automation to multiple Kubernetes clusters, the cluster environment is used as part of the application deployment/update request to select the Kubernetes cluster. Prerequisites Before you connect Atomist and your Kubernetes cluster(s), you need a few prerequisites. Atomist workspace You must have an Atomist workspace. If you do not already have one, you can create one following the instructions in the getting started documentation . Kubernetes cluster You must have a Kubernetes cluster and access to that cluster as a user with either cluster-admin role privileges to run in cluster-wide mode or admin role privileges within a namespace to run in namespace-scoped mode. If you do not have access to a Kubernetes cluster, you can create one on your local system using minikube . Installation Several different methods for installing the Atomist Kubernetes utilities are supported. Choose the one that makes sense for your situation. If you aren\u2019t sure how to proceed, try the Atomist CLI approach as it is the easiest. Atomist CLI To use the Atomist CLI to install the Atomist Kubernetes utilities, you must have the Atomist CLI installed and configured . You will also need the Kubernetes kubectl command-line utility installed and configured to access your Kubernetes cluster with the needed privileges. Once you have the Atomist and Kubernetes CLIs installed and configured, you can install the Atomist Kubernetes utilities one the following commands. Be sure to replace CLUSTER_ENV with a meaningful name for you Kubernetes cluster/namespace and, if deploying in namespace-scoped mode, NAMESPACE with the existing namespace you want to deploy the utilities to. Cluster-wide mode To install the Atomist Kubernetes utilities in cluster-wide mode, able to report on and manage resources in all namespaces, run the following command. atomist kube --environment=\"CLUSTER_ENV\" Namespace-scoped mode To install the Atomist Kubernetes utilities in namespace-scoped mode, run the following command for each namespace you want to deploy them to. Replace NAMESPACE with the namespace you want to deploy the utilities to. atomist kube --namespace=\"NAMESPACE\" --environment=\"CLUSTER_ENV\" Kubernetes CLI If you have the kubectl command-line utility installed and configured to access your Kubernetes cluster with the needed privileges, you can install the needed Atomist utilities with the proper configuration using the following commands. Be sure to replace CLUSTER_ENV with a meaningful name for you Kubernetes cluster/namespace, WORKSPACE_ID with your Atomist workspace ID, and API_KEY with a valid Atomist API key. See the developer prerequisites for more information on Atomist workspace IDs and API keys. Cluster-wide mode k8vent To deploy k8vent in cluster-wide mode and have it report on changes to all pod containers, run the following command. kubectl apply --filename=https://raw.githubusercontent.com/atomist/k8vent/master/kube/kubectl/cluster-wide.yaml kubectl create secret --namespace=k8vent generic k8vent --from-literal=environment=\"CLUSTER_ENV\" \\ --from-literal=webhooks=\"https://webhook.atomist.com/atomist/kube/teams/WORKSPACE_ID\" k8-automation To deploy k8-automation in cluster-wide mode with the ability to manage applications in all namespaces, run the following command. kubectl apply --filename=https://raw.githubusercontent.com/atomist/k8-automation/master/assets/kubectl/cluster-wide.yaml kubectl create secret --namespace=k8-automation generic automation \\ --from-literal=config=\"{\\\"workspaceIds\\\":[\\\"WORKSPACE_ID\\\"],\\\"apiKey\\\":\\\"API_KEY\\\",\\\"environment\\\":\\\"CLUSTER_ENV\\\"}\" Namespace-scoped mode In the commands below, replace NAMESPACE with the namespace you want to deploy the utilities to. k8vent To deploy k8vent in namespace-scoped mode such that it will only report on pod containers in a single namespace, run the following commands. kubectl create secret --namespace=\"NAMESPACE\" generic k8vent \\ --from-literal=environment=\"CLUSTER_ENV\" \\ --from-literal=webhooks=\"https://webhook.atomist.com/atomist/kube/teams/WORKSPACE_ID\" kubectl apply --namespace=\"NAMESPACE\" \\ --filename=https://raw.githubusercontent.com/atomist/k8vent/master/kube/kubectl/namespace-scoped.yaml k8-automation To deploy k8-automation in namespace-scoped mode such that it will only deploy and update resources in a single Kubernetes cluster namespace, run the following commands. kubectl create secret --namespace=\"NAMESPACE\" generic automation \\ --from-literal=config=\"{\\\"workspaceIds\\\":[\\\"WORKSPACE_ID\\\"],\\\"apiKey\\\":\\\"API_KEY\\\",\\\"environment\\\":\\\"CLUSTER_ENV\\\",\\\"kubernetes\\\":{\\\"mode\\\":\\\"namespace\\\"}}\" kubectl apply --namespace=\"NAMESPACE\" \\ --filename=https://raw.githubusercontent.com/atomist/k8-automation/master/assets/kubectl/namespace-scoped.yaml Helm If you manage resources in your Kubernetes cluster with Helm , you can install the Atomist Kubernetes utilities using Helm. Replace API_KEY with an Atomist API key, WORKSPACE_ID with your Atomist workspace ID, and CLUSTER_ENV with a meaningful name for your Kubernetes cluster/namespace. Helm and Minikube Due to a bug in the default minikube bootstrapper localkube, kubernetes/helm#3135: Helm 2.7.0 creates RBAC resource fail , if you want to manage RBAC resources using Helm in minikube, you must start minikube using the kubeadm bootstrapper. minikube start --bootstrapper kubeadm You can make kubeadm your default bootstrapper by running the following command. minikube config set bootstrapper kubeadm Cluster-wide mode To install all of the Atomist Kubernetes utilities in cluster-wide mode, run the following helm command. helm upgrade --install --namespace=atomist atomist-utilities \\ --repo=https://atomist.github.io/helm-charts atomist-utilities \\ --set=global.atomist.apiKey=\"API_KEY\" \\ --set=global.atomist.workspaceIds=\"{WORKSPACE_ID}\" \\ --set=global.atomist.environment=\"CLUSTER_ENV\" Namespace-scoped mode To install all of the Atomist Kubernetes utilities in namespace-scoped mode, run the following helm command for each namespace you want to deploy them to. Replace NAMESPACE with the namespace you want to deploy the utilities to. helm upgrade --install --namespace=\"NAMESPACE\" \"atomist-utilities-NAMESPACE\" \\ --repo=https://atomist.github.io/helm-charts atomist-utilities \\ --set=global.atomist.apiKey=\"API_KEY\" \\ --set=global.atomist.workspaceIds=\"{WORKSPACE_ID}\" \\ --set=global.atomist.environment=\"CLUSTER_ENV\" \\ --set=global.atomist.mode=namespace Updating You can update to a new version of the Atomist Kubernetes utilities using standard Kubernetes approaches. If you installed the Atomist utilities using the Atomist CLI or Helm, simply re-run the same command you ran to install them. If you are using kubectl you can run the following commands, replacing NAMESPACE and M.N.P as appropriate. kubectl set image --namespace=NAMESPACE \\ deployment/k8vent k8vent=atomist/k8vent:M.N.P kubectl set image --namespace=NAMESPACE \\ deployment/k8-automation k8-automation=atomist/k8-automation:M.N.P You can always find the latest versions of k8-automation and k8vent on their release pages.","title":"Kubernetes"},{"location":"pack/kubernetes/#overview","text":"Before getting started, it is helpful to provide some information about how Atomist interacts with Kubernetes. Atomist is able to deploy and update applications to Kubernetes as well as report back on the health of those applications, providing feedback in the Atomist web interface or Slack on deployments running containers across clusters and namespaces in the concise, correlated manner users of Atomist expect. This integration has three parts: the SDM extension pack , a process for executing deploys and a process for transmitting events .","title":"Overview"},{"location":"pack/kubernetes/#sdm-extension-pack","text":"The extension pack ( github , [API doc]) adds functions to your SDM for deploying to Kubernetes. apidoc","title":"SDM Extension Pack"},{"location":"pack/kubernetes/#deploying-and-updating-applications","text":"The Atomist k8-automation utility manages deploying and updating applications. It is able to create deployments to manage the runtime of the application container, services to provide standard Kubernetes discovery capabilities, and ingresses to provide the properly hosted and secured external access to services. The k8-automation utility runs inside each Kubernetes cluster you want to deploy applications to, using a Kubernetes service account with only the permissions needed to create, read, update, and delete namespaces, deployments, services, and ingresses.","title":"Deploying and updating applications"},{"location":"pack/kubernetes/#container-status","text":"The Atomist k8vent utility watches pods in your Kubernetes cluster and sends change events, e.g., container started and container crashed, back to Atomist. Like k8-automation, the k8vent utility runs inside each Kubernetes cluster you want events from, using a Kubernetes service account with only the permissions needed to watch pod events.","title":"Container status"},{"location":"pack/kubernetes/#role-based-access-control-rbac","text":"To perform their tasks, the Atomist utilities running within a Kubernetes cluster need access to do so. In modern, i.e., version 1.6 or greater, Kubernetes clusters, this access is provided using role-based access control (RBAC) . Briefly, a service account is created and bound to roles with the appropriate privileges. The pod is then configured to use the service account when accessing the Kubernetes API using the in-cluster client. Part of deploying the Atomist utilities to your Kubernetes cluster is creating the needed RBAC resources. To create RBAC resources, your Kubernetes user needs admin privileges. If your Kubernetes user does not have admin privileges in the cluster or a namespace, someone whose Kuberetes user has those privileges will need to deploy the Atomist utilities. If you see errors like the following when you try to deploy the Atomist utilities to your Kubernetes cluster, Error from server (Forbidden): error when creating \"rbac.yaml\": clusterroles.rbac.authorization.k8s.io \"k8-automation-clusterrole\" is forbidden: attempt to grant extra privileges: [...] user=&{YOUR_USER [system:authenticated] map[]} ownerrules=[PolicyRule{Resources:[\"selfsubjectaccessreviews\"], APIGroups:[\"authorization.k8s.io\"], Verbs:[\"create\"]} PolicyRule{NonResourceURLs:[\"/api\" \"/api/*\" \"/apis\" \"/apis/*\" \"/healthz\" \"/swagger-2.0.0.pb-v1\" \"/swagger.json\" \"/swaggerapi\" \"/swaggerapi/*\" \"/version\"], Verbs:[\"get\"]}] ruleResolutionErrors=[] then your Kubernetes user does not have administrative privileges on your cluster/namespace. You will either need to ask someone who has admin privileges on the cluster/namespace to create the RBAC resources or try to escalate your privileges in the cluster/namespace. In the following commands, replace USER with your Kubernetes user name. To attempt to provide your Kubernetes user with cluster admin privileges, run: kubectl create clusterrolebinding USER-cluster-admin-binding \\ --clusterrole=cluster-admin --user=USER To attempt to provide your Kubernetes user with namespace admin privileges, run: kubectl create --namespace=NAMESPACE rolebinding USER-admin-binding \\ --clusterrole=admin --user=USER Then run the command to deploy the Atomist utilities again. GKE and RBAC By default, the user you authenticate with a GKE cluster does not have sufficient permissions to install the Atomist Kubernetes utilities. To grant your user the necessary permissions, run the cluster-wide command above replacing USER in the commands above with $(gcloud config get-value account) : kubectl create clusterrolebinding \\ $(gcloud config get-value account)-cluster-admin-binding \\ --clusterrole=cluster-admin --user=$(gcloud config get-value account) If you see errors like the following when you try to deploy the Atomist utilities to your Kubernetes cluster, unable to decode \"https://raw.githubusercontent.com/atomist/k8vent/master/kube/kubectl/cluster-wide.yaml\": no kind \"ClusterRole\" is registered for version \"rbac.authorization.k8s.io/v1beta1\" unable to decode \"https://raw.githubusercontent.com/atomist/k8vent/master/kube/kubectl/cluster-wide.yaml\": no kind \"ClusterRoleBinding\" is registered for version \"rbac.authorization.k8s.io/v1beta1\" then either your kubectl CLI, Kubernetes cluster, or both are too old and do not support RBAC. Upgrade your kubectl CLI and Kubernetes cluster or contact us for help in deploying the Atomist utilities.","title":"Role-Based Access Control (RBAC)"},{"location":"pack/kubernetes/#cluster-vs-namespace","text":"The Atomist utilities can run in two modes: cluster wide and namespace scoped. If your Kubernetes user has cluster-admin role access, which is typically the case if you created the cluster, you can and probably should deploy Atomist utilities in cluster-wide mode. This allows these utilities to manage and report on applications across all namespaces in your cluster. If you are limited to managing Kubernetes resources in a single namespace and your user has admin role access to that namespace, you should probably install in namespace-scoped mode. If your Kubernetes user has neither cluster-admin or admin role access, you will need to ask someone who does to install the Atomist utilities in your cluster. If you want the Atomist Kubernetes utilities to report on and manage resources in several but not all namespaces, you can deploy the Atomist utilities using namespace-scoped mode multiple times, one time for each namespace you want reported on and managed.","title":"Cluster vs. namespace"},{"location":"pack/kubernetes/#cluster-environment","text":"The Atomist Kubernetes utilities use the concept of a cluster environment . While the cluster environment is an arbitrary description of the Kubernetes cluster to which you are deploying the Atomist Kubernetes utilities, it is used to link application deployment requests and cluster activity to the other activity in your development flow. Therefore it should be meaningful to you and your team and unique across your organization\u2019s Kubernetes clusters. Examples of good cluster environments are \u201cproduction\u201d, \u201cend-user\u201d, \u201cuat\u201d, \u201cstaging\u201d, etc. The cluster environment you provide when installing the Atomist Kubernetes utilities will be used when reporting on Kubernetes pod container activity in development lifecycle messages. For example, the following image shows the containers that are running a specific Docker image from a specific commit and build in various namespaces in the Kubernetes cluster environment \u201cgke-int-demo\u201d. The cluster environment is used by k8-automation and your software delivery machine (SDM) to coordinate application deployments and upgrades. Since you may be deploying k8-automation to multiple Kubernetes clusters, the cluster environment is used as part of the application deployment/update request to select the Kubernetes cluster.","title":"Cluster environment"},{"location":"pack/kubernetes/#prerequisites","text":"Before you connect Atomist and your Kubernetes cluster(s), you need a few prerequisites.","title":"Prerequisites"},{"location":"pack/kubernetes/#atomist-workspace","text":"You must have an Atomist workspace. If you do not already have one, you can create one following the instructions in the getting started documentation .","title":"Atomist workspace"},{"location":"pack/kubernetes/#kubernetes-cluster","text":"You must have a Kubernetes cluster and access to that cluster as a user with either cluster-admin role privileges to run in cluster-wide mode or admin role privileges within a namespace to run in namespace-scoped mode. If you do not have access to a Kubernetes cluster, you can create one on your local system using minikube .","title":"Kubernetes cluster"},{"location":"pack/kubernetes/#installation","text":"Several different methods for installing the Atomist Kubernetes utilities are supported. Choose the one that makes sense for your situation. If you aren\u2019t sure how to proceed, try the Atomist CLI approach as it is the easiest.","title":"Installation"},{"location":"pack/kubernetes/#atomist-cli","text":"To use the Atomist CLI to install the Atomist Kubernetes utilities, you must have the Atomist CLI installed and configured . You will also need the Kubernetes kubectl command-line utility installed and configured to access your Kubernetes cluster with the needed privileges. Once you have the Atomist and Kubernetes CLIs installed and configured, you can install the Atomist Kubernetes utilities one the following commands. Be sure to replace CLUSTER_ENV with a meaningful name for you Kubernetes cluster/namespace and, if deploying in namespace-scoped mode, NAMESPACE with the existing namespace you want to deploy the utilities to.","title":"Atomist CLI"},{"location":"pack/kubernetes/#cluster-wide-mode","text":"To install the Atomist Kubernetes utilities in cluster-wide mode, able to report on and manage resources in all namespaces, run the following command. atomist kube --environment=\"CLUSTER_ENV\"","title":"Cluster-wide mode"},{"location":"pack/kubernetes/#namespace-scoped-mode","text":"To install the Atomist Kubernetes utilities in namespace-scoped mode, run the following command for each namespace you want to deploy them to. Replace NAMESPACE with the namespace you want to deploy the utilities to. atomist kube --namespace=\"NAMESPACE\" --environment=\"CLUSTER_ENV\"","title":"Namespace-scoped mode"},{"location":"pack/kubernetes/#kubernetes-cli","text":"If you have the kubectl command-line utility installed and configured to access your Kubernetes cluster with the needed privileges, you can install the needed Atomist utilities with the proper configuration using the following commands. Be sure to replace CLUSTER_ENV with a meaningful name for you Kubernetes cluster/namespace, WORKSPACE_ID with your Atomist workspace ID, and API_KEY with a valid Atomist API key. See the developer prerequisites for more information on Atomist workspace IDs and API keys.","title":"Kubernetes CLI"},{"location":"pack/kubernetes/#cluster-wide-mode_1","text":"","title":"Cluster-wide mode"},{"location":"pack/kubernetes/#k8vent","text":"To deploy k8vent in cluster-wide mode and have it report on changes to all pod containers, run the following command. kubectl apply --filename=https://raw.githubusercontent.com/atomist/k8vent/master/kube/kubectl/cluster-wide.yaml kubectl create secret --namespace=k8vent generic k8vent --from-literal=environment=\"CLUSTER_ENV\" \\ --from-literal=webhooks=\"https://webhook.atomist.com/atomist/kube/teams/WORKSPACE_ID\"","title":"k8vent"},{"location":"pack/kubernetes/#k8-automation","text":"To deploy k8-automation in cluster-wide mode with the ability to manage applications in all namespaces, run the following command. kubectl apply --filename=https://raw.githubusercontent.com/atomist/k8-automation/master/assets/kubectl/cluster-wide.yaml kubectl create secret --namespace=k8-automation generic automation \\ --from-literal=config=\"{\\\"workspaceIds\\\":[\\\"WORKSPACE_ID\\\"],\\\"apiKey\\\":\\\"API_KEY\\\",\\\"environment\\\":\\\"CLUSTER_ENV\\\"}\"","title":"k8-automation"},{"location":"pack/kubernetes/#namespace-scoped-mode_1","text":"In the commands below, replace NAMESPACE with the namespace you want to deploy the utilities to.","title":"Namespace-scoped mode"},{"location":"pack/kubernetes/#k8vent_1","text":"To deploy k8vent in namespace-scoped mode such that it will only report on pod containers in a single namespace, run the following commands. kubectl create secret --namespace=\"NAMESPACE\" generic k8vent \\ --from-literal=environment=\"CLUSTER_ENV\" \\ --from-literal=webhooks=\"https://webhook.atomist.com/atomist/kube/teams/WORKSPACE_ID\" kubectl apply --namespace=\"NAMESPACE\" \\ --filename=https://raw.githubusercontent.com/atomist/k8vent/master/kube/kubectl/namespace-scoped.yaml","title":"k8vent"},{"location":"pack/kubernetes/#k8-automation_1","text":"To deploy k8-automation in namespace-scoped mode such that it will only deploy and update resources in a single Kubernetes cluster namespace, run the following commands. kubectl create secret --namespace=\"NAMESPACE\" generic automation \\ --from-literal=config=\"{\\\"workspaceIds\\\":[\\\"WORKSPACE_ID\\\"],\\\"apiKey\\\":\\\"API_KEY\\\",\\\"environment\\\":\\\"CLUSTER_ENV\\\",\\\"kubernetes\\\":{\\\"mode\\\":\\\"namespace\\\"}}\" kubectl apply --namespace=\"NAMESPACE\" \\ --filename=https://raw.githubusercontent.com/atomist/k8-automation/master/assets/kubectl/namespace-scoped.yaml","title":"k8-automation"},{"location":"pack/kubernetes/#helm","text":"If you manage resources in your Kubernetes cluster with Helm , you can install the Atomist Kubernetes utilities using Helm. Replace API_KEY with an Atomist API key, WORKSPACE_ID with your Atomist workspace ID, and CLUSTER_ENV with a meaningful name for your Kubernetes cluster/namespace. Helm and Minikube Due to a bug in the default minikube bootstrapper localkube, kubernetes/helm#3135: Helm 2.7.0 creates RBAC resource fail , if you want to manage RBAC resources using Helm in minikube, you must start minikube using the kubeadm bootstrapper. minikube start --bootstrapper kubeadm You can make kubeadm your default bootstrapper by running the following command. minikube config set bootstrapper kubeadm","title":"Helm"},{"location":"pack/kubernetes/#cluster-wide-mode_2","text":"To install all of the Atomist Kubernetes utilities in cluster-wide mode, run the following helm command. helm upgrade --install --namespace=atomist atomist-utilities \\ --repo=https://atomist.github.io/helm-charts atomist-utilities \\ --set=global.atomist.apiKey=\"API_KEY\" \\ --set=global.atomist.workspaceIds=\"{WORKSPACE_ID}\" \\ --set=global.atomist.environment=\"CLUSTER_ENV\"","title":"Cluster-wide mode"},{"location":"pack/kubernetes/#namespace-scoped-mode_2","text":"To install all of the Atomist Kubernetes utilities in namespace-scoped mode, run the following helm command for each namespace you want to deploy them to. Replace NAMESPACE with the namespace you want to deploy the utilities to. helm upgrade --install --namespace=\"NAMESPACE\" \"atomist-utilities-NAMESPACE\" \\ --repo=https://atomist.github.io/helm-charts atomist-utilities \\ --set=global.atomist.apiKey=\"API_KEY\" \\ --set=global.atomist.workspaceIds=\"{WORKSPACE_ID}\" \\ --set=global.atomist.environment=\"CLUSTER_ENV\" \\ --set=global.atomist.mode=namespace","title":"Namespace-scoped mode"},{"location":"pack/kubernetes/#updating","text":"You can update to a new version of the Atomist Kubernetes utilities using standard Kubernetes approaches. If you installed the Atomist utilities using the Atomist CLI or Helm, simply re-run the same command you ran to install them. If you are using kubectl you can run the following commands, replacing NAMESPACE and M.N.P as appropriate. kubectl set image --namespace=NAMESPACE \\ deployment/k8vent k8vent=atomist/k8vent:M.N.P kubectl set image --namespace=NAMESPACE \\ deployment/k8-automation k8-automation=atomist/k8-automation:M.N.P You can always find the latest versions of k8-automation and k8vent on their release pages.","title":"Updating"},{"location":"pack/markdown/","text":"The Markdown pack provides parsing support and other utilities for working with Markdown files. The automation around this docs site uses this pack. GitHub API Doc Parsing Use the RemarkFileParser when evaluating [path expressions][../developer/pxe.md] to transform Markdown files. Code Transforms updateTitle returns a transform that changes the first top-level header of a Markdown file. Update Title Update the title of a Markdown document. This is useful for changing the title of README.md in a new project.","title":"Markdown"},{"location":"pack/markdown/#parsing","text":"Use the RemarkFileParser when evaluating [path expressions][../developer/pxe.md] to transform Markdown files.","title":"Parsing"},{"location":"pack/markdown/#code-transforms","text":"updateTitle returns a transform that changes the first top-level header of a Markdown file.","title":"Code Transforms"},{"location":"pack/markdown/#update-title","text":"Update the title of a Markdown document. This is useful for changing the title of README.md in a new project.","title":"Update Title"},{"location":"pack/node/","text":"The Node SDM pack provides various tools for JavaScript and TypeScript projects. It includes full support for building using npm scripts. There are also code inspections, reviewers, and more. You can use all or part of this support. Find the full API Doc here . GitHub Bundled automations You can install a chunk of node support by installing the pack with: sdm . addExtensionPack ( nodeSupport ({ inspectGoal , autofixGoal , review : { typescriptErrors : true }, autofix : { typescriptErrors : true }, })) This will get you the autofixes and code inspections listed below. Autofixes Let Atomist correct some common nitpicks in code. Add these autofixes to your autofix goal , or let the pack installation do it for you. tslint If a project is TypeScript, is Node, and has tslint.json , the tslintFix will run npm run lint:fix and commit the results for you. You need to define a \u201clint:fix\u201d npm script in package.json for this to work. This lets you pass additional options. We have the following in our package.json: \"scripts\": { ... \"lint\": \"tslint --format verbose --project . --exclude \\\"{build,node_modules}/**\\\" --exclude \\\"**/*.d.ts\\\" \\\"**/*.ts\\\"\", \"lint:fix\": \"npm run lint -- --fix\", ... } Add Build Script Our node build goals expect every project to have a \u201cbuild\u201d script in package.json. The AddBuildScript autofix adds one if you don\u2019t have it. The build script will echo something about \u201cbuild goes here,\u201d giving you a placeholder. Code Inspections Notice problems in TypeScript code. Add this to your autoinspect goal , or let the pack installation do it for you. DontImportOwnIndex We like to re-export the definitions that compose our external API from index.ts . Sometimes the IDE tries to import from index.ts even within the project, which creates circular imports and causes problems. This inspection makes that an error. PushTests Push Tests measure qualities of a project or push, so that you can decide whether goals or operations apply to them. This pack includes: IsTypeScript checks for any TypeScript files. IsNode checks for a package.json, which indicates a Node project. IsAtomistAutomationClient recognizes SDM projects. Code Transforms Code transforms operate on the code inside a project, performing well-defined modifications in place. This pack includes two that are used in generating new Node projects: Update Package Identification UpdatePackageJsonIdentification helps transform a seed into a new Node project. It sets the app name, description, version, author, repository, homepage, and bugs URL in package.json . Update README Title UpdateReadmeTitle helps transform a seed into a new Node project. Fingerprinters Fingerprinters identify significant bits of a project so that we can react when they change. package-lock.json Fingerprinter This computes a SHA of the package-lock.json, which changes whenever dependencies are updated. Goals This pack includes some useful parts to build your own goals. I recommend looking at the code for these when you decide whether to use them (or copy them). nodeBuilder Supply a list of commands to run your build. This builder adds error finding: if the log includes \u201cERR!\u201d or \u201c[error]\u201d the build fails log interpretation: pulls out the relevant bits of the log for some npm errors and mocha test failures app info extraction: pulls the project version name and out of package.json Register this builder on a build goal to use it: import { Build } from \"@atomist/sdm-pack-build\" ; const build = new Build (). with ({ name : \"npm-build\" , builder : nodeBuilder ( \"npm run compile\" , \"npm test\" ), pushTest : IsNode , }); npm publish executePublish as a GoalExecutor; you can use it to create a custom goal that publishes to npm. Examples of this pack in action Within Atomist, we use this pack extensively in the node support within our own SDM .","title":"Node"},{"location":"pack/node/#bundled-automations","text":"You can install a chunk of node support by installing the pack with: sdm . addExtensionPack ( nodeSupport ({ inspectGoal , autofixGoal , review : { typescriptErrors : true }, autofix : { typescriptErrors : true }, })) This will get you the autofixes and code inspections listed below.","title":"Bundled automations"},{"location":"pack/node/#autofixes","text":"Let Atomist correct some common nitpicks in code. Add these autofixes to your autofix goal , or let the pack installation do it for you.","title":"Autofixes"},{"location":"pack/node/#tslint","text":"If a project is TypeScript, is Node, and has tslint.json , the tslintFix will run npm run lint:fix and commit the results for you. You need to define a \u201clint:fix\u201d npm script in package.json for this to work. This lets you pass additional options. We have the following in our package.json: \"scripts\": { ... \"lint\": \"tslint --format verbose --project . --exclude \\\"{build,node_modules}/**\\\" --exclude \\\"**/*.d.ts\\\" \\\"**/*.ts\\\"\", \"lint:fix\": \"npm run lint -- --fix\", ... }","title":"tslint"},{"location":"pack/node/#add-build-script","text":"Our node build goals expect every project to have a \u201cbuild\u201d script in package.json. The AddBuildScript autofix adds one if you don\u2019t have it. The build script will echo something about \u201cbuild goes here,\u201d giving you a placeholder.","title":"Add Build Script"},{"location":"pack/node/#code-inspections","text":"Notice problems in TypeScript code. Add this to your autoinspect goal , or let the pack installation do it for you.","title":"Code Inspections"},{"location":"pack/node/#dontimportownindex","text":"We like to re-export the definitions that compose our external API from index.ts . Sometimes the IDE tries to import from index.ts even within the project, which creates circular imports and causes problems. This inspection makes that an error.","title":"DontImportOwnIndex"},{"location":"pack/node/#pushtests","text":"Push Tests measure qualities of a project or push, so that you can decide whether goals or operations apply to them. This pack includes: IsTypeScript checks for any TypeScript files. IsNode checks for a package.json, which indicates a Node project. IsAtomistAutomationClient recognizes SDM projects.","title":"PushTests"},{"location":"pack/node/#code-transforms","text":"Code transforms operate on the code inside a project, performing well-defined modifications in place. This pack includes two that are used in generating new Node projects:","title":"Code Transforms"},{"location":"pack/node/#update-package-identification","text":"UpdatePackageJsonIdentification helps transform a seed into a new Node project. It sets the app name, description, version, author, repository, homepage, and bugs URL in package.json .","title":"Update Package Identification"},{"location":"pack/node/#update-readme-title","text":"UpdateReadmeTitle helps transform a seed into a new Node project.","title":"Update README Title"},{"location":"pack/node/#fingerprinters","text":"Fingerprinters identify significant bits of a project so that we can react when they change.","title":"Fingerprinters"},{"location":"pack/node/#package-lockjson-fingerprinter","text":"This computes a SHA of the package-lock.json, which changes whenever dependencies are updated.","title":"package-lock.json Fingerprinter"},{"location":"pack/node/#goals","text":"This pack includes some useful parts to build your own goals. I recommend looking at the code for these when you decide whether to use them (or copy them).","title":"Goals"},{"location":"pack/node/#nodebuilder","text":"Supply a list of commands to run your build. This builder adds error finding: if the log includes \u201cERR!\u201d or \u201c[error]\u201d the build fails log interpretation: pulls out the relevant bits of the log for some npm errors and mocha test failures app info extraction: pulls the project version name and out of package.json Register this builder on a build goal to use it: import { Build } from \"@atomist/sdm-pack-build\" ; const build = new Build (). with ({ name : \"npm-build\" , builder : nodeBuilder ( \"npm run compile\" , \"npm test\" ), pushTest : IsNode , });","title":"nodeBuilder"},{"location":"pack/node/#npm-publish","text":"executePublish as a GoalExecutor; you can use it to create a custom goal that publishes to npm.","title":"npm publish"},{"location":"pack/node/#examples-of-this-pack-in-action","text":"Within Atomist, we use this pack extensively in the node support within our own SDM .","title":"Examples of this pack in action"},{"location":"pack/pcf/","text":"This pack provides deployment to Cloud Foundry . GitHub API Doc","title":"Cloud Foundry"},{"location":"pack/sloc/","text":"This pack helps you notice changes in the number of lines of code in your repository. GitHub API Doc","title":"Lines of Code"},{"location":"pack/sonarqube/","text":"This pack integrates with Sonarqube , a code quality tool. GitHub API Doc","title":"Sonarqube"},{"location":"pack/spring/","text":"This pack provides SDM functionality for Java. GitHub API Doc npm install @atomist/sdm-pack-spring Building Java software The Spring pack provides a way to build Java software, handling the CI part of a CI/CD lifecycle. This functionality depends on the presence of the @atomist/sdm-pack-build extension pack, so add that to your dependencies as well. Building using Maven To build your application using Maven, create a goal that kicks off a build using Maven: const mavenBuild = new Build (). with ({ builder : mavenBuilder ()}) When scheduling this goal, you can use the IsMaven push predicate to check whether this goal needs to be scheduled. sdm . withPushRules ( whenPushSatisfies ( IsMaven ). setGoals ( mavenBuild ) ) Building using Gradle Building your application using Gradle requires you to create a goal that kicks off a build using Gradle: const mavenBuild = new Build (). with ({ builder : gradleSingleModuleBuilder ()}) When scheduling this goal, you can use the IsGradle push predicate to check whether this goal needs to be scheduled. sdm . withPushRules ( whenPushSatisfies ( IsGradle ). setGoals ( mavenBuild ) ) Generating Java applications Atomist can be used to create brand new projects as well, and the Spring pack provides specific functionality to generate new Java (or Kotlin) applications. Take for example the following generator command as defined within an SDM: sdm . addGeneratorCommand < SpringProjectCreationParameters > ({ name : \"create-spring\" , intent : \"create spring\" , description : \"Create a new Java Spring Boot REST service\" , parameters : SpringProjectCreationParameterDefinitions , startingPoint : GitHubRepoRef.from ({ owner : \"atomist-seeds\" , repo : \"spring-rest\" , branch : \"master\" }), transform : [ ReplaceReadmeTitle , SetAtomistTeamInApplicationYml , TransformSeedToCustomProject , ], }); This will allow you to issue a create spring command to Atomist which creates a new project based on a specific seed project (in this case, a Github project) and will issue a couple of transforms in order to customize the project. In this case, the transforms will: Change the title of the README to reflect the new name Add the correct configuration in the Spring Boot property to have Atomist integration configured Transform the project based on the parameters you entered. This transform, which is Spring Boot specific, will: Change the POM Change the package to the package defined by the parameters Rename the application class name to reflect the project name as defined in the parameters These transforms use the parameters defined in SpringProjectCreationParameterDefinitions which requires your to enter: A project name A Maven group id A new root package Maven specific features Fingerprinting The MavenFingerprinter can be used in the Fingerprint goal in order to create a defining fingerprint for a build. In the case of the MavenFingerprinter , it will use the dependency information in the POM to create a dependency fingerprint. This way you can easily detect whether dependencies have changed between builds and act accordingly. Review usage of provided dependency The ProvidedDependencyReviewer will check whether your project is using provided dependencies and generate reveiw comments for each of those dependencies. You can then configure your AutoCodeInspection goal to use this reviewer. Transforms Add a dependency to a project You can use Atomist to add a dependency to a project, where it will add that dependency in the POM. sdm . addCodeTransformCommand ( AddMavenDependency ) This command will allow you to enter dependency information, and Atomist will edit the POM for you and add the dependency accordingly. Spring support Adding Spring support Spring support is added through an extension. Adding this extension to your SDM is done like this: sdm.addExtensionPacks( springSupport({ inspectGoal: inspect, autofixGoal: autofix, review: { cloudNative: true, springStyle: true, }, autofix: {}, reviewListeners: isInLocalMode() ? [] : [ singleIssuePerCategoryManaging(\"sdm-pack-spring\"), ], }), ); This support pack will add the following: Code inspections for certain known Spring issues: Violations common to cloud native application Violations common to modern Spring usage (usage of RequestMapping for example) An inspection listener that will put review comments into an issue, one per branch. The pack will automatically manage/update that issue and close it when the inspection is clean for the branch. Specific push tests The Spring support also provides a couple of push tests , like IsMaven , to support Spring-specific applications. These are: HasSpringBootPom : whether the POM of the project has a dependency to Spring Boot HasSpringBootApplicationClass : whether the project has a class that is annotated with @SpringBootApplication","title":"Spring"},{"location":"pack/spring/#building-java-software","text":"The Spring pack provides a way to build Java software, handling the CI part of a CI/CD lifecycle. This functionality depends on the presence of the @atomist/sdm-pack-build extension pack, so add that to your dependencies as well.","title":"Building Java software"},{"location":"pack/spring/#building-using-maven","text":"To build your application using Maven, create a goal that kicks off a build using Maven: const mavenBuild = new Build (). with ({ builder : mavenBuilder ()}) When scheduling this goal, you can use the IsMaven push predicate to check whether this goal needs to be scheduled. sdm . withPushRules ( whenPushSatisfies ( IsMaven ). setGoals ( mavenBuild ) )","title":"Building using Maven"},{"location":"pack/spring/#building-using-gradle","text":"Building your application using Gradle requires you to create a goal that kicks off a build using Gradle: const mavenBuild = new Build (). with ({ builder : gradleSingleModuleBuilder ()}) When scheduling this goal, you can use the IsGradle push predicate to check whether this goal needs to be scheduled. sdm . withPushRules ( whenPushSatisfies ( IsGradle ). setGoals ( mavenBuild ) )","title":"Building using Gradle"},{"location":"pack/spring/#generating-java-applications","text":"Atomist can be used to create brand new projects as well, and the Spring pack provides specific functionality to generate new Java (or Kotlin) applications. Take for example the following generator command as defined within an SDM: sdm . addGeneratorCommand < SpringProjectCreationParameters > ({ name : \"create-spring\" , intent : \"create spring\" , description : \"Create a new Java Spring Boot REST service\" , parameters : SpringProjectCreationParameterDefinitions , startingPoint : GitHubRepoRef.from ({ owner : \"atomist-seeds\" , repo : \"spring-rest\" , branch : \"master\" }), transform : [ ReplaceReadmeTitle , SetAtomistTeamInApplicationYml , TransformSeedToCustomProject , ], }); This will allow you to issue a create spring command to Atomist which creates a new project based on a specific seed project (in this case, a Github project) and will issue a couple of transforms in order to customize the project. In this case, the transforms will: Change the title of the README to reflect the new name Add the correct configuration in the Spring Boot property to have Atomist integration configured Transform the project based on the parameters you entered. This transform, which is Spring Boot specific, will: Change the POM Change the package to the package defined by the parameters Rename the application class name to reflect the project name as defined in the parameters These transforms use the parameters defined in SpringProjectCreationParameterDefinitions which requires your to enter: A project name A Maven group id A new root package","title":"Generating Java applications"},{"location":"pack/spring/#maven-specific-features","text":"","title":"Maven specific features"},{"location":"pack/spring/#fingerprinting","text":"The MavenFingerprinter can be used in the Fingerprint goal in order to create a defining fingerprint for a build. In the case of the MavenFingerprinter , it will use the dependency information in the POM to create a dependency fingerprint. This way you can easily detect whether dependencies have changed between builds and act accordingly.","title":"Fingerprinting"},{"location":"pack/spring/#review-usage-of-provided-dependency","text":"The ProvidedDependencyReviewer will check whether your project is using provided dependencies and generate reveiw comments for each of those dependencies. You can then configure your AutoCodeInspection goal to use this reviewer.","title":"Review usage of provided dependency"},{"location":"pack/spring/#transforms","text":"","title":"Transforms"},{"location":"pack/spring/#add-a-dependency-to-a-project","text":"You can use Atomist to add a dependency to a project, where it will add that dependency in the POM. sdm . addCodeTransformCommand ( AddMavenDependency ) This command will allow you to enter dependency information, and Atomist will edit the POM for you and add the dependency accordingly.","title":"Add a dependency to a project"},{"location":"pack/spring/#spring-support","text":"","title":"Spring support"},{"location":"pack/spring/#adding-spring-support","text":"Spring support is added through an extension. Adding this extension to your SDM is done like this: sdm.addExtensionPacks( springSupport({ inspectGoal: inspect, autofixGoal: autofix, review: { cloudNative: true, springStyle: true, }, autofix: {}, reviewListeners: isInLocalMode() ? [] : [ singleIssuePerCategoryManaging(\"sdm-pack-spring\"), ], }), ); This support pack will add the following: Code inspections for certain known Spring issues: Violations common to cloud native application Violations common to modern Spring usage (usage of RequestMapping for example) An inspection listener that will put review comments into an issue, one per branch. The pack will automatically manage/update that issue and close it when the inspection is clean for the branch.","title":"Adding Spring support"},{"location":"pack/spring/#specific-push-tests","text":"The Spring support also provides a couple of push tests , like IsMaven , to support Spring-specific applications. These are: HasSpringBootPom : whether the POM of the project has a dependency to Spring Boot HasSpringBootApplicationClass : whether the project has a class that is annotated with @SpringBootApplication","title":"Specific push tests"},{"location":"user/","text":"This page describes enrollment with Atomist as a service. Atomist is here to help you smooth your development flow. Start with our web console; see consolidated event notifications. Add ChatOps with Slack if you have it. Spawn your own software delivery machine, and integrate with other tools as you choose. When you enroll in the Atomist service, you get built-in automations such as Lifecycle Messages (Slack notifications on code push, PR, issue etc with action buttons) and commands like \u201ccreate issue\u201d. And your own Software Delivery Machines will work on events and commands from your whole organization. You can also use a Software Delivery Machine (SDM) on your laptop, individually, without enrolling in the service. To get going with a Local SDM, skip to the quick start guide . This page describes how to create an Atomist workspace . An Atomist workspace connects your code, build, deployment, and runtime platforms into a single, cohesive model of how your team provides value: delivering great solutions. Prerequisites You must have a Git source code management account, either GitHub.com, GitHub Enterprise (GHE), or BitBucket. If you want to use Atomist with GHE or BitBucket, please contact Atomist . The remainder of these instructions assume you have a GitHub.com account. If you do not already have a GitHub.com account, you can create one . For the whole shebang, it helps to have a GitHub organization and a Slack workspace. You can create these for free and have full admin powers, if you want to experiment. Hello Atomist Follow the instructions in the sign up or trial invitation email you received. When you first sign up, you\u2019ll be asked to authenticate with GitHub. Once you\u2019ve authenticated, you\u2019ll create a new Atomist workspace. Associate a GitHub organization with the Atomist workspace to start getting events. Atomist will ask your permission to create the needed webhook(s). For more information on how Atomist integrates with GitHub, see the GitHub integration documentation. The Atomist web interface will show you events, e.g., new commits and issue and pull request activity, from GitHub. Next steps Now that you have an Atomist workspace, you can Connect Atomist with your Slack workspace Connect Atomist with your continuous integration solution Connect Atomist with your Kubernetes clusters Configure the built-in chat integration You can also customize Atomist, molding it to your team\u2019s delivery model. Make Atomist respond to your own events and commands by creating your Software Delivery Machine. See the developer documentation to learn how to create and run your own Software Delivery machine!","title":"Getting Started"},{"location":"user/#prerequisites","text":"You must have a Git source code management account, either GitHub.com, GitHub Enterprise (GHE), or BitBucket. If you want to use Atomist with GHE or BitBucket, please contact Atomist . The remainder of these instructions assume you have a GitHub.com account. If you do not already have a GitHub.com account, you can create one . For the whole shebang, it helps to have a GitHub organization and a Slack workspace. You can create these for free and have full admin powers, if you want to experiment.","title":"Prerequisites"},{"location":"user/#hello-atomist","text":"Follow the instructions in the sign up or trial invitation email you received. When you first sign up, you\u2019ll be asked to authenticate with GitHub. Once you\u2019ve authenticated, you\u2019ll create a new Atomist workspace. Associate a GitHub organization with the Atomist workspace to start getting events. Atomist will ask your permission to create the needed webhook(s). For more information on how Atomist integrates with GitHub, see the GitHub integration documentation. The Atomist web interface will show you events, e.g., new commits and issue and pull request activity, from GitHub.","title":"Hello Atomist"},{"location":"user/#next-steps","text":"Now that you have an Atomist workspace, you can Connect Atomist with your Slack workspace Connect Atomist with your continuous integration solution Connect Atomist with your Kubernetes clusters Configure the built-in chat integration You can also customize Atomist, molding it to your team\u2019s delivery model. Make Atomist respond to your own events and commands by creating your Software Delivery Machine. See the developer documentation to learn how to create and run your own Software Delivery machine!","title":"Next steps"},{"location":"user/ci/","text":"Atomist natively supports several continuous integration (CI) platforms, listening for CI events, correlating them with the commits that triggered the build, and showing contextualized notifications in a Slack channel linked to the repository. To enable this capability, just add the desired Atomist CI webhook URL to your CI configuration. Note In the examples below, replace WORKSPACE_ID with your workspace ID. CircleCI To send events from CircleCI to Atomist, add the following snippet to your .circleci/config.yml configuration file. notify : webhooks : - url : https://webhook.atomist.com/atomist/circle/teams/WORKSPACE_ID Jenkins You can send events from Jenkins to Atomist using the notification plugin , configuring it to send its payload to https://webhook.atomist.com/atomist/jenkins/teams/WORKSPACE_ID , replacing WORKSPACE_ID with your Atomist workspace ID. If you configure your build using a Jenkinsfile , add the following function to your Jenkinsfile . import groovy.json.JsonOutput /** * Notify the Atomist services about the status of a build based from a * git repository. */ def notifyAtomist ( String workspaceIds , String buildStatus , String buildPhase = \"FINALIZED\" ) { if (! workspaceIds ) { echo 'No Atomist workspace IDs, not sending build notification' return } def payload = JsonOutput . toJson ( [ name: env . JOB_NAME , duration: currentBuild . duration , build: [ number: env . BUILD_NUMBER , phase: buildPhase , status: buildStatus , full_url: env . BUILD_URL , scm: [ url: env . GIT_URL , branch: env . COMMIT_BRANCH , commit: env . COMMIT_SHA ] ] ] ) workspaceIds . split ( ',' ). each { workspaceId -> String endpoint = \"https://webhook.atomist.com/atomist/jenkins/teams/${workspaceId}\" sh \"curl --silent -X POST -H 'Content-Type: application/json' -d '${payload}' ${endpoint}\" } } Ensure your build has an environment variable named ATOMIST_WORKSPACES whose value is your Atomist workspace ID or, if you want to send the event to more than one Atomist workspace, the value should be a comma-separated list of your Atomist workspace IDs. Then call notifyAtomist when the build starts (in the first stage) and ends (in the post block), sending the appropriate status and phase. Start: notifyAtomist(env.ATOMIST_WORKSPACES, \"STARTED\", \"STARTED\") Succesful: notifyAtomist(env.ATOMIST_WORKSPACES, \"SUCCESS\") Unstable: notifyAtomist(env.ATOMIST_WORKSPACES, \"UNSTABLE\") Failure: notifyAtomist(env.ATOMIST_WORKSPACES, \"FAILURE\") Here is a simple example Jenkinsfile pipeline that sends the appropriate webhook payloads at the appropriate time. /** * Simple Jenkins pipeline for Maven builds */ pipeline { agent any environment { MVN = 'mvn -B -V' } stages { stage ( 'Notify' ) { steps { echo 'Sending build start...' notifyAtomist ( env . ATOMIST_WORKSPACES , 'STARTED' , 'STARTED' ) } } stage ( 'Set version' ) { steps { echo 'Setting version...' sh \"${env.MVN} versions:set -DnewVersion=${env.COMMIT_SHA} versions:commit\" } } stage ( 'Build, Test, and Package' ) { steps { echo 'Building, testing, and packaging...' sh \"${env.MVN} clean package\" } } } post { always { echo 'Post notification...' notifyAtomist ( env . ATOMIST_WORKSPACES , currentBuild . currentResult ) } } } Travis CI To send events from Travis CI to Atomist, add the following snippet to your .travis.yml configuration file. notifications : webhooks : urls : - https://webhook.atomist.com/atomist/travis/teams/WORKSPACE_ID on_success : always on_failure : always on_start : always on_cancel : always on_error : always Other If you use a different CI tool than those listed above, you can send your build payload to Atomist using its generic build payload webhook endpoint. Atomist provides a helper Bash script you can call from your CI solution to post webhook payloads to Atomist. The script can be found in the Atomist utilities repository and can be invoked as follows: bash atomist-post-webhook.bash build WORKSPACE_ID If your CI platform is not supported by the above script or you prefer to use your own script, below is an example of how to send the necessary JSON payload using curl . curl -s -f -X POST -H \"Content-Type: application/json\" \\ --data-binary \"{\\\"branch\\\":\\\"BRANCH\\\",\\\"repository\\\":{\\\"owner_name\\\":\\\"REPO_OWNER\\\",\\\"name\\\":\\\"REPO_NAME\\\"},\\\"commit\\\":\\\"SHA\\\",\\\"status\\\":\\\"STATUS\\\",\\\"type\\\":\\\"TYPE\\\"}\" \\ https://webhook.atomist.com/atomist/build/teams/WORKSPACE_ID When using the above command, replace the ALL_CAPS strings as follows: String Description BRANCH Branch of commit being built REPO_OWNER Owner, i.e., organization or user, of repository REPO_NAME Name of repository SHA Full commit SHA STATUS Build status: \u201cstarted\u201d, \u201cfailed\u201d, \u201cerror\u201d, \u201cpassed\u201d, \u201ccanceled\u201d TYPE Build trigger: \u201cpush\u201d, \u201cpull_request\u201d, \u201ctag\u201d, \u201ccron\u201d, \u201cmanual\u201d There are other optional elements you can include in your webhook POST payload. Here is the complete list of build payload elements. Property JSON Type Description branch string Branch of commit (required if build type is \u201cpush\u201d) build_url string Web URL for build report/log commit string Full commit SHA (required) compare_url string Commit comparison URL showing changes id string Build ID, must be unique among all builds associated with a given repository name string Name for build number number Build number provider string Name of CI provider pull_request_number number Pull request number (only valid and required if build type is \u201cpull_request\u201d) repository.owner_name string Owner, i.e., organization or user, of repository (required) repository.name string Name of repository (required) status string Build status: \u201cstarted\u201d, \u201cfailed\u201d, \u201cerror\u201d, \u201cpassed\u201d, \u201ccanceled\u201d (required) tag string Tag being build, only valid and required if build type is \u201ctag\u201d type string Build trigger: \u201cpush\u201d, \u201cpull_request\u201d, \u201ctag\u201d, \u201ccron\u201d, \u201cmanual\u201d (required) See the build webhook documentation for more details.","title":"Integrations"},{"location":"user/ci/#circleci","text":"To send events from CircleCI to Atomist, add the following snippet to your .circleci/config.yml configuration file. notify : webhooks : - url : https://webhook.atomist.com/atomist/circle/teams/WORKSPACE_ID","title":"CircleCI"},{"location":"user/ci/#jenkins","text":"You can send events from Jenkins to Atomist using the notification plugin , configuring it to send its payload to https://webhook.atomist.com/atomist/jenkins/teams/WORKSPACE_ID , replacing WORKSPACE_ID with your Atomist workspace ID. If you configure your build using a Jenkinsfile , add the following function to your Jenkinsfile . import groovy.json.JsonOutput /** * Notify the Atomist services about the status of a build based from a * git repository. */ def notifyAtomist ( String workspaceIds , String buildStatus , String buildPhase = \"FINALIZED\" ) { if (! workspaceIds ) { echo 'No Atomist workspace IDs, not sending build notification' return } def payload = JsonOutput . toJson ( [ name: env . JOB_NAME , duration: currentBuild . duration , build: [ number: env . BUILD_NUMBER , phase: buildPhase , status: buildStatus , full_url: env . BUILD_URL , scm: [ url: env . GIT_URL , branch: env . COMMIT_BRANCH , commit: env . COMMIT_SHA ] ] ] ) workspaceIds . split ( ',' ). each { workspaceId -> String endpoint = \"https://webhook.atomist.com/atomist/jenkins/teams/${workspaceId}\" sh \"curl --silent -X POST -H 'Content-Type: application/json' -d '${payload}' ${endpoint}\" } } Ensure your build has an environment variable named ATOMIST_WORKSPACES whose value is your Atomist workspace ID or, if you want to send the event to more than one Atomist workspace, the value should be a comma-separated list of your Atomist workspace IDs. Then call notifyAtomist when the build starts (in the first stage) and ends (in the post block), sending the appropriate status and phase. Start: notifyAtomist(env.ATOMIST_WORKSPACES, \"STARTED\", \"STARTED\") Succesful: notifyAtomist(env.ATOMIST_WORKSPACES, \"SUCCESS\") Unstable: notifyAtomist(env.ATOMIST_WORKSPACES, \"UNSTABLE\") Failure: notifyAtomist(env.ATOMIST_WORKSPACES, \"FAILURE\") Here is a simple example Jenkinsfile pipeline that sends the appropriate webhook payloads at the appropriate time. /** * Simple Jenkins pipeline for Maven builds */ pipeline { agent any environment { MVN = 'mvn -B -V' } stages { stage ( 'Notify' ) { steps { echo 'Sending build start...' notifyAtomist ( env . ATOMIST_WORKSPACES , 'STARTED' , 'STARTED' ) } } stage ( 'Set version' ) { steps { echo 'Setting version...' sh \"${env.MVN} versions:set -DnewVersion=${env.COMMIT_SHA} versions:commit\" } } stage ( 'Build, Test, and Package' ) { steps { echo 'Building, testing, and packaging...' sh \"${env.MVN} clean package\" } } } post { always { echo 'Post notification...' notifyAtomist ( env . ATOMIST_WORKSPACES , currentBuild . currentResult ) } } }","title":"Jenkins"},{"location":"user/ci/#travis-ci","text":"To send events from Travis CI to Atomist, add the following snippet to your .travis.yml configuration file. notifications : webhooks : urls : - https://webhook.atomist.com/atomist/travis/teams/WORKSPACE_ID on_success : always on_failure : always on_start : always on_cancel : always on_error : always","title":"Travis CI"},{"location":"user/ci/#other","text":"If you use a different CI tool than those listed above, you can send your build payload to Atomist using its generic build payload webhook endpoint. Atomist provides a helper Bash script you can call from your CI solution to post webhook payloads to Atomist. The script can be found in the Atomist utilities repository and can be invoked as follows: bash atomist-post-webhook.bash build WORKSPACE_ID If your CI platform is not supported by the above script or you prefer to use your own script, below is an example of how to send the necessary JSON payload using curl . curl -s -f -X POST -H \"Content-Type: application/json\" \\ --data-binary \"{\\\"branch\\\":\\\"BRANCH\\\",\\\"repository\\\":{\\\"owner_name\\\":\\\"REPO_OWNER\\\",\\\"name\\\":\\\"REPO_NAME\\\"},\\\"commit\\\":\\\"SHA\\\",\\\"status\\\":\\\"STATUS\\\",\\\"type\\\":\\\"TYPE\\\"}\" \\ https://webhook.atomist.com/atomist/build/teams/WORKSPACE_ID When using the above command, replace the ALL_CAPS strings as follows: String Description BRANCH Branch of commit being built REPO_OWNER Owner, i.e., organization or user, of repository REPO_NAME Name of repository SHA Full commit SHA STATUS Build status: \u201cstarted\u201d, \u201cfailed\u201d, \u201cerror\u201d, \u201cpassed\u201d, \u201ccanceled\u201d TYPE Build trigger: \u201cpush\u201d, \u201cpull_request\u201d, \u201ctag\u201d, \u201ccron\u201d, \u201cmanual\u201d There are other optional elements you can include in your webhook POST payload. Here is the complete list of build payload elements. Property JSON Type Description branch string Branch of commit (required if build type is \u201cpush\u201d) build_url string Web URL for build report/log commit string Full commit SHA (required) compare_url string Commit comparison URL showing changes id string Build ID, must be unique among all builds associated with a given repository name string Name for build number number Build number provider string Name of CI provider pull_request_number number Pull request number (only valid and required if build type is \u201cpull_request\u201d) repository.owner_name string Owner, i.e., organization or user, of repository (required) repository.name string Name of repository (required) status string Build status: \u201cstarted\u201d, \u201cfailed\u201d, \u201cerror\u201d, \u201cpassed\u201d, \u201ccanceled\u201d (required) tag string Tag being build, only valid and required if build type is \u201ctag\u201d type string Build trigger: \u201cpush\u201d, \u201cpull_request\u201d, \u201ctag\u201d, \u201ccron\u201d, \u201cmanual\u201d (required) See the build webhook documentation for more details.","title":"Other"},{"location":"user/dashboard/","text":"The Atomist web interface is located at app.atomist.com . Here, you can see some notifications, run GraphQL queries against your data, and administer your Atomist workspace.","title":"Atomist web interface"},{"location":"user/github/","text":"Atomist helps you work with GitHub in two ways: Atomist surfaces your team\u2019s development activity, such as pushes, pull requests, or issues, in the Atomist web interface in chat. This visibility is enabled via webhooks. Atomist allows you to take action in your repositories, creating issues, merging pull requests, even releasing services to production, from the Atomist web interface or in chat. To release the full ChatOps power of Atomist, each user on your team will independently authorize Atomist \u2013 this means that your users remain within the boundaries of the existing GitHub security model. Atomist acts on behalf of your users, not instead of them. Webhooks Atomist receives its information from GitHub via webhooks . To ease adoption across your organization, installing an organization webhook is recommended. To try Atomist out on a small scale, you can install webhooks repository by repository. Organization webhooks GitHub organization members that have the owner role , are allowed to configure organization webhooks. This is convenient because it only has to be configured once; however, you will require a user who has the Owner role in your GitHub organization. you> @atomist enroll org When you choose to enroll a GitHub organization, you will most likely be prompted to authorize a new scope (Atomist only asks for new scopes when explicitly required). The admin:org_hook is required when enrolling a new GitHub organization. If you are a member of more than one GitHub organization, Atomist asks you to choose which organization to enroll. Repository webhooks If your team does not use a GitHub organization account, you can choose to configure webhooks on individual repositories owned by your user account. GitHub user authorization When the Atomist bot first arrives in a Slack workspace, it will send a direct message to the authorizing user, requesting that they authorize Atomist to access GitHub on their behalf. This same dialog will be shown to users anytime Atomist detects that an automation needs to access GitHub as that user. Every member of the workspace must individually opt in. Atomist will display this option each time an un-authorized user runs a command that requires a GitHub authorization. Users can ask for their current GitHub authorization status by running: you> @atomist github Atomist will send a direct message to this user with their current GitHub authorization status.","title":"Source Control"},{"location":"user/github/#webhooks","text":"Atomist receives its information from GitHub via webhooks . To ease adoption across your organization, installing an organization webhook is recommended. To try Atomist out on a small scale, you can install webhooks repository by repository.","title":"Webhooks"},{"location":"user/github/#organization-webhooks","text":"GitHub organization members that have the owner role , are allowed to configure organization webhooks. This is convenient because it only has to be configured once; however, you will require a user who has the Owner role in your GitHub organization. you> @atomist enroll org When you choose to enroll a GitHub organization, you will most likely be prompted to authorize a new scope (Atomist only asks for new scopes when explicitly required). The admin:org_hook is required when enrolling a new GitHub organization. If you are a member of more than one GitHub organization, Atomist asks you to choose which organization to enroll.","title":"Organization webhooks"},{"location":"user/github/#repository-webhooks","text":"If your team does not use a GitHub organization account, you can choose to configure webhooks on individual repositories owned by your user account.","title":"Repository webhooks"},{"location":"user/github/#github-user-authorization","text":"When the Atomist bot first arrives in a Slack workspace, it will send a direct message to the authorizing user, requesting that they authorize Atomist to access GitHub on their behalf. This same dialog will be shown to users anytime Atomist detects that an automation needs to access GitHub as that user. Every member of the workspace must individually opt in. Atomist will display this option each time an un-authorized user runs a command that requires a GitHub authorization. Users can ask for their current GitHub authorization status by running: you> @atomist github Atomist will send a direct message to this user with their current GitHub authorization status.","title":"GitHub user authorization"},{"location":"user/integrations/","text":"Atomist receives events from and performs operations on many systems, including version control, CI systems, Slack, and more. Atomist uses the native integration technology for each platform or tool. For example, to integrate with GitHub and Travis CI, Atomist uses webhooks; to integrate with Slack it uses their event API. For each platform Atomist integrates with, it requests the minimal set of permissions required. If you use a system or tool Atomist does not natively support, you can implement your own integrations. You can use whatever tools and libraries you want to communicate with your systems, and then register these custom event types with Atomist so it can properly connect them with other events. Chat Integrations Send messages to channels and people, receive commands, query people for command parameters, update messages, and include buttons on messages. Slack MS Teams (experimental) Version Control Integrations Atomist receives events for Pushes and Pull Requests (PRs). The built-in integrations include action buttons to create and merge PRs and add labels, reviewers, and comments to PRs. GitHub GitHub Enterprise BitBucket BitBucket Cloud GitLab Issue Tracking Integrations Atomist receives events for issue and issue comment creation and update. GitHub Issues CI Integrations Atomist can receive build notifications from: Jenkins Travis CI TeamCity Circle CI any other build system, as a POST to our webhook Running other programs from Atomist In response to events, you can trigger actions on other systems from your Atomist automations. Some of the ones already implemented include: Checkstyle TSLint Sonarqube anything you can run from a shell or command prompt","title":"Supported Integrations"},{"location":"user/integrations/#chat-integrations","text":"Send messages to channels and people, receive commands, query people for command parameters, update messages, and include buttons on messages. Slack MS Teams (experimental)","title":"Chat Integrations"},{"location":"user/integrations/#version-control-integrations","text":"Atomist receives events for Pushes and Pull Requests (PRs). The built-in integrations include action buttons to create and merge PRs and add labels, reviewers, and comments to PRs. GitHub GitHub Enterprise BitBucket BitBucket Cloud GitLab","title":"Version Control Integrations"},{"location":"user/integrations/#issue-tracking-integrations","text":"Atomist receives events for issue and issue comment creation and update. GitHub Issues","title":"Issue Tracking Integrations"},{"location":"user/integrations/#ci-integrations","text":"Atomist can receive build notifications from: Jenkins Travis CI TeamCity Circle CI any other build system, as a POST to our webhook","title":"CI Integrations"},{"location":"user/integrations/#running-other-programs-from-atomist","text":"In response to events, you can trigger actions on other systems from your Atomist automations. Some of the ones already implemented include: Checkstyle TSLint Sonarqube anything you can run from a shell or command prompt","title":"Running other programs from Atomist"},{"location":"user/lifecycle/","text":"Chat notifications about pushes, builds, pull requests, issues, and issue comments are fewer and far more useful when they\u2019re correlated by Atomist. You get one message per push, and that message updates as new information comes in. Less spam in your channels! Even better, the messages have buttons that make them useful. Messages Push A code push is the most recognized event in the delivery process. Atomist correlates all of this into a dynamic, updating push notification: Commit summaries, grouped by author GitHub statuses Build results SDM Goals, with approval buttons Tags Deployments Buttons: Raise PR for branches, Restart Build when it failed Here\u2019s a sample push notification with SDM goals: Build Build status is included on the push notification, right next to the commit message. This could be a build performed by your Atomist SDM or by another build system like Jenkins, Travis, TeamCity, etc. If a build fails, the person who made the commit gets a private message with a link to the log. Linked Channels Messages about each repository are sent to chat channels linked to that repository. You control which repositories are linked to which channels are linked from chat, within the channel itself. Link a repository to a channel to start receiving messages like Push and Issue. This will also give the channel some context: if there\u2019s one repository linked, and you say @atomist create issue , Atomist will put the new issue in that repository. What repositories are linked? Within any chat channel, say @atomist repos to see whether any repositories are linked. You\u2019ll get a list of linked repositories (with an \u201cunlink\u201d button for each) and a button to link a new channel. Link a repository Within a channel, say @atomist link repo to link a repository to that channel. Atomist will ask you for the repository name. It\u2019ll give you a dropdown box if there aren\u2019t too many channels to list in it. (If Atomist hasn\u2019t been invited yet, invite it; after that, you\u2019ll have to type the command again. It can\u2019t see any messages that appeared before it was invited.) Your Atomist workspace might be connected to multiple repository owners\u2013multiple GitHub organizations, say, or multiple versions systems like GitHub and GitLab. In this case, Atomist will ask you to choose the owner first, and then the repository. Hint If you already have a repository linked to this channel, Atomist will assume you want to link a repository with the same owner. If you want a different one, try @atomist link repos owner=<other-organization> . Customize the link You can turn some messages on and off. For instance, do you want to hear about the lifecycle of a Pull Request? How about a branch? Maybe not Issue Comments, anymore. Say @atomist configure lifecycle to see your options. Unlink a repository Say @atomist repos to get a list of linked repositories; push the \u201cUnlink\u201d button on the one you want to remove.","title":"Built-in Chat Integrations"},{"location":"user/lifecycle/#messages","text":"","title":"Messages"},{"location":"user/lifecycle/#push","text":"A code push is the most recognized event in the delivery process. Atomist correlates all of this into a dynamic, updating push notification: Commit summaries, grouped by author GitHub statuses Build results SDM Goals, with approval buttons Tags Deployments Buttons: Raise PR for branches, Restart Build when it failed Here\u2019s a sample push notification with SDM goals:","title":"Push"},{"location":"user/lifecycle/#build","text":"Build status is included on the push notification, right next to the commit message. This could be a build performed by your Atomist SDM or by another build system like Jenkins, Travis, TeamCity, etc. If a build fails, the person who made the commit gets a private message with a link to the log.","title":"Build"},{"location":"user/lifecycle/#linked-channels","text":"Messages about each repository are sent to chat channels linked to that repository. You control which repositories are linked to which channels are linked from chat, within the channel itself. Link a repository to a channel to start receiving messages like Push and Issue. This will also give the channel some context: if there\u2019s one repository linked, and you say @atomist create issue , Atomist will put the new issue in that repository.","title":"Linked Channels"},{"location":"user/lifecycle/#what-repositories-are-linked","text":"Within any chat channel, say @atomist repos to see whether any repositories are linked. You\u2019ll get a list of linked repositories (with an \u201cunlink\u201d button for each) and a button to link a new channel.","title":"What repositories are linked?"},{"location":"user/lifecycle/#link-a-repository","text":"Within a channel, say @atomist link repo to link a repository to that channel. Atomist will ask you for the repository name. It\u2019ll give you a dropdown box if there aren\u2019t too many channels to list in it. (If Atomist hasn\u2019t been invited yet, invite it; after that, you\u2019ll have to type the command again. It can\u2019t see any messages that appeared before it was invited.) Your Atomist workspace might be connected to multiple repository owners\u2013multiple GitHub organizations, say, or multiple versions systems like GitHub and GitLab. In this case, Atomist will ask you to choose the owner first, and then the repository. Hint If you already have a repository linked to this channel, Atomist will assume you want to link a repository with the same owner. If you want a different one, try @atomist link repos owner=<other-organization> .","title":"Link a repository"},{"location":"user/lifecycle/#customize-the-link","text":"You can turn some messages on and off. For instance, do you want to hear about the lifecycle of a Pull Request? How about a branch? Maybe not Issue Comments, anymore. Say @atomist configure lifecycle to see your options.","title":"Customize the link"},{"location":"user/lifecycle/#unlink-a-repository","text":"Say @atomist repos to get a list of linked repositories; push the \u201cUnlink\u201d button on the one you want to remove.","title":"Unlink a repository"},{"location":"user/slack/","text":"Atomist has a powerful Slack integration to help your team access the power of ChatOps. If you already have the Atomist bot in your Slack, skip to Issuing commands . Enroll Slack bot Click the \u201cAdd to Slack\u201d button below to invite the Atomist bot into your Slack workspace. Slack\u2019s default configuration allows all workspace members to add new Slack applications. However, your workspaces\u2019 admins may restrict the applications that can can be added in your workspace. The permissions management page has an \u201cApproved Apps\u201d setting to control this. If your workspace requires approval for new apps and you\u2019re not a Slack administrator, Slack helps you request approval from your Slack workspace\u2019 administrators to install the Atomist application. Currently the authorization process asks you to authorize two things: The Atomist app adds a bot user named \u201c@atomist\u201d to your workspace. Members can \\invite the Atomist bot to channels to access the full functionality of Atomist. Bot users cannot create channels, cannot join channels unless they are invited by a non-bot channel member, and cannot see messages in channels where they are not a member. Atomist requests a scope called \u201cModify public channels\u201d. This scope allows Atomist to help you setup channels. For example, when you create a project in a new repository, Atomist can create a Slack channel to go with it. Note The Atomist app creates new channels on behalf of the user who first authorizes Atomist. Removing Atomist from Slack You can remove the bot from all your channels instantly by revoking access to the \u201cAtomist\u201d application. We certainly hope it doesn\u2019t come to this! The App Manage page has a \u201cRemove App\u201d button at the bottom of the page. Please let us know if there\u2019s anything we can do to clarify how the bot works within your Slack workspace. Linking repositories & Slack channels Now that you you have Slack connected with Atomist, you should \u201clink\u201d your source code repositories with Slack channels so you can see and control your project\u2019s activity from Slack. All you need to do is invite the Atomist bot to a Slack channel and then send it repo . /invite @atomist @atomist repo The bot will open a thread and ask you what repository you want to link to the channel. If you added an organization webhook, you can link any repository in your organization. If you added webhooks to individual repositories, you will only be able to link those repositories. /** * Function that tracks a click on an outbound link in Analytics. * * We want to track clicks on 'Add to Slack' */ var trackOutboundLink = function(url) { ga('send', 'event', 'outbound', 'click', url, { 'transport': 'beacon', 'hitCallback': function(){document.location = url;} }); } Issuing commands The Atomist bot can do many things for you. There are some commands built-in, and others added by automations, including your own. Issue commands either by addressing the bot in any channel it has been invited to (for example, @atomist help ) or by sending a DM to atomist. When you\u2019re in a channel that is linked to a repository, and you run a command (such as create issue ) that works on a repository, Atomist recognizes the context and runs the command on that repository. Finding commands Get a short list of commands to try from @atomist help . Get the full list of commands with @atomist list skills . Get the details of a particular command with @atomist describe skill <skill> where \u201cskill\u201d is replaced by the skill text: for instance, @atomist describe skill create issue . Parameters When a command needs parameters, Atomist will prompt you for them. For instance, \u201ccreate issue\u201d requires an issue title and accepts an optional issue body. You can also provide parameters in the command invocation. For example: @atomist create issue title=\"Say hello please\" body=\"I want it to say hello\" If you provide all required parameters on the command line, most commands will immediately execute. Others will give you an opportunity to change any of the parameters before submission. Sometimes all parameters are optional, and the only way to override them is on the command line. For instance: @atomist reset goals branch=my-branch will trigger goal-setting on your branch instead of on the master branch. To see all the parameters, use @atomist describe skill <skill> .","title":"Slack"},{"location":"user/slack/#enroll-slack-bot","text":"Click the \u201cAdd to Slack\u201d button below to invite the Atomist bot into your Slack workspace. Slack\u2019s default configuration allows all workspace members to add new Slack applications. However, your workspaces\u2019 admins may restrict the applications that can can be added in your workspace. The permissions management page has an \u201cApproved Apps\u201d setting to control this. If your workspace requires approval for new apps and you\u2019re not a Slack administrator, Slack helps you request approval from your Slack workspace\u2019 administrators to install the Atomist application. Currently the authorization process asks you to authorize two things: The Atomist app adds a bot user named \u201c@atomist\u201d to your workspace. Members can \\invite the Atomist bot to channels to access the full functionality of Atomist. Bot users cannot create channels, cannot join channels unless they are invited by a non-bot channel member, and cannot see messages in channels where they are not a member. Atomist requests a scope called \u201cModify public channels\u201d. This scope allows Atomist to help you setup channels. For example, when you create a project in a new repository, Atomist can create a Slack channel to go with it. Note The Atomist app creates new channels on behalf of the user who first authorizes Atomist.","title":"Enroll Slack bot"},{"location":"user/slack/#removing-atomist-from-slack","text":"You can remove the bot from all your channels instantly by revoking access to the \u201cAtomist\u201d application. We certainly hope it doesn\u2019t come to this! The App Manage page has a \u201cRemove App\u201d button at the bottom of the page. Please let us know if there\u2019s anything we can do to clarify how the bot works within your Slack workspace.","title":"Removing Atomist from Slack"},{"location":"user/slack/#linking-repositories-slack-channels","text":"Now that you you have Slack connected with Atomist, you should \u201clink\u201d your source code repositories with Slack channels so you can see and control your project\u2019s activity from Slack. All you need to do is invite the Atomist bot to a Slack channel and then send it repo . /invite @atomist @atomist repo The bot will open a thread and ask you what repository you want to link to the channel. If you added an organization webhook, you can link any repository in your organization. If you added webhooks to individual repositories, you will only be able to link those repositories. /** * Function that tracks a click on an outbound link in Analytics. * * We want to track clicks on 'Add to Slack' */ var trackOutboundLink = function(url) { ga('send', 'event', 'outbound', 'click', url, { 'transport': 'beacon', 'hitCallback': function(){document.location = url;} }); }","title":"Linking repositories &amp; Slack channels"},{"location":"user/slack/#issuing-commands","text":"The Atomist bot can do many things for you. There are some commands built-in, and others added by automations, including your own. Issue commands either by addressing the bot in any channel it has been invited to (for example, @atomist help ) or by sending a DM to atomist. When you\u2019re in a channel that is linked to a repository, and you run a command (such as create issue ) that works on a repository, Atomist recognizes the context and runs the command on that repository.","title":"Issuing commands"},{"location":"user/slack/#finding-commands","text":"Get a short list of commands to try from @atomist help . Get the full list of commands with @atomist list skills . Get the details of a particular command with @atomist describe skill <skill> where \u201cskill\u201d is replaced by the skill text: for instance, @atomist describe skill create issue .","title":"Finding commands"},{"location":"user/slack/#parameters","text":"When a command needs parameters, Atomist will prompt you for them. For instance, \u201ccreate issue\u201d requires an issue title and accepts an optional issue body. You can also provide parameters in the command invocation. For example: @atomist create issue title=\"Say hello please\" body=\"I want it to say hello\" If you provide all required parameters on the command line, most commands will immediately execute. Others will give you an opportunity to change any of the parameters before submission. Sometimes all parameters are optional, and the only way to override them is on the command line. For instance: @atomist reset goals branch=my-branch will trigger goal-setting on your branch instead of on the master branch. To see all the parameters, use @atomist describe skill <skill> .","title":"Parameters"}]}